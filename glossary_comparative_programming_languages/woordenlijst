Abstract datatype/{Also known as ADT. An abstract data type is a mathematical model for a certain class of data structures that have similar behavior, or for certain data types of one or more programming languages that have similar semantics. An abstract data type is defined indirectly, only by the operations that may be performed on it and by mathematical constraints on the effects (and possibly cost) of those operations.}
Abstraction/{The ability of a programming language to emphasise general properties of a segment of code and hide the details. For instance avoiding that something should be stated more than once.}
Actor-oriented/{A programming paradigm where programs are structured as agents who have their own state and communicate through messages with each other.}
Advanced object-oriented programming/{A set of extensions for the basic object-oriented programming model. Advanced object-oriented programming techniques include multiple inheritance, traits, implicits, open classes, multimethods and generics.}
Agent-Oriented/{A programming paradigm based on actor-orientd programming where the actors have more constraints. Agents are actors who should make use of commitments and goals.}
AGOL60/{A modern programming language and abbreviation of the ALGOrithmic Language. AGOL60 introduced many new concepts like nested block structures, lexical scoping, anonymous routines, recursive typing with high-order functions,...}
Aspect-oriented programming/{Also known as AOP. A programming paradigm that aims to increase modularity by allowing the separation of cross-cutting concerns. aspect-oriented programming forms a basis for aspect-oriented software development.}
Assembly Language/{A language that is just one level above machine language. Instructions are translated into their ASCII-equivalent and one can use symbolic addresses.}
Automation/{The ability of a programming language to automate mechanical, tedious, or error-prone activities (for instance with Domain Specific Languages).}
Bit-level matching/{Bit level matching is a programming technique where conditions are represented as grouped bits. One can perform matching by using a logical operator (like AND, OR,...) and finally check on some condition of the resulting group. Bit-level matching can increase the performance of certain checks.}
C/{An early system programming language. Developed between 1969 and 1973.}
C++/{A programming language that combined object-oriented programming with system programming.}
Clauses/{Clauses are a modularisation in logic programming where the programmer specifies that a certain clause is true if a set of other clauses is true.}
COBOL/{One of the first three modern programming languages. An abbreviation for the COmmon Business Oriented Language.}
Code generation code/{Code generation code is code written in a specific programming language in order to generate code written in the target programming language.}
Component-based programming/{A programming paradigm that emphasizes the separation of concerns in respect of the wide-ranging functionality available throughout a given software system. It is a reuse-based approach to defining, implementing and composing loosely coupled independent components into systems. This practice aims to bring about an equally wide-ranging degree of benefits in both the short-term and the long-term for the software itself and for organizations that sponsor such software. Software engineers regard components as part of the starting platform for service-orientation. Components play this role, for example, in Web services, and more recently, in service-oriented architectures (SOA), whereby a component is converted by the Web service into a service and subsequently inherits further characteristics beyond that of an ordinary component. Components can produce or consume events and can be used for event driven architectures (EDA).}
Concurrency/{concurrency is a property of systems in which several computations are executing simultaneously, and potentially interacting with each other. The computations may be executing on multiple cores in the same chip, preemptively time-shared threads on the same processor, or executed on physically separated processors.}
Constraint-based programming/{A programming paradigm where the programmer specifies the constraints in a programming language and the execution mechanism will solve the problem using some type of inference. A problem with constraint based programming is that it is in general NP-complete and therefore some programs will be executed inefficiently.}
Data abstraction/{A form of abstraction where we hide information about how data is represented. This can be done by abstract data types, modules, classes and interfaces. The implementation decisions are separated from the parts of the program using the data structure. Data abstraction allows data to be used in different ways by different programs.}
Database/{A database is a computer system designed to store and maintain data.}
Dataflow/{The dataflow of a program is a description how variables interact wich each other and how data is passed from variables to variables.}
Defence in Depth/{The ability of a programming language to have a series of defences, so that if an error is not caught by one, it will probably be caught by another.}
Domain abstractions/{Domain abstracts are a set of rules specific to a domain. If we implement a domain specific language, these rules can be ommited in code written in the domain specific language.}
Duck typing/{Duck typing is a style of dynamic typing in which an object's methods and properties determine the valid semantics, rather than its inheritance from a particular class or implementation of a specific interface. The name of the concept refers to the duck test ``When I see a bird that walks like a duck and swims like a duck and quacks like a duck, I call that bird a duck.'' In duck typing, one is concerned with just those aspects of an object that are used, rather than with the type of the object itself. For example, in a non-duck-typed language, one can create a function that takes an object of type Duck and calls that object's walk and quack methods. In a duck-typed language, the equivalent function would take an object of any type and call that object's walk and quack methods. If the object does not have the methods that are called then the function signals a run-time error. If the object does have the methods, then they are executed no matter the type of the object, evoking the quotation and hence the name of this form of typing.}
Dynamic typing/{A programming language is said to be dynamically typed when the majority of its type checking is performed at run-time as opposed to at compile-time. In dynamic typing values have types, but variables do not; that is, a variable can refer to a value of any type. Dynamically typed languages include APL, Erlang, Groovy, JavaScript, Lisp, Lua, MATLAB, GNU Octave, Perl, PHP, Pick BASIC, Prolog, Python, R, Ruby, Smalltalk and Tcl. Implementations of dynamically typed languages generally associate run-time objects with "tags" containing their type information. This run-time classification is then used to implement type checks and dispatch overloaded functions, but can also enable pervasive uses of dynamic dispatch, late binding and similar idioms that would be cumbersome at best in a statically typed language, requiring the use of variant types or similar features. Dynamic typing may result in runtime type errors—that is, at runtime, a value may have an unexpected type, and an operation nonsensical for that type is applied. Such errors may occur long after the place where the programming mistake was made—that is, the place where the wrong type of data passed into a place it should not have. This may make the bug difficult to locate. Dynamically typed language systems' run-time checks can potentially be more sophisticated than those of statically typed languages, as they can use dynamic information as well as any information from the source code. On the other hand, runtime checks only assert that conditions hold in a particular execution of the program, and the checks are repeated for every execution of the program. Development in dynamically typed languages is often supported by programming practices such as unit testing. Testing is a key practice in professional software development, and is particularly important in dynamically typed languages. In practice, the testing done to ensure correct program operation can detect a much wider range of errors than static type-checking, but full test coverage over all possible executions of a program (including timing, user inputs, etc.), if even possible, would be extremely costly and impractical. Static typing helps by providing strong guarantees of a particular subset of commonly made errors never occurring.}
Elegance/{The ability of a programming language to confine your attention to designs that look good because they are good.}
Encapsulation/{A language mechanism for restricting access to some of the object's components. Or a language construct that facilitates the bundling of data with the methods operating that data.}
Equational definition/{An equational definition is a piece of programming code where the entire result of a method is computed as a mathematical formula.}
Event-driven programming/{Also known as EDP or event-based programming. A programming paradigm in which the flow of the program is determined by eventsor messages from other programs or threads. Event-driven programming can also be defined as an application architecture technique in which the application has a main loop which is clearly divided down to two sections: the first is event selection (or event detection) and the second is event handling. In embedded systems the same may be achieved using interrupts instead of a constantly running main loop; in that case the former portion of the architecture resides completely in computer hardware. Event-driven programs can be written in any language, although the task is easier in languages that provide high-level abstractions, such as closures. Some integrated development environments, such as Microsoft Visual Studio, provide code generation assistants that automate the most repetitive tasks required for event handling.}
Failure model/{A failure model is a description on how threads should handle the fact that they fail on a certain task. In most cases this means the thread terminates. Furthermore in some models other threads will receive a message that a thread has failed in order to act appropriate.}
Field init/{Field init is a piece of code in a programming language that specifies how fields should receive their initial values. In most cases this is done by the constructor or by the field declaration.}
FORTRAN/{One of the first three modern programming languages. Invented in 1954 and an abbreviation for FORmula TRANslator.}
Functional programming/{A programming paradigm that treats computation as the evaluation of mathematical functions, avoiding state and mutable data. A popular example is Haskell}
Generic abstraction/{A form of abstraction where we make abstraction of the datatypes and take the type as a parameter in order to avoid code duplication.}
Higher-order function/{Also known as functional form, functional or functor. A higher-order function is a function that does at least one of the following: take one or more functions as an input or, output a function. All other functions are first order functions. In mathematics higher-order functions are also known as operators or functionals. The derivative in calculus is a common example, since it maps a function to another function. In the untyped lambda calculus, all functions are higher-order; in a typed lambda calculus, from which most functional programming languages are derived, higher-order functions are values with types of the form $(\tau_1\to\tau_2)\to\tau_3$.}
Imperative programming/{A programming paradigm where programs are defined in terms of statements that the change the program state. A popular example is C}
Impossible error/{The ability of a programming language that making some errors is impossible due to language specificiations. Making errors impossible is preferable to detecting them after their commission.}
Inferred typing/{Also known as implicit typing or type inference. It is a feature present in some strongly statically typed languages. It is often characteristic of, but not limited to, functional programming languages in general. Some languages that include type inference are ML, OCaml, Haskell, Scala, D, Clean, Opa and Go. It has lately been added (to some extent) to Visual Basic, C\# and C++11. It is also planned for Perl 6. The ability to infer types automatically makes many programming tasks easier, leaving the programmer free to omit type annotations while still permitting type checking.}
Information hiding/{The ability of a programming language to permit modules to be designed so the user has all the information he needs in order to use the module correctly, but noting more. Furthermore an implementor should have all the information needed to implement the module correctly but nothing more. An example is the use of the private keyword in Java.}
Instruction set/{An instruction set is a set of instructions that can be executed on a processor. Most instructions are further specified with additional operation-codes and arguments.}
Layered desings/{Layered design is a way to structure programming code where code belongs to a certain layer. Code can only call code that belongs to one of the layers below his own layer.}
Localized Cost/{The ability of a programming language to make programmers only pay for what they use: their are no distributed costs.}
Logic Programming/{A programming paradigm where logic is used as a purely declarative representation language and theorem proving or model generation is used as the problem-solver. A popular example is Prolog.}
LSIP/{One of the first three modern programming languages. Invented in 1958 and an abbreviation for LISt Processor.}
Machine Language/{A language consisting out of zeros and ones to represent machine instructions. Instruction include: moving data between memory and registers, perform aritmetic and do (conditional) jumps into memory.}
Manifest Interface/{The ability of a programming language to make all interfaces apparent in the syntax. For instance classes obey this, since the interface to objects is the method suite.}
Manifest typing/{Manifest typing is explicit identification by the software programmer of the type of each variable being declared. For example: if variable X is going to store integers then its type must be declared as integer. In contrast, some programming languages use inferred typing where the type is deduced from context or allow for dynamic typing in which the variable is just declared and may be assigned a value of any type at runtime.}
Meta-object protocol/{Also known as MOP. A metaobject protocol is an interpreter of the semantics of a program that is open and extensible. Therefore, a MOP determines what a program means and what its behavior is, and it is extensible in that a programmer (or metaprogrammer) can alter program behavior by extending parts of the MOP. The MOP exposes some or all internal structure of the interpreter to the programmer. The MOP may manifest as a set of classes and methods that allow a program to inspect the state of the supporting system and alter its behaviour. MOPs are implemented as object-oriented programs where all objects are metaobjects.}
Metaprogramming/{Metaprogramming is the writing of computer programs that write or manipulate other programs (or themselves) as their data, or that do part of the work at compile time that would otherwise be done at runtime. In some cases, this allows programmers to minimize the number of lines of code to express a solution (hence reducing development time), or it gives programs greater flexibility to efficiently handle new situations without recompilation. The language in which the metaprogram is written is called the metalanguage. The language of the programs that are manipulated is called the object language. The ability of a programming language to be its own metalanguage is called reflection or reflexivity.}
ML/{A programming language that supported a polymorphic type system on top of Lisp. Pioneering statically tped functional programming languages.}
Modularity/{The ability of a programming language to let programs be structured into modules breaking down programming functionality into composable units.}
Multi-paradigm programming/{A modern trend in programming languages where a language supports many paradigms by intermixing constructs from these paradigms. The programmer can choose which tools most suit the job at hand. Popular examples are Scala and F\#}
Object-oriented programming/{A programming paradigm based on using objects to design computer programs. A popular example is Ruby}
Objects/{Data structures consisting of fields and methods together}
Orthagonality/{The ability of a programming language to let independent functions be controlled by independent mechanisms.}
Plankalk\"ul/{A programming language designed by Conrad Zuse in 1943. The language supports: assignments, subroutines, conditional statements, iteration, floating point arithmetic, arrays, hierarchical record sturctures, assertions, exception handling,...}
Portability/{The ability of a programming language to avoid using faculities that are dependent on a particular computer, operating system, or a small class of computers in general.}
Pre computer languages/{Programming languages invented before their were any computer. Like for instance Jacquard's Loom, Babbage's Analytical Engine, punched cards, punched tape, lambda calculus and turing machines.}
Preservation of Information/{The ability of a programming language to allow the representation of information the user might know and the compiler might need. For example packed data structures in Pascal.}
Procedural Abstraction/{A form of abstraction where we encapsulate code into a function or method with a well defined interface. Local variables and implementation are thus hidden from outside the function.}
Programming paradigm/{A fundamental style of computer programming. Paradigms differ in the concepts and abstractions used to represent the elements of a program and the steps that compose a computation.}
Prolog/{The first logic programming language, developed in 1972.}
Regularity/{The ability of a programming language to use regular ruleswithout exceptions. These are easier to learn, describe, use and implement.}
Safety/{The ability of the programming language that no program that violates the definition of the language, or its own intended structure, should escape detection. The programmer thus cannot break language abstractions.}
Separation of Concerns/{The process of separating a computer program into distinct features that overlap in functionality as little as possible. Examples are aspect-oriented programming and layered designs}
Simplicity/{The ability of a programming language to use a minimal number of concepts, and use simply rules to combine them.}
Simula/{A programming languages invented in the early '60s. A superset of AGOL60. The first language to support the object-oriented paradigm.}
Smalltalk/{A complete ground-up design of an object-oriented language.}
Software transactional memory/{Also known as STM. Software transactional memory is a concurrency control mechanism analogous to database transactions for controlling access to shared memory in concurrent computing. It is an alternative to lock-based synchronization. A transaction in this context is a piece of code that executes a series of reads and writes to shared memory. These reads and writes logically occur at a single instance in time; intermediate states are not visible to other (successful) transactions. STM has recently been the focus of intense research and support for practical implementations is growing.}
Static typing/{A programming language is said to use static typing when type checking is performed during compile-time as opposed to run-time. Statically typed languages include ActionScript 3, Ada, C, D, Eiffel, F\#, Fortran, Go, Haskell, haXe, JADE, Java, ML, Objective-C, OCaml, Pascal, Seed7 and Scala. C++ is statically typed, aside from its run-time type information system. The C\# type system performs static-like compile-time type checking, but also includes full runtime type checking. Perl is statically typed with respect to distinguishing arrays, hashes, scalars, and subroutines. Static typing is a limited form of program verification: accordingly, it allows many type errors to be caught early in the development cycle. Static type checkers evaluate only the type information that can be determined at compile time, but are able to verify that the checked conditions hold for all possible executions of the program, which eliminates the need to repeat type checks every time the program is executed. Program execution may also be made more efficient (e.g. faster or taking reduced memory) by omitting runtime type checks and enabling other optimizations. Because they evaluate type information during compilation and therefore lack type information that is only available at run-time, static type checkers are conservative. They will reject some programs that may be well-behaved at run-time, but that cannot be statically determined to be well-typed.}
Strong typing/{a type system is said to feature strong typing when it specifies one or more restrictions on how operations involving values of different data types can be intermixed. The opposite of strong typing is weak typing.}
Structure/{The ability of a programming lanugage to let the static structure of the program correspond to the dynamic structure of the corresponding computations. For example classes versus objects.}
Syntactical extension/{A syntactic extension is a programming language contruct where a programmer can extend the syntax of a language in order to introduce new concepts and aspects.}
Syntactic Consistency/{The ability of a programming language to make simular things look simular. Furthermore different things should look different.}
Threads/{A thread of execution is the smallest sequence of programmed instructions that can be managed independently by an operating system scheduler. A thread is a light-weight process. The implementation of threads and processes differs from one operating system to another, but in most cases, a thread is contained inside a process. Multiple threads can exist within the same process and share resources such as memory, while different processes do not share these resources. In particular, the threads of a process share the latter's instructions (its code) and its context (the values that its variables reference at any given moment). On a single processor, multithreading generally occurs by time-division multiplexing (as in multitasking): the processor switches between different threads. This context switching generally happens frequently enough that the user perceives the threads or tasks as running at the same time. On a multiprocessor (including multi-core system), the threads or tasks will actually run at the same time, with each processor or core running a particular thread or task. Many modern operating systems directly support both time-sliced and multiprocessor threading with a process scheduler. The kernel of an operating system allows programmers to manipulate threads via the system call interface. Some implementations are called a kernel thread, whereas a lightweight process (LWP) is a specific type of kernel thread that shares the same state and information.}
Type system/{The mode on how a programming language deals with data-types. The following type systems are accepted standards: strong typing, weak typing, static typing, dynamic typing, duck typing, manifest typing, inferred typing.}
Weak typing/{Also known as loose typing. Weak typing is a property attributed to the type systems of some programming languages. It is the opposite of strong typing, and consequently the term weak typing has a number of different meanings, just as "strong typing" does. One of the more common definitions states that weakly typed programming languages are those that support either implicit type conversion (nearly all languages support at least one implicit type conversion), ad-hoc polymorphism (also known as overloading) or both. These less restrictive usage rules can give the impression that strict adherence to typing rules is less important than in strongly typed languages and hence that the type system is "weaker". However, such languages usually have restrictions on what programmers can do with values of a given type; thus it is possible for a weakly typed language to be type safe. Moreover, weakly typed languages may be statically typed, in which case overloading is resolved statically and type conversion operations are inserted by the compiler, or dynamically typed, in which case everything is resolved at run time. One claimed advantage of weak typing over strong typing is that it requires less effort on the part of the programmer because the compiler or interpreter implicitly performs certain kinds of conversions. However, one claimed disadvantage is that weakly typed programming systems catch fewer errors at compile time and some of these might still remain after testing has been completed. Sometimes implicit conversion occurs which will surprise unwary programmers and lead to unexpected bugs.}
Zero-One-Infinity/{The only three reasonable numbers in a programming language design.}
Object-oriented programming/{Object oriented programming is a programming paradigm based on reuse, modularity, composition and polymorphism.}
Reuse/{The ability of a programming language to organize code in that way that repetition is avoided.}
Composite/{The ability of a programming language that a user can build new abstractions from old ones and therefore delegates to these structures. Examples are inheritance, multiple inheritance and traits.}
Polymorphism/{The ability of a programming language to dispatch the same code to different method implementations. Polymorphism is dynamic and can be multi-dimensional. The different types of polymorphism are: subtype polymorphism, ad hoc polymorphism, parametric polymorphism and `incidental' polymorphism.}
Subtype polymorphism/{Also known as dynamic dispatch or method overriding. Subtype polymorphism allows a function to be written to take an object of a certain type $T$, but also work correclty if passed an object that belongs to a type $S$ that is a subtype of $T$.}
Ad hoc polymorphism/{Also known as overloaded defintions. Polymorphic functions applied to arguments of different types, but behave differently depending on the (static) type of the argument to which they are applied.}
Parametric polymorphism/{Parametric polymorphism is a form of polymorphism allowing a function or data type to be written generically so that it can handle values identically without depending on their type.}
`Incidental' polymorphism/{A form of polymorphism caused by duck typing where an object's current set of methods and properties determines the valid semantics.}
Single inheritance/{Single inheritance is a programming paradigm where methods are inherited from a single superclass. These methods may be overridden in the subclass. Furthermore a subclass can call methods from the superclass. A class is allowed to implement multiple interfaces or protocols. A typical example is Java.}
Unnatural modularisation/{Unnatural modularisation is a solution pattern to solve problems with single inheritance by pushing features into a common superclass. Since subclasses will inherit methods that don't make any sense, this is bad practice.}
Duplicate features/{Duplicate features is a solution pattern to solve problems with single inheritance by implementing the methods in two subclasses. Since both classes will impelement the same code, this will result in code duplication. Therefore it is bad pactice.}
Multiple inheritance/{Multiple inheritance is a programming paradigm in object-oriented programming where a class is allowed to have one or more parent classes. The main problems with multiple inheritance is how to handle calls to methods who are implemented by both parents or ancestors, and how we should represent the state of a object of several parents share the same ancestors. Popular solutions are repeated inheritance, virtual inheritance.}
Repeated Inheritance/{Repeated inheritance is programming paradigm in the multiple inheritance paradigm where the state of shared ancestors is duplicated. This is implemented in the Eiffel programming language.}
Unifying shared field/{a programming construct used in repeated inheritance. This construct is usefull if some parts of the duplicated state are actually the same and thus should remain consistent.}
Virtual Inheritance/{a programming paradigm in the multiple inheritance paradigm who ensures that the state of the shared ancestors is the same. This is implemented using the virtual keyword in C++.}
Diamond problem/{A formal description of a problem occuring with multiple inheritance. The problem occurs when two classses B and C have A as a common parent. A defined a method m and both A and B override this method. A class D extends both B and C. If D calls m, which method should be called? This problem is solved in different ways from not allowing this structures to occur (C++) to C3 linearisation.}
Fragile Base Class Problem/{A formal description occuring with inheritance in general. If we have want to make changes to a superclass, we are not sure if these modifications won't cause any malfunctioning in the subclasses of that class. And thus could cause a broken derived class. Solutions to this problem are mixins, monkey patching and categories.}
Decomposition problem/{A formal description of a problem occuring in single inheritance. We have two classes A and B, both classes implement methods but use the same compositions.}
Traits/{Also known as Mixins. Is a language construct in order to prevent the programmer to duplicate a lot of code and the decomposition problem. A trait is a class providing functionality to be inherited without the ability to be instatiated. A class may inherit some or all of it's functionality from one or more mixins using multiple inheritance. Traits can also bew applied sequentially. In general one can say mixins require certain functionality in order to provide additional functionality. We can subdivide traits further into static traits and dynamic traits.}
Static trait/{A trait that is inherited by a class and thus a static structure.}
Dynamic trait/{A trait that is inherited only by a single object.}
Trait with requirements/{A trait that requires certain methods in order to provide additional functionality.}
Stackable modifications/{also known as Static decorator pattern. The use of traits in order to stack modifications to a class.}
Linearisation/{A programming construct that has to decide in which modifications provided by traits are applied. In other words, if one calls a method, that is provided at multiple places, to where is the call dispatched. Furthermore if one of these methods calls the super-implementation, to where is that call dispatched? When a class is created, a linearisation of its superclasses including itself is determined, ordered from most specific to least specific. When a call is applicable to many of the superclasses, the most specific class is selected according to the linearisation. Desired properties of a linearisation are local precendence and monotonicity.}
Scala's linearisation/{A form of linearisation where we first create a list created by reading parents from right to left. In a second phase parents are removed from the list if they already occured earlier.}
Scope/{A scope is an enclosing context where values and expressions are associated. A scope defines the extent of information hiding and thus the accessibility of variables throughout a program.}
Lexical Scoping/{Also known as Static scoping. A form of scoping where a reference to a parameter is determined lexical. If the variables is not declared in the most inner scope, the compiler will look for variables with the same name in outer scopes. A popular language using lexical scoping is Java.}
Dynamic Scoping/{A form of scoping where a reference to a parameter is determined by the execution stack. If the variables doesn't exist in the most inner scope, the runtime environment will look in the execution stack for the nearest usage of a variable with the same name. A popular language using dynamic scoping was the original LISP.}
Implicit parameter/{Parameters to methods that can be omitted. In that case the compiler finds the appropriate object from the context of the method call. By implicitly threading these values through methods, a type safe alternative to dynamic scoping becomes available.}
Implicit objects/{Objects declared at the same level where implicit parameters are used in order to fill the missing parameter places.}
Legacy Class Problem/{A formal description of a problem. In the problem, a programmer is stuck with a legacy library. Since the legacy library uses other classes, we can't use the library directly. Instead of writing adapter objects who must be instantiated, one could provide implicit conversions.}
Explicit Adapter/{A design pattern. In order to make types of different libraries compatible a programmer can implement adapter classes who perform conversions between the two types.}
Implicit Conversion/{A program language construct who enables programmer to define conversions between two different types. In case the programmer calls a method with different arguments, the compiler will insert the proper conversion calls. Implicit conversions therefore also add methods from one type to another and change method argument types implicitly.}
Extension Methods/{A programming language construct where the programmer can add methods to an already defined type. The programmer can only add new methods to the type and cannot remove or overriding existing ones.}
Open Classes/{Also known as monkey patcking and duck punching. A programming language construct. Open classes allow methods to be added later. This allows better modularisation, flexibility and more reuse. Problems that might occur with open classes are conflicting updates and difficult compile-time type checking. Furthermore one could modify system and library code.}
Categories/{Categories are a programming language concept in Object C. Categories can add new methyods to an existing class by writing a modified interface file and class file.}
Dispatching/{Dispatching deals with which method receives the call when several methods share the same name. Popular dimensions of dispatching are static dispatching, dynamic dispatching, single dispatching, multiple dispatching and implicit dispatching.}
Static dispatching/{A dispatching method based on the static type of the calling object.}
Dynamic dispatching/{Also known as dynamic binding. Dynamic dispatch is the process of mapping a message to a specific sequence of code (method) at runtime. This is done to support the cases where the appropriate method can't be determined at compile-time (i.e., statically). Dynamic dispatch is only used for code invocation and not for other binding processes (such as for global variables) and the name is normally only used to describe a language feature where a runtime decision is required to determine which code to invoke. This object-oriented feature allows substituting a particular implementation using the same interface, and therefore it enables polymorphism.}
Single dispatching/{A dispatching method based on the target of the method. Java uses this form of dispatching. A problem with Single dispatching is to ensure that the type of the parameter is correct (since the method can be overloaded, the type of the parameter can be to general).}
Multiple dispatching/{Also called run-time polymporphism and multimethods. The dipatching depends on the types of all arguments. Potential problems of multiple dispatching are ambiguity, inheritance and missing methods. Multiple dispatching is implemented in Clojure, CLOS, Dylan, Cecil,... Most of the problems are solved by preference: a set of priority rules called dispatching resolution policy to determine which method should be called in case of ambiguity.}
Dispatch resolution policy/{A set of rules to determine which method should be called in case of ambiguity in the multiple dispatching paradigm. Popular policies are match left-to-right, match right-to-left or programmer-specified.}
Implicit dispatching/{Dispatching based on the context and objects in it. This is popular in context-oriented programming.}
Double Dispatch/{A solution pattern for problems with single dispatching. Since the compiler doesn't know the type of the parameter at runtime the class provides a general method, who redirects the call to the parameter itself and includes itself as parameter of the last call. Since an object knows it's own type. This can be calculated at runtime. The problem with double dispatching is that it requires a lot of work together with code duplication. Extensions to triple dispatch,... don't seem to solve the problem.}
Generics/{A programming paradigm where one is allowed to use a type as a parameter in order to make other programming structures more general. Benefits incluse type safety, and better reuse of code. Generics has some problems with subtyping since it's not always clear that a the same template class but different type parameters have an inheritance relation. This problem can be solved by Variance.}
C++ Templates/{A programming language construct where code is generated by macro expansion. This code is generated in a precompiler step. Therefore typechecking can be performed after the code is generated. In C++ the template language is Turing complete.}
Java Generics/{An implementation of the generics concepts in Java. Java allows to pass a type as parameter. We make a distinction between unbounded polymorphism, bounded polymorphism and F-bounded polymorphism.}
Unbounded polymorphism/{Also called Parameteric polymorphism. Unbounded polymorphism is a form of generics where we don't place any constraints on the type provided by the type parameter.}
Bounded polymorphism/{A form of generics where we place constraints on which types can be used. Constraints include upper bounds and in some (rare) cases lower-bounds.}
F-bounded polymorphism/{Also known as F-bounded quantification or recursive bounded quantification. A form of generics where the subtype constraint itself is parameterized by one of the binders occuring on the left hand side.}
Variance/{Variance is a way to specify that two objects of the same template class but with different type parameters have an inheritance relationship. Popular alternatives of variance are covariance, contravariance and invariance.}
Covariance/{A programming language construct where a programmer specifies that if two classes with the same template class, but where the type parameter of the first class is a subclass of the type parameter of the second class, the first class is a subclass of the second class.}
Contravariance/{A programming language construct where a programmer specifies that if two classes with the same template class, but where the type parameter of the first class is a subclass of the type parameter of the second class, the second class is a subclass of the first class.}
Invariant/{Also known as rigid. A programming language construct where a programmer specifies that two classes with the same template class, but with a different type parameter, have no subclass relationship.}
Abstract Type Members/{A programming language concept in generics where objects can have fields with types who depend on the type parameter of that class.}
Pattern matching/{An activity where we match and (optionally) deconstruct data. Special forms of pattern matching include case analysis, string matching, tree matching,...}
Algebraic Data Types/{Also known as ADTs. A type made up of tagged choices.}
Algebraic Data Types Pattern Matching/{Also known as ADT Pattern Matching or ADT Matching. A process where we match an abstract data type with a definition of a pattern.}
Wildcard patterns/{A wildcard pattern matches everything. It can be nested within other patterns and is often used as a catch-all clause since patterns are tested top-to-bottom.}
Constant pattern/{A constant pattern matches only itself. It can be nested within other patterns and is often used to define the structure of the data. If the data itself can be subclassed it is of course possible that the constant pattern matches more than just the object described.}
Variable patterns/{A variable pattern matches a certain object and binds this object to a variable.}
Constructor patterns/{Constructor patterns allow the programmer to define some structure in how the data is represented and how the values shoud be bounded. Deep matches are therefore supported and are useful in compiler transformations.}
Sequence patterns/{Sequence patterns match any number of elements within a sequence (list or array), including zero elements. They can only be used as the last element of a pattern.}
Tuple patterns/{A pattern allowing the programmer to match tuples. This means each item in the tuple should be matched.}
Typed patterns/{A convenient replacement for type tests and type casts. The match performs the type test. The resulting type is associated with the variable.}
Pattern guards/{Patterns guards are a serie of if-then-else cases who can refine patterns (if the expression power of the pattern language lacks support).}
Extensible patterns/{Extensible patterns are patterns that consist of several patterns together with some operator. An example is the orElse operator in Scala. The patterns succeeds if one of the patterns succeeds. In that case the first binding in the list is used.}
Regular Expression/{Also known as regexp or regex. Key concepts of regular expressions include greedy patterns, back references, passive groups, pattern modifiers and look arounds. Regular expressions consist out of non-special characters matching themselves, dots (.) matching any single character, sequences of characters, grouping, the Kleene-closure and the logical or. Popular linux programs that use regular expression include grep and sed.}
Anchors/{Anchors are an extension on Regular Expressions. The set of features include character to mark the begin or end of the line, string and word. None of these anchors consume any characters of the string to match.}
Character Classes/{Character classes are an extension on regular expressions. They include a set of characters groups like control characters, digits and words.}
Quantifiers/{Quantifiers are an extension on regular expressions to be more precise about the number of repetitions and wether or not a group should be greedy.}
Ranges/{Ranges are an extension of regular expressions where a programmer specifies a group of characters by specifying the first and list element of the sequence. Ranges are inclusive the bounds.}
Assertions/{Assertions are an extension on regular expressions in order to perform some test in forward or reverse direction. Consuming none of the characters in the string. These tests include the lookahead assertion, negative lookahead,...}
Pattern modifiers/{Pattern modifiers are an extension on regular expressions in order to change the context of the pattern match. These modifiers include global match, case-insensitive, multiple lines, treat as single line, allow comments and white space in pattern and ungreedy pattern.}
Binding variables/{Binding variables are an extension on regular expressions where the string is not only matched against the pattern. If the matching succeeds some variables will hold substrings extracted from the string. How these substrings are extracted is specified in the extended regular expression.}
String replacement/{Also known as Back references. String replacement is an extension on regular expressions where some parts of a string matched by the regular expression are replaced by other substrings. In some cases these substrings are the result of binding variables.}
Extensible Markup Language/{Also known as XML. It is a tree-based representation of data. The data is represented by constructs like tags, attributes and values.}
Extensible Markup Language Processing/{Also known as XML Processing. A process where an XML stream is matched by a certain XML pattern and rewritten into another XML file. A popular way to do this is using Extensible Stylesheet Language Transformations (XSLT).}
XPath/{A language to express XML patterns. The language consists out of nodenames, slashes to select children and dots to select current or parent nodes. The at is used to select attributes. Furthermore the language allows to add predicates to the items in order to match them.}
Tree Matching/{Tree matching is a form of pattern matching where we match an object structured as a tree by a pattern. A popular way to do tree matching is using Extensible Stylesheet Language Transformations (XSLT) where trees are represented in XML and an XSLT program converts data from one XML file into another.}
Extensible Stylesheet Language Transformations/{Also known as XSLT. It is a programming language syntactically embedded in XML that specifies how we can translate one XML document into another by extracting values from the source.}
Monads/{Monads are a programming language construct in functional programming. Monads offer a uniform way of dealing with computational effects (IO). It adds impure features but in a highly structured way. Monads are type classes since they only provide an interface. Monads must statisfy three laws: right unit \texttt{(m >>= return = m)}, left unit \texttt{(return x >>= f = f x)} and associativity \texttt{(m >>= f) >>= g = m >>= (\textbackslash x -> f x >>= g)}. Popular monads in Haskell include: Maybe, IO, List, Exception, Parser, State, Continuation and Environment.}
IO Monad/{The IO monad is a primitive monad in Haskell for input-out of data. The Monad provides print, getLine, writeFile and readFile functions and can be seen as an imperative sub-language.}
State Monad/{State monad is a state monad holding a specific state. Each time a transition is made (the shift operator), a value is returned and the state is updated. The monad provides three basic functions. runSM, readSM and updateSM.}
Maybe Monad/{The maybe monad is a monad in order to handle exceptions. A maybe monad provides two functions, return who converts a result in its monad-encapsulated equivalent. The shift function performs a function on the value of the monad(in case the monad holds a value). Other provided functions include fail (in order to return Nothing).}
Type classes/{A type class is a type system construct that supports ad-hoc polymorphism. Therefore polymorphic functions behave differently with different type arguments. Their is a relation between type classes in Haskell and overloading in object-oriented programming languages. Type classes contain function signatures who specify which functions should be implemented for some type in order to be part of the type class. Haskell has a lot of built-in type classes. Some of them can automatically be derived.}
Superclasses/{Superclasses is a programming language construct in type classes where one type class requires the data to be part of another type class. In that case the second typeclass is the superclass of the first one.}
Do-notation/{The do-notation is syntactical sugar for the maybe monad.}
Laziness/{A programming paradigm where expressions are only evaluated when they are realy needed in order to solve the problem. Since IO requires a strict ordening of instructions, this can result into problems. In order to solve these problems lazy languages need a system to force computations single-threaded.}
Monad Transformers/{Monad transformers are a programming language construct in monads. Where monads are combined. A problem with combining monads is that some monads are not compatible to others. Furthermore the order in which computations are executed is not straight forward. Monads are thus combinated in a certain order. To avoid having to write each combination, monad transformers thus provide a function lift that converts computation phrased in terms of one monad into another one.}
Continuations/{An abstract representation of control state of a computer program, reified as a first class entity. Continuations are useful for encoding other control mechanisms in programming languages such as exceptions, generators, coroutines, and so on. The current continuation represents the rest of a computation at a given point during a computation. Continuation enables programmer to create new control operators, without continuations a whole program transformation into continuation-passing style is required to get the desired effect.}
Asynchronous JavaScript And XML/{Also known as AJAX. A web programming technique wich uses an XMLHttpRequest object in JavaScript to fetch data asynchronously from a server. When the data arrives, computation is resumed. Therefore AJAX uses a form of continuation.}
Continuation-passing style/{Also known as CPS. A programming style where a function computes a step and then returns a continuation. Continuation-passing style is safer than recursive calls since the stack doesn't increment.}
Continuation-passing style transformation/{Also known as CPS Transformation. A transformation turing a recursive calls into a continuation-passing style.}
Lambda Calculus/{A formal computational model, where expressions containing terms, values and reduction contexts are rewritten using the beta-reduction rule.}
Co-operative Threads/{Also known as coroutines. In cooperative threading, a thread must yield control manually, i.e. programmer issues yield instructions. It will not be preemptively switched out. A potential problem with co-operative threads is the risk of starvation if the thread doesn't yield. Constructs to make coroutines possible include spawn, quit, yield, start-threads and halt.}
Dynamic language/{A dynamic programming language is a programming language without static typing in order to make the language very extensible. Errors are detected as late as possible. Furthermore code can be threated as data and data can be threated as code. Advantages of dynamic typing are whip-up abilities, flexibility, abstraction levels, high expressiveness, garbage collection, high-level syntax. Problems with dynamic languages are that the language is unsafer, more hackable, performance and bad readability.}
Read-Eval-Print Loop/{Also known as REPL. Is a concept in programming languages where the user has the ability to input programs into an interactive console. The console reads the input, evaluates the commands and prints the results. This enables rapid prototyping and exploration.}
Meta-programming/{A programming language construct that enables the programmers to create their own language.}
Language-oriented programming/{A programming language paradigm where a programmer mainly programs a language in order to solve problems.}
Macros/{Also known as Compile-time Meta-programming. Macros are expressions in a programming language in who are executed at compile time in order to modify the source code. Therefore macros offer syntactical shortcut. They don't evaluate their arguments but simply transform their input. Furthermore macro's cannot access runtime information. Macros are used to change the syntax of the language and are therefore useful for developing domain specific languages.}
Quote/{A quote is a language structure in LISP languages. Quotes prevent arguments from being evaluated. Therefore the eval-function can for instance evaluate lists as if they were code.}
Backquote/{A backquote is a language structure in LISP languages. Backquotes in a macro make it possible to build lists from templates. Like regular quotes, backquotes alone protect its arguments from evaluation. Withing a backquoted expression, you can use comma (,) and comma-at (,@) to turn evaluation back on.}
Comma-at/{Comma-at is a language structure in LISP languages. Comma-at has the same semantics as the comma structure but splices its arguments (which should be a list). It is useful in macros that have so called rest parameters representing a body of code.}
Gensym/{Gensym is a language structure in LISP languages. Gensym can be used by macros in order to generate globally unique names who are safe for variable capture.}
Run-time meta-programming/{Run-time meta-programming is a programming language construct where code writes code. Therefore the written code can manipulate the language constructs at run-time.}
Introspection/{A programming language construct where mete-data about run-time structures is kept. The programmer can for instance retrieve a list of available methods.}
Reflection/{reflection is the ability of a computer program to examine (see type introspection) and modify the structure and behavior (specifically the values, meta-data, properties and functions) of an object at runtime. Reflection is most commonly used in high-level virtual machine programming languages like Smalltalk and scripting languages and also in manifestly typed or statically typed programming languages such as Java, ML, Haskell and C\#.}
Reification/{Reification is a programming language construct where the program is able to inspect for instance the run-time stack, class definitions and the dispatch algorithm.}
Meta-object protocol/{A meta-object protocol is programming language construct where an open and extensible interpreter is used for other or new language constructs.}
Singleton classes/{Also known as Eigenclass. Singleton classes is a programming language construct where we can add and modify methods for a specific instance. These methods are stored into a singleton class associated with the object (also called its eigenclass). Singleton classes are used for test mocking. Singelton classes should not be confused with the singleton pattern. Singleton classes are anonymous and cannot be instantiated.}
Test mocking/{Test mocking is a technique used to test programs. In each test we use a singleton class where we modify some behavior in order to see wether the program reacts to the modified version correctly.}
Concurrent programming/{Concurrent programming is a programming paradigm where code is executed on several cores or machines simultaniously. The unit of a concurrent program is a computational thread. The main challenges in designing concurrent programs are ensuring the correct sequencing of the interactions or communications between different computational threads, and the coordinating access to resources that are shared among threads. Problems arising with concurrent programming are deadlock, livelock, race condition, resource starvation and mutual execlusion}
Parallel programming/{Parallel programming is a programming paradigm where we want to speed up the execution of an algorithm by sharing the computational load over different machines or cores. Each thread has their own resources.}
Computational thread/{Also known as thread. A computational thread is the unit of a concurrently executed program. Each thread executes a part of the code. In most cases thread have to interact. Each thread has its own local stack and variables. Global variables are maintained by the thread context.}
Multicore/{A unit of processing power. Today almost every available machine has more than one processing core.}
Virtal thread/{A way of multithreading where a processors swaps between two threads after each instructions. The advantage of this is that the different execution states (registers, state flags,...) are hardware supported instead of software.}
Deadlock/{Deadlock is a problem that arises with concurrency where two or more threads are waiting for each other. Since each process is waiting on another one, there will be no process.}
Livelock/{Livelock is a problem that arises with concurrency. A livelock is similar to a deadlock, except that the states of the processes involved in the livelock constantly change with regard to one another, none progressing. Livelock is a special case of resource starvation; the general definition only states that a specific process is not progressing.}
Race conditions/{Race conditions is a problem that arises with concurrency where two or more threads execute a piece of code where processes access the same (global) variables. Since some processes modify these variables, some threads can read variables in a corrupt state. Furthermore write statements can interleave and thus leave objects in a corrupt state.}
Resource starvation/{Resource starvation is a problem that arises with concurrency where one or more threads never reach the required conditions to resume execution.}
Mutual exclution/{Also known as the readers-writers problem is a problem where some part of the code can only be executed by one thread at a time.}
Concurrency control mechanisms/{Concurrency control mechanisms are programming language constructs to resolve problems that arise with concurrency. Popular concurrency control mechanisms are locks, condtion variables, semaphores, critical sections, fork-joins, barrier synchronisation, monitors, rendezvous, message passing, tuple space and lock-free synchronisation.}
Locks/{Locks are a concurrency control mechanism. A lock is a synchronization mechanism for enforcing limits on access to a resource in an environment where there are many threads of execution. A lock is designed to enforce a mutual exclusion concurrency control policy. Generally, locks are advisory locks, where each thread cooperates by acquiring the lock before accessing the corresponding data. Some systems also implement mandatory locks, where attempting unauthorized access to a locked resource will force an exception in the entity attempting to make the access. A (binary) semaphore is the simplest type of lock. In terms of access to the data, no distinction is made between shared (read only) or exclusive (read and write) modes. Other schemes provide for a shared mode, where several threads can acquire a shared lock for read-only access to the data. Other modes such as exclusive, intend-to-exclude and intend-to-upgrade are also widely implemented.}
Condition variables/{Condition variables are a concurrency control mechanism. Conceptually a condition variable is a queue of threads, associated with a monitor, on which a thread may wait for some condition to become true. Thus each condition variable $c$ is associated with an assertion $P_c$. While a thread is waiting on a condition variable, that thread is not considered to occupy the monitor, and so other threads may enter the monitor to change the monitor's state. In most types of monitors, these other threads may signal the condition variable c to indicate that assertion $P_c$ is true in the current state. Thus there are two main operations on condition variables: wait $c$ is called by a thread that needs to wait until the assertion $P_c$ is true before proceeding. While the thread is waiting, it does not occupy the monitor. And signal $c$ (sometimes written as notify $c$) is called by a thread to indicate that the assertion $P_c$ is true.}
Semaphores/{Semaphores are a concurrency control mechanism.  A semaphore is a variable or abstract data type that provides a simple but useful abstraction for controlling access by multiple processes to a common resource in a parallel programming or multi user environment. A useful way to think of a semaphore is as a record of how many units of a particular resource are available, coupled with operations to safely (i.e., without race conditions) adjust that record as units are required or become free, and if necessary wait until a unit of the resource becomes available. Semaphores are a useful tool in the prevention of race conditions; however, their use is by no means a guarantee that a program is free from these problems. Semaphores which allow an arbitrary resource count are called counting semaphores, while semaphores which are restricted to the values 0 and 1 (or locked and unlocked, unavailable andavailable) are called binary semaphores (same functionality that mutexes have).}
Critical sections/{Also known as atomic blocks. Critical sections are a concurrency control mechanism. A critical section is a piece of code that accesses a shared resource (data structure or device) that must not be concurrently accessed by more than one thread of execution. A critical section will usually terminate in fixed time, and a thread, task, or process will have to wait a fixed time to enter it (aka bounded waiting). Some synchronization mechanism is required at the entry and exit of the critical section to ensure exclusive use, for example a semaphore. By carefully controlling which variables are modified inside and outside the critical section, concurrent access to that state is prevented. A critical section is typically used when a multithreaded program must update multiple related variables without a separate thread making conflicting changes to that data. In a related situation, a critical section may be used to ensure a shared resource, for example a printer, can only be accessed by one process at a time.}
Fork-joins/{Fork-joins are a concurrency control mechanism. On arrival at the fork point, a job is split into $N$ sub-jobs which are served by each of the $N$ servers. After service, sub-job wait until all other sub-jobs have also been processed. The sub-jobs are then rejoined and leave the system.}
Barrier synchronisation/{Barrier synchronisation is a concurrency control mechanism. A barrier for a group of threads or processes in the source code means any thread or process must stop at this point and cannot proceed until all other threads or processes reach this barrier.}
Monitors/{A monitor is a concurrency control mechanism, an object or module intended to be used safely by more than one thread. The defining characteristic of a monitor is that its methods are executed with mutual exclusion. That is, at each point in time, at most one thread may be executing any of its methods. This mutual exclusion greatly simplifies reasoning about the implementation of monitors compared to reasoning about parallel code that updates a data structure. Monitors also provide a mechanism for threads to temporarily give up exclusive access, in order to wait for some condition to be met, before regaining exclusive access and resuming their task. Monitors also have a mechanism for signaling other threads that such conditions have been met.}
Rendezvous/{Rendezvous is a concurrency control mechanism implemented in Ada. It is a system call that allows two processes to exchange a single datum while synchronizing. The rendezvous call takes a tag and a value as its arguments. The tag is typically an address in memory shared by both processes. Calling rendezvous causes a process to sleep until a second rendezvous call with a matching tag occurs. Then, the values are exchanged and both processes are awakened.}
Message Passing/{Message passing is a concurrency control mechanism. Message passing is a form of communication used in parallel computing, object-oriented programming, and interprocess communication. In this model, processes or objects can send and receive messages (comprising zero or more bytes, complex data structures, or even segments of code) to other processes. By waiting for messages, processes can also synchronize. Message passing is the paradigm of communication where messages are sent from a sender to one or more recipients. Forms of messages include (remote) method invocation, signals, and data packets. Prominent theoretical foundations of concurrent computation, such as the Actor model and the process calculi are based on message passing. Implementations of concurrent systems that use message passing can either have message passing as an integral part of the language, or as a series of library calls from the language. Examples of the former include many distributed object systems. Examples of the latter include Microkernel operating systems that pass messages between one kernel and one or more server blocks, and the Message Passing Interface used in high-performance computing.}
Tuple spaces/{Tuple spaces are a concurrency control mechanism. A tuple space is an implementation of the associative memory paradigm for parallel or distributed computing. It provides a repository of tuples that can be accessed concurrently. As an illustrative example, consider that there are a group of processors that produce pieces of data and a group of processors that use the data. Producers post their data as tuples in the space, and the consumers then retrieve data from the space that match a certain pattern. This is also known as the blackboard metaphor. Tuple space may be thought as a form of distributed shared memory.}
Lock-free/{Also known as wait-free. Lock-free is a concurrency control mechanism. A non-blocking algorithm ensures that threads competing for a shared resource do not have their execution indefinitely postponed by mutual exclusion. A non-blocking algorithm is lock-free if there is guaranteed system-wide progress; wait-free if there is also guaranteed per-thread progress. The traditional approach to multi-threaded programming is to use locks to synchronize access to shared resources. Synchronization primitives such as mutexes, semaphores, and critical sections are all mechanisms by which a programmer can ensure that certain sections of code do not execute concurrently if doing so would corrupt shared memory structures. If one thread attempts to acquire a lock that is already held by another thread, the thread will block until the lock is free. Blocking a thread is undesirable for many reasons. An obvious reason is that while the thread is blocked, it cannot accomplish anything. If the blocked thread is performing a high-priority or real-time task, it is highly undesirable to halt its progress. Other problems are less obvious. Certain interactions between locks can lead to error conditions such as deadlock, livelock, and priority inversion. Using locks also involves a trade-off between coarse-grained locking, which can significantly reduce opportunities for parallelism, and fine-grained locking, which requires more careful design, increases locking overhead and is more prone to bugs. Non-blocking algorithms are also safe for use in interrupt handlers: even though the preempted thread cannot be resumed, progress is still possible without it. In contrast, global data structures protected by mutual exclusion cannot safely be accessed in a handler, as the preempted thread may be the one holding the lock.}
Shared memory/{Shared memory is a form of memory organisation where each processor has access to a global memory space.}
Distributed memory/{Distributed memory is a form of memory organisation where each processor has his own local memory space. A processor can access the memory space of another processor by message passing.}
Actor-based concurrency/{Is a programming paradigm where actors each have a local state and pass messages through each other in order to cooperate.}
Actors/{Actors are the universal primitives in the actor-based concurrency model. An actor is a single thread of control together with a mailbox (queue). An actor pulls a message from the queue and acts upon it. In response to a message it receives, an actor can make local decisions, create more actors, send more messages and determine how to respond to the next message received. Their is no shared state among actors.}
Erlang/{Erlang is a programming language designed for concurrent, distributed and fault-tolerant applications. Erlang is based on actors and can support millions of threads. It employs the ''Let it crash'' philosophy and is dynamically typed.}
State machine/{A state machine is a paradigm where a program is in a certain state. Certain events can change the state of the program and activate certain behavior. State machines are well used in concurrent applications in order to support some protocol.}
Timeout/{Timeouts are a programming language construct where the program only waits for a certain time for an event to happen, if the event doesn't happen in this time span, the execution is resumed. Timeouts are well used on concurrent applications in order to prevent deadlocks.}
Interrupt/{An interrupt is a programming language construct where execution of a program is suspended in order to react on an important event that causes the interrupt. After the interrupt is handled, normal execution is resumed. Interrupts are well used in concurrent applications.}
Linked processes/{Linked processes is a programming language constructs where different threads can monitor each other's behaviour. This behaviour is described in terms of thread links and exit signals. This is done by setting up bidirectional links. When a process terminates, it will send exit signals to the linked processes to inform them of this termination together with the reason why the process has been terminated. In most cases default behavior to exit signals is to fail as well and thus propagate the exit signal further. Of course this behaviour can be overridden. Erlang is programming language who works with this concept.}
Immutable messages/{Immutable messages are messages who can't be modified once they're created, nor by the sender or receiver. Using immutable messages avoids problems with mutable updates and synchronisation from many actors.}
Self-contained messages/{Self contained messages are messages where the meaning doesn't depend on other messages. Using self-containing message avoids context problems in order to interpret responses when this message doesn't come immediately.}
Domain specific language/{A computer language of limited expressiveness focused on a particular domain. A domain specific language has limited concepts in order to lead to better developer productivity and communication with domain experts.. Therefore domain specific languages are designed to bridge the gap between the problem domain and the solution domain. Examples of domain specific languages can be found in querying, language processors, graph layout, document layout, web, hand-held devices, spreadsheets, games, modelling, text processing, hardware, symbolic computations, music,... Domain specific languages provide abastractions, concrete syntax, optimisation, error checking and tool support.}
Make/{Make is a linux program designed to specify a dependency network in order to deploy software on a computer.}
High-level programming languages/{High level programming languages are programming language who help to reduce the gap between the problem domain and the solution domain (the machine).}
Domain specific language lifecycle/{Also known as the DSL lifecycle. The steps needed to in order to develop a domain specific language. The different steps are decision, domain analysis, design, implementation, deployment and maintenance. It's an iterative process where common patterns are incremmentally abstracted in order to mitigate the risk of failure.}
Decision/{Decision is a stem in the domain specific language lifecycle where we decide if we will invest in a new domain specific language. If the domain is fresh and little knowledge is available, it doesn't make sense to develop a domain specific language. In order to determine wether or not we will built a domain specific language, we will need to perform a regular software engineering process where we build a code base and supporting libraries. This step requires a deep understanding of the domain.}
Domain engineering/{Domain engineering is the activity of collecting, organising and storing past experience in building systems or parts of systems in a particular domain in the form of reusable assets, as well as providing an adequate means for reusing these assets when building a new system.}
Domain analysis/{Domain analysis is a step in the domain specific language lifecycle where we identify the problem domain and gather domain knowledge. In this step, one has to produce a domain definition defining the scope of the domain, a domain terminology, a description of the domain concepts and models describing the commonalities and variabilities of domain concepts and their independencies. This results in a meta-model which gives the abstract structure of the language.}
Variabilities/{Elements that should be specified in the domain specific language.}
Commonalities/{Elements of the problem domain who are that common that the domain specific language doesn't has to specify them. Commonalities are used to define a domain framework or an execution engine.}
Meta-model/{A meta-model is a simplification of a system. Therefore it includes abstractions, descriptions, specifications and information. A meta-model facilitates communcation between domain experts and developers and among developers. Meta-models need to be refined until they can adequately represent domain constructs.}
Deductive design/{Also known as top-down design is a way to design things were first the problem domain is analysed, then the elements are identified and in a later stage the details are filled in. The risk of this strategy is that implementing the design can turn out to be hard.}
Inductive design/{Also known as bottom-up design is a way to design things were first small code samples are implemented, these code samples are grouped together into more abstract elements until the design is acceptable. The risk of this stragegy is that the designed level is too low level.}
Piggybacking/{Piggy backing is a general technique where one takes advantage of already existing systems in order to implement a new system.}
Specialisation/{Specialisation is a strategy that can be applied when designing a domain specific language where an existing language is restricted.}
Extension/{Extension is a strategy that can be applied when designing a domain specific language where an existing language is extended with new features.}
Semantic model/{The semantic model of a domain specific language is the library or framework the domain specific language populates. The validation of correct input occurs here. A semantical model should have two interfaces: an operation interface used by clients and thus the main application and a population interface used by the domain specific language to create instances.}
Operation interface/{An operation interface is one of the two interfaces of a semantic model. It is used by the clients, that is, the main application.}
Population interface/{A population interface is one of the two interfaces of a semantical model. It is used by the domain specific language in order to create instances.}
Decision table/{A decision table is a way to implement the semantical model of a domain specific language. In a decision table, the domain specific language consits of a table defining a set of rules and thus conditions and consequences, built in priority.}
Production rule system/{A production rule system is a way to implement a domain specific language. In a production rule system logic is divided up into a set of rules thus a condition plus consequence action.}
State machine/{A state machine is a possible way to implement a domain specific language. In a state machine events trigger behavior and state changes.}
Dependency network/{A dependency network is a way to implement a domain specific language. In a dependency network tasks are specified with dependencies of tasks that need to precede them. Tasks are executed only once.}
Adaptive model/{An adaptive model arranges blocks of codes in a datastructure in order to implement an alternative model of computation. This is useful when the model takes a primary behavrioural role in the system. Adaptive models define a model where the links between elements represent the behavioural relationships of the computational model. The model can run by either executing code over it or by executing code within the model itself.}
Internal domain specific language/{Also known as embedded domain specific language. An internal domain specific language is a domain specific language who uses a host language in order to execute the commands. The advantage of an internal domain specific language is that the domain specific language will include certain features of the host language and thus makes it easier to learn the language. The downslide of an internal domain specific language is a potential lack of portability, less domain specific errors, analysis and optimisations and less freedom in designing the domain specific language.}
External domain specific language/{An external domain specific language is a domain specific language that is self-contained: it doesn't use a host language and is implemented with a compiler or interpreter. The advantage of an external domain specific language is that the language is more dedicated to the domain and one can perform domain specific analysis and optimisations. The downside of a external domain specific language is the cost of learning and maintaining the new language.}
Interpreter/{An interpreter is a program that can read code written in a specific programming language and execute that code directly.}
Compiler/{Also known as Application generator. A compiler is a program that translates code in a specific programming language into code in another programming language. In some cases that code is machine code. In other cases the code is easier to understand by a machine (like Java byte code).}
Preprocessor/{A preprocessors is a program that translates code in a specific programming language into code of another programming language. Another compiler or interpreter can then compile or run this code. The statical analysis is therefore limited by the analysis done by the compiler or interpreter.}
Embedding/{Embedding is a technique used to design a domain specific programming language where a programmer takes advantage of the programming language constructs in order to slightly modify the program's syntax (for instance by making methods publicly available). The domain specific code is than enhanced with other code in order to write executable programming code.}
Extensible compiler/{An extensible compiler is a compiler who can be extended with domain-specific optimization rules and domain-specific code generation. Extensible compilers are quite rare and hard to master.}
Extensible interpreters/{An extensible interpreter is an interpreter who can be extended with domain specific optimization rules and domain-spicific executions. Most interpreters are relatively easy to extend.}
Linguistic abstraction/{Linguistic abstraction means identifying recurring patterns and making abstraction of them by providing specific syntax. Especially when the pattern is not linguistically expressible in the original syntax. It is one of the strategies in order to design a domain specific language.}
Tree construction/{Tree construction is a process done by a parser where code in the domain specific language is converted into a abstract syntax tree.}
Method chaining/{Method chaining is a technique in programming where method who modify the object return the active object in order to call more methods on the same object in the same line. By using method chaining expression become much shorter and one can eliminate variables.}
Expression builder/{An expression builder is aobject or family of object s that provides a fluent interface over a normal command-query API. Expression builders are somtimes used in the implementation of domain specific languages in order to make the code in the domain specific language much shorter.}
Nested functions/{Nested functions is a programming language construct where we compose functions by nesting function calls as arguments of other calls. Nested functions are sometimes used for the implementation of domain specific langauges in order to make the code in the domain specific language shorter.}
Object scoping/{Object scoping is a technique used in the implementation of a domain specific langauge where the domain specific language script is placed in existing code so that bare references will resolve to a single object.}
Literal lists/{Literal lists are a technique used to implement a domain specific language where we represent the language expression with a literal list.}
Literal maps/{Literal maps are a technique used to implement a domain specific language where we represent the language expression as a literal map.}
Dynamic reception/{Dynamic reception is a technique used to implement a domain specific language where we handle messages without defining them in the receive class. We simply override the \texttt{method\_missing} class of ruby in order to make the language more extensible.}
Code genration/{Code generation is the last step in a compiler where code in the target language is generated based on an internal representation. There are different techniques for code genration. Popular ones include: print statements, string composition, template engines and string interpolation.}
Print statements/{Print statements is a code generation technique where code is generated by a series of console prints. The advantages of print statements are that it is very accessible and concrete syntax and it is a very optimized way to do this. The disadvantage is that the order of evaluation will determine the resuling code and there is no formatting or syntax check}
Composing strings/{Composing strings is a code generation technique where strings where the resulting code is generated by creating a string who is the result of several concatenations and conversions. The advantage of composing strings is that we use concrete syntax. The downside of composing strings is that we don't perform any syntax checks. Furthermore composing strings may suffer from escape characters who can hack the program.}
Template engine/{A template engine is a code generation technique where code is generated by a list of templates where variables are filled in. The advantage is that we still work with concrete syntax and can use this to generate long code fragments. The downside of a template engine is that there is no syntax check and no general structure.}
String interpolation/{String interpolation is a code generation technique where we create a string where target code is as plain text and parameters are interpolated. The advantages of string interpolation are concrete syntax, the ability to generate long code fragments, the ability to prevent escape characters. A disadvantae of string interpolation is that one cannot perform syntax checking.}
Composing AST/{Composing abstract trees is a code generation technique where we built an abstract syntax tree directly. We can feed this abstract syntax tree back into the compiler for checking, bytecode generation and direct execution. The advantages of composing AST are syntax checking through the type system, automatic formatting and the ability to transform code after generation. The main disadvantage of composing AST is that their is no concrete syntax.}
Concrete object Syntax/{Concrete object syntax is a code generation technique where we specify which commands should be executed in a certain context. The user can write natural code using string interpolation and pass the result to the compiler in order to perform transformations. The main disadvantage of this technique is that this is currently an experimental feature and support is not widly provided.}
Linguistic abstract/{Linguistic abstract is a construct in a domain specific language where an expression in the domain specific language is actually a representation for (probably longer) target language code.}
Language cacophony/{Language cacophony is a problem that arises with domain specific languages. Since domain specific language have a specific syntax, it makes it harder to work on the system and introduce new people to the project.}
Ghetto language/{Ghetto language is a problem that arises with domain specific languages. It occurs when a company builds a lot of its systems using an in-house language. Since it is hard to find new staff and keep up with the technological changes, the language can become to limited to fit modern needs.}
Blinkering abstraction/{Blinkering abstraction is a problem that might arise with maintaining a domain specific language. Sometimes more effort is spent in fitting the world into the provided abstractions, rather than the other way around. Therefore the balance of implementing a domain specific language can become negative.}
