\chapter{Approximation algorithms}
\chplab{approx}

\section{Introduction}
Instances of \concepts{combinatorial optimization problem} cannot always be solved to optimality within a reasonable amount of computing time. Indeed, some combinatorial problems are so-called \concept{NP-hard} (e.g. \concept[knapsack problem]{knapsack}, \concept[stable set problem]{stable set}, \concept[node cover problem]{node cover}) which implies that the best-known algorithms that guarantee an optimal solution have an \concept{enumerative character} (like the \concept{branch-and-price} approach).

\paragraph{}
This chapter deals with \concepts{approximation algorithm}. These are algorithms that return a \concept{feasible solution} fast (i.e. within \concept{polynomial time}), but sacrifice the \concept{guarantee of optimality}. Thus, whereas \concepts{branch-and-price algorithm} always output an \concept{optimum solution} at the expense of potentially enormous computing times, \concepts{approximation algorithm} form a \concept{dual approach} to solving \concepts{combinatorial optimization problem}. An \concept{approximation algorithm} guarantees a fast solution, but not necessarily an optimal one. Of course,
one still wants an \concept{approximation algorithm} to produce solutions that have a value that does not differ too much from the \concept{optimum value}. In order to be able to judge approximation algorithms, the concept of \concept{worst case analysis} is discussed in \secref{worstcase}. Further, we presents \concept{approximation algorithm} for two specific problems, namely \concept[node cover problem]{node cover} (\secref{nodecoverapprox}) and the \concept{traveling salesman problem} (\secref{tspapprox}).

\section{Worst case analysis}
\seclab{worstcase}

The \concept{worst case ratio} (WCR) of an algorithm $A$ for a \concept{minimization problem} $P$ is defined as follows:

\begin{definition}[Worst case ratio]
Given an \concept{instance} $I$ of \concept{problem} $P$, let the value of the \concept{solution} generated by \concept{algorithm} $A$ be $\fun{A}{I}$, and let the \concept{optimum value} be denoted by $\funm{opt}{I}$; we will sometimes simply write $\mbox{OPT}$, and ignore the ``$\fun{}{I}$''-part. The ratio

\begin{equation}
\fun{r}{I}\equiv\displaystyle\frac{\fun{A}{I}}{\funm{opt}{I}}
\end{equation}

is a \concept{measure} of the \concept{quality of the solution} found. (Notice that other \concept{measure} are certainly possible as well!). Now, the \concept{smallest upper bound} on $\fun{r}{I}$, measured over all \concepts{instance} $I$ of $P$ is called the \concept{worst case ratio} (WCR) of \concept{algorithm} $A$, i.e.,

\begin{equation}
\funm{wcr}{I}\equiv\fun{\sup_I}{\fun{r}{I}}=\fun{\sup_I}{\displaystyle\frac{\fun{A}{I}}{\funm{opt}{I}}}
\end{equation}

Notice that this \concept{ratio} is at least $1$. For a \concept{maximization problem} $P$ we define a similar \concept{quality measure} as
follows.

\begin{equation}
\funm{wcr}{I}\equiv\fun{\inf_I}{\fun{r}{I}}=\fun{\inf_I}{\displaystyle\frac{\fun{A}{I}}{\funm{opt}{I}}}
\end{equation}
This \concept{ratio} is at most $1$ (and not smaller than $0$).
\end{definition}

\paragraph{}
How can one find the \concept{worst case ratio} of a certain \concept{algorithm}? Almost always this amounts to applying a problem specific analysis. In such an analysis two things must
be argued:
\begin{enumerate}
 \item one has to argue that for all \concepts{instance} $I$ of $P$ it is true that $\dfrac{\fun{A}{I}}{\funm{opt}{I}}\leq R$, and that
 \item there exists an \concept{instance} $I$ of $P$ for which the ratio $\dfrac{\fun{A}{I}}{\funm{opt}{I}}$ is equal (or arbitrarily close) to $R$.
\end{enumerate}

Then one can conclude that $\funm{WCR}{A}=R$. Notice that the \concept{worst case ratio} depends on the \concept{algorithm}, thus different \concepts{algorithm} for the same problem can yield different \concepts{worst case ratio} (as we shall see in this chapter). Of course, one could ask the question: ``How well can we \concept{approximate} a certain \concept{problem} when using only \concept{polynomial time} algorithms?''. More formal, let $\funm{\textsc{PolyTime}}{P}=\condset{A}{\mbox{$A$ is a polynomial time algorithm for $P$}}$, then one is interested in something that can be formulated as:

\begin{equation}
\fun{\inf_{A\in\funm{\textsc{\small{PolyTime}}}{P}}}{\funm{wcr}{A}}
\end{equation}

This is certainly a valid question, and in recent years a number of results in this direction have been obtained; however, we will not go into this issue.

\section{Node Cover}
\seclab{nodecoverapprox}

Recall that given a \concept{graph} $G=\tupl{V,E}$, a node cover is a \concept{subset} of the \concept[vertex]{vertices} $W\subseteq V$ with the property that each \concept{edge} in $E$ is \concept{incident} to at least one \concept{vertex} in $W$. The \concept{objective} in this problem is to find a \concept{node cover} with a minimum number of \concepts{node}. This problem is \concept{NP-hard}. Let us now describe two \concepts{approximation algorithm} for node cover.

\importalgorithmicalgorithm{nodecover1}{First proposed approximating algorithm for the node cover problem.}
\importalgorithmicalgorithm{nodecover2}{Second proposed approximating algorithm for the node cover problem.}

\algoref{nodecover1} is a \concept[Greedy algorithm]{greedy type of algorithm}. At first glance it seems to be better than \algoref{nodecover2}, as it uses at least part of the structure of the \concept{graph}. And indeed, in instances arising from practical applications, it turns out that \algoref{nodecover1} outperforms \algoref{nodecover2} with respect to the number of \concepts{node} in the \concept[node cover]{cover} found. However, as we are about to discover, the WCR of \algoref{nodecover2} is much better than the WCR of \algoref{nodecover1}.

\paragraph{}
Consider the following instance depicted in \figref{nodecover-approx-example}.

\importtikzfigure{nodecover-approx-example}{An instance for node cover.}

What is the \concept{optimum}? It is not hard to figure out that one needs at least $5$ nodes for a \concept{node cover} in the instance above, and moreover, that taking all nodes from layer $B$ indeed constitutes a \concept{feasible node cover}. Thus, this is an \concept{optimum solution}. Let us now apply \algoref{nodecover1} to this instance and let us break ties by choosing nodes in the lowest possible layer first (that is nodes of layer $A$ enjoy priority over nodes in layer $B$ which enjoy priority over nodes in layer $C$). What happens? \algoref{nodecover1} selects first the nodes from layer $A$ and then the nodes from layer $B$ concluding with a node cover consisting of $8$ nodes. Even worse, we can generalize this instance as follows: let the number of nodes in layer $B$ be $n$, then there are also $n$ nodes in layer $C$ and there are at most $n-1$ nodes in the bottom layer. Again, each node in layer $A$ is connected to each node in layer $B$ and a node in layer $C$ is connected only to its ``\concept{companion node}'' directly beneath it. Thus the \concept{optimum node cover} consists of all nodes in layer $B$ with optimal value $n$, whereas \algoref{nodecover1} will find a solution consisting of all nodes of layer $A$ and $B$, with a value equal to almost twice the optimum value. What can we deduce from this example concerning the \concept{worst case ratio} of \algoref{nodecover1}? Well, we can only say that it is at least $2$. One cannot conclude that the \concept{worst case ratio} equals $2$ since there may exist instances on which \algoref{nodecover1} fares even worse.

\paragraph{}
Such examples exist. Consider \figref{nodecover-approx-exampld}. In this instance we see that the \concept{optimum node} cover still consists of all middle nodes (i.e. value $6$), whereas the \concept{node cover} constructed by \algoref{nodecover1} will consist of all nodes in the two bottom layers (i.e. a solution with value $13$). From this instance alone we can conclude that the worst case ratio of \algoref{nodecover1} must be worse than $2.1666$.

\importtikzfigure{nodecover-approx-exampld}{Another instance for node cover.}

\paragraph{}
By generalizing this instance an even more dramatic statement can be made:
\begin{theorem}
\thmlab{wcr-nodecover-approx1}
For each $r\geq 0$, there exist \concepts{instance} $I$ of \concept{node cover} such that $\fun{A}{I}\geq r\cdot\funm{opt}{I}$.
\end{theorem}
In other words, the \concept{worst case ratio} of \algoref{nodecover1} is \concept[unbounded worst case ratio]{unbounded}; it is impossible to find a constant $r$ such that
\begin{equation}
\displaystyle\frac{\fun{A}{I}}{\funm{opt}{I}}\leq r.
\end{equation}

\paragraph{}
Let us motivate this theorem by generalizing the instance in \figref{nodecover-approx-exampld}. The structure of this instance is as follows. In case of $6$ middle nodes we do the following: \concept{partition} the nodes from $B$ into $3$ pairs and join the nodes in each pair with a node from layer $A$. Then we partition the nodes in layer $B$ into two triples, and again join all nodes in a triple with a new node from layer $A$. Repeat this for quadruples and quintuples, and so on, possibly leaving out some nodes from layer $B$, and always adding a new node in layer $A$. Then, when applying \algoref{nodecover1}, there is always a node from the bottom layer with highest degree, consequently \algoref{nodecover1} will find a \concept{node cover} consisting of $\fun{L}{n}+n$ \concepts{node}, where $\fun{L}{n}$ is the number of \concepts{node} in layer $A$. How large is $\fun{L}{n}$? Observe that

\begin{equation}
\fun{L}{n}=\sumieqb[j]{2}{n-1}{\floor{\displaystyle\frac{n}{j}}}.
\end{equation}
We leave the exact proof of \thmref{wcr-nodecover-approx1} as an exercise.

What about \algoref{nodecover2}? It is easy to establish a \concept{lower bound} of $2$ on the \concept{worst case ratio}. Indeed, when simply taking a \concept{graph} consisting of $2\cdot n$ \concept[vertex]{vertices} and $n$ \concepts{edge} forming a \concept{perfect matching}, one observes that $n$ is the value of a \concept{minimum node cover}, whereas \algoref{nodecover2} selects all $2\cdot n$ nodes. However, it turns out that this is the worst that can happen for \algoref{nodecover2}:

\begin{theorem}
\thmlab{wcr-nodecover-approx2}
$\funm{wcr}{\algoref{nodecover1}}=2$.
\end{theorem}

The argument is as follows. Of course, any \concept{node cover} must cover all \concepts{edge} chosen by \algoref{nodecover2}. However, these \concepts{edge} do not have a \concept{node} in common, and therefore each \concept{edge} must be covered by a different node in any \concept{node cover}. Thus no \concept{node cover} can be smaller than half the size of the \concept{node cover} found by \algoref{nodecover2}. Together with the example sketched above \thmref{wcr-nodecover-approx2} now follows.

\section{The Traveling Salesman Problem (TSP)}
\seclab{tspapprox}
In a sense the \concept{TSP} is a harder problem to solve than \concept{node cover}. This follows from the well known fact that, unless $\cclass{P}=\cclass{NP}$, no polynomial time algorithm for the TSP exists that has a bounded \concept{WCR} (which contrasts with \algoref{nodecover2} in \secref{nodecoverapprox}). What we can do is to restrict our instances. Recall that the input to the \concept{TSP} is a \concept{distance matrix} $D$. In the sequel we restrict ourselves to instances for which the distances satisfy the \concept{triangle inequality}.

\begin{definition}[Triangle inequality]
The \concept{triangle inequality} is a restriction on a distance metric $\delta:X\times X\rightarrow\RRR$ that states that for every three items $x_1,x_2,x_3\in X$, the distance $\fun{\delta}{x_1,x_3}$ is less than or equal to the sum of the distance from $x_1$ to $x_2$ and the distance from $x_2$ to $x_3$. More formally:
\begin{equation}
\forall x_1,x_2,x_3\in X:\fun{\delta}{x_1,x_3}\leq\fun{\delta}{x_1,x_2}+\fun{\delta}{x_2,x_3}
\end{equation}
\end{definition}

Observe that many practical problems satisfy this restriction. Indeed, \concept{TSP} instances coming from actual ``\concept{travel settings}'' are quite likely to obey the \concept{triangle inequality}.

\subsection{The double tree algorithm (DT)}
\ssclab{doubletree}

The \concept{double tree algorithm} consists of four \concepts{phase}. In the first three \concepts{phase}, we construct an \concept{Eulerian cycle} that we convert into a \concept{Hamilton circuit} in \phsref{tsp-dt-d}:

\begin{phasenum}
 \item \phslab{tsp-dt-a} Construct a \concept{minimum spanning tree} with respect to the \concept{distance function} $d$.
 \item \phslab{tsp-dt-b} Double all \concepts{edge} in the \concept{tree}. Notice that the resulting graph is \concept[Eulerian graph]{Eulerian}.
 \item \phslab{tsp-dt-c} Determine an \concept{Eulerian cycle} in the \concept{Eulerian graph} determined in \phsrf{tsp-dt-b}. Since the \concept{Eulerian graph} is \concept[connected graph]{connected} (it contains the \concept{minimum spanning tree} as a subgraph), the \concept{cycle} contains each \concept{vertex} at least once.
 \item \phslab{tsp-dt-d} Convert the \concept{Eulerian cycle} into a \concept{Hamiltonian cycle} by applying \concepts{shortcut}, i.e., replace a pair of \concepts{consecutive edge} $\tupl{i,j}$ and $\tupl{j, k}$ in the \concept{Eulerian cycle} by $\tupl{i,k}$. We are only allowed to do this if $j$ appears somewhere else in the \concept{Eulerian cycle}.
\end{phasenum}

\begin{example}
Consider the $7$-\concept{city} \concept{TSP} instance depicted \tblref{tsp-approx-dst} and \figref{tsp-approx-ph1}.

\importtabulartable{tsp-approx-dst}{The distance matrix of the Traveling Salesman Problem example.}

\begin{figure}[hbt]
\centering
\importtikzsubfigure{tsp-approx-ph1}{Phase $1$.}
\importtikzsubfigure{tsp-approx-ph2}{Phase $2$.}
\caption{Phase $1$ and $2$ of the \concept{double tree algorithm}.}
\end{figure}
\end{example}

\paragraph{}
The \concept{Eulerian cycle} generated in \concept{phase} $3$ is $1-2-3-2-4-5-6-7-6-5-4-2-1$.

\paragraph{}
The operation described in \phsref{tsp-dt-d} can be performed on any \concept{cycle}. Its effect is that a new \concept{cycle} is constructed with one edge less; in this cycle, there is one \concept{vertex} that is visited one time less in comparison with the previous \concept{cycle}. Due to the assumption that the \concept{distance function} satisfies the \concept{triangle inequality}, it follows that applying a \concept{shortcut} does not increase the \concept[length of a cycle]{length of the cycle}. Let us formally record this observation in a lemma.

\begin{lemma}
\lemlab{minimalitycycle}
Let $G=\tupl{V,E}$ be a \concept{complete graph}, and let $\funsig{d}{E}{\RRR^+}$ be a \concept{distance function} on the \concepts{edge}, which satisfies the \concept{triangle inequality}. Let $C$ be a \concept{cycle} in this \concept{graph} with total \concept[length of a cycle]{length} $\fun{d}{C}$. If $C'$ is a \concept{cycle} constructed from $C$ by applying \concepts{shortcut}, then we have that the total length of $C'$ is no more than $\fun{d}{C}$.
\end{lemma}

\paragraph{}
Let us now be more specific concerning \phsref{tsp-dt-d}. We apply a \concept{shortcut} on each second appearance of a \concept{vertex} $j$. Therefore, each \concept{vertex} remains in the \concept{cycle} at least once. After the \concept{shortcut} has been applied to all second appearances of the \concept[vertex]{vertices}, the \concept{cycle} contains each \concept{vertex} exactly once, that is, we have constructed a \concept{Hamiltonian cycle}.

\importtikzfigure{tsp-approx-ph4}{Phase $4$: replacing $3-2-4$ by $3-4$}

\importtikzfigure{tsp-approx-ph5}{Phase $4$: further replacements}

\paragraph{}
We now show that the \concept{double tree algorithm} will never produce a solution with length more than twice the length of an optimal solution. In other words:
\begin{theorem}
\thmlab{wcrdtleq2}
$\funm{wcr}{\mbox{double tree}}\leq2$.
\end{theorem}

Given an instance $I$, let $\funm{opt}{I}$ denote the length of an \concept{optimal tour}, and let $\fun{z_{dt}}{I}$ denote the length of the \concept{tour} constructed by \concept{double tree algorithm}. Finally, let $\fun{z_T}{I}$ denote the length of a \concept{minimum spanning tree}. We first prove that $\fun{z_T}{I}\leq\funm{opt}{I}$ for all instances $I$;
\begin{subproof}
Consider any \concept{optimal tour}. If we delete an arbitrary \concept{edge} from it, then we obtain a... \concept{spanning tree}. By definition, the \concept[length of a spanning tree]{length} of a \concept{spanning tree} does not exceed the \concept{length of a minimal spanning tree}, and hence, we know that its length amounts to at least $\fun{z_T}{I}$. Concluding, we have that $\fun{z_T}{I}\leq\funm{opt}{I}$.
\end{subproof}
We then complete the proof by showing that $\fun{z_{dt}}{I}\leq2\cdot\fun{z_T}{I}$:
\begin{subproof}
The total length of the \concepts{edge} in the \concept{Eulerian graph} that is constructed by doubling the \concept{minimum spanning tree} is equal to $2\cdot\fun{z_T}{I}$. From \lemref{minimalitycycle}, it follows that the length $\fun{z_{dt}}{I}$ of the \concept{Hamiltonian circuit} that is obtained by applying \concepts{shortcut}, amounts to no more than the length of the \concept{Eulerian cycle}, which is equal to $2\cdot\fun{z_T}{I}$.
\end{subproof}
Combining both results, we get $\fun{z_{dt}}{I}\leq2\cdot\fun{z_T}{I}\leq2\cdot\funm{opt}{I}$.

\subsection{The tree-matching algorithm (TM)}
\ssclab{treematching}

From the analysis above, it follows that, if we want to improve our \concept{worst case ratio}, then we can try to decrease the \concept[length of a Eulerian cycle]{length} of the \concept{Eulerian cycle}. In the sequel we will do so. This means that we use the same structure of the \concept{double tree algorithm}. In fact, \phsrefe{tsp-dt-a,tsp-dt-b,tsp-dt-c,tsp-dt-d} in the \concept{tree-matching algorithm} are identical to the corresponding phases in the \concept{double tree algorithm}. Thus, we only change the phase in which the \concept{Eulerian cycle} is constructed.

\paragraph{}
Recall that a graph is \concept[Eulerian graph]{Eulerian} if and only if it is \concept[connected graph]{connected}, and each \concept{vertex} has even \concept[vertex degree]{degree}. It seems obvious to start with a \concept{minimum spanning tree} to make sure that the \concept{graph} is \concept[connected graph]{connected}. The only problem left is to take care of the \concept[vertex]{vertices} with odd \concept[vertex degree]{degree}, which we denote by $V_0$; notice that the number of \concept[vertex]{vertices} with odd \concept[vertex degree]{degree} is even. We see that we can get even \concept[vertex degree]{degree} in each of these \concept[vertex]{vertices} by adding a \concept{perfect matching} on these \concept[vertex]{vertices} $V_0$ (see \chpref{formulation} for the definition of a \concept{perfect matching}). This is exactly what happens in Phase $2$ of the \concept{tree-matching algorithm}, where we will compute a \concept{minimum weight perfect matching} $M$ on the \concept[vertex]{vertices} in $V_0$.

\paragraph{}
\begin{example}
Consider the example again. The initial \concept{minimum spanning tree} contains $4$ \concept[vertex]{vertices} of odd \concept[vertex degree]{degree}, namely $1$, $2$, $3$, and $7$. The \concept{minimum weight perfect matching} of these \concept[vertex]{vertices} consists of the \concepts{edge} $\tupl{1,2}$ and $\tupl{3,7}$. Thus, we get the \concept[Minimum spanning tree extension]{extension} of the \concept{minimum spanning tree} as depicted in \figref{tsp-approx-pi2}.

\importtikzfigure{tsp-approx-pi2}{Phases $1$ and $2$ of the \concept{tree-matching algorithm}}.
\end{example}

\paragraph{}
An \concept{Eulerian cycle} in this \concept{graph} is $1-2-3-7-6-5-4-2-1$, where $2$ is the only \concept{vertex} that appears more than once, and therefore we remove one of its occurrences.

\importtikzfigure{tsp-approx-pi4}{Replacing $4-2-1$ by $4-1$.}

\paragraph{}
This small change with respect to the \concept{double tree algorithm} results in a better \concept{worst case behaviour}. For any instance of the \concept{TSP} (satisfying the \concept{triangle inequality}), the \concept{tree-matching algorithm} constructs a \concept{tour} with \concept[tour length]{length} no more than $\dfrac{3}{2}$ times the \concept[tour length]{length} of an optimal \concept{tour}. To prove this, it suffices to show that the length $\fun{z_M}{I}$ of the \concept{matching} $M$ is no more than $\dfrac{1}{2}$ times the optimum. Namely, then $\fun{z_{tm}}{I}\leq\fun{z_T}{I}+\fun{z_M}{I}\leq\funm{opt}{I}+\dfrac{1}{2}\cdot\funm{opt}{I}=\dfrac{3}{2}\cdot\funm{opt}{I}$.

\paragraph{}
The proof makes use of a \concept{shrinking argument}. Consider any \concept{optimal tour} with value $\funm{opt}{I}$. Apply \concepts{shortcut} such that only the \concept[vertex]{vertices} in $V_0$ remain in the \concept{cycle}; this yields a \concept{cycle} $C$ on the \concept[vertex]{vertices} in $V_0$ with length no more than $\funm{opt}{I}$. $C$ can be \concept[partitioning]{partitioned} into two \concept{perfect matchings} $M_1$ and $M_2$ on $V_0$ by ``walking'' along the \concept{circuit} and putting the first \concept{edge} in $M_1$, the second \concept{edge} in $M_2$, the third edge in
$M_1$, etc. Notice that the \concept{cycle} contains an even number of \concepts{edge}, because $\abs{v_0}$ is even.

\paragraph{}
Since $M_1$ and $M_2$ are \concepts{perfect matching} on $V_0$, we have that $\fun{d}{M}\leq\fun{d}{M_1}$ and $\fun{d}{M}\leq\fun{d}{M_2}$. Hence, we have that $2\cdot\fun{d}{M}\leq\fun{d}{M_1}+\fun{d}{M_2}=\fun{d}{C}\leq\funm{opt}{I}$, which was to be proved.

\paragraph{}
Notice that for both algorithms, our analysis of the \concept{worst case ratio} depends heavily on the assumption that the \concept{triangle inequality} holds. It can be shown that, in case the \concept{triangle inequality} fails to hold, the \concept{worst case ratio} is \concept[unbounded worst case ratio]{unbounded} (as could be inferred from the beginning of this section).

\section*{Exercises}
\begin{exercise}
Prove \thmref{wcr-nodecover-approx1}.
\end{exercise}

\begin{exercise}
Consider the following \concept{greedy algorithm} for the \concept{knapsack problem}. Sort the \concepts{object} by decreasing ratio of \concept{profit} and \concept{size}, and \concept{reindex} the \concepts{item} such that the \concept{order} of \concepts{object} is $1,2,\ldots,n$. Next, greedily pick \concepts{object} in this order while ensuring that the \concept{capacity of the knapsack} is not exceeded.
\begin{enumerate}
 \item Show that this method can behave arbitrarily bad,
 \item Modify this method by identifying the smallest $k$ such that the total size of the first $k$ \concepts{object} exceeds the capacity. Next, find the best of the following two solutions: $\accl{1,2,\ldots,k-1}$ and $\accl{k}$.
Show that this algorithm is a \concept[$r$-approximation]{2-approximation}.
\end{enumerate}
\end{exercise}

\begin{exercise}
Consider the \concept{node packing problem}. What can you tell about the \concept{worst case ratio} of \algoref{nodepacking1} and \algoref{nodepacking2}?
\importalgorithmicalgorithm{nodepacking1}{First proposed algorithm for the node packing problem.}
\importalgorithmicalgorithm{nodepacking2}{Second proposed algorithm for the node packing problem.}
\end{exercise}

\begin{exercise}
Consider the \concept{matching problem}. What can you tell about the \concept{worst case ratio} of \algoref{matching1}?
Algorithm (Input: a graph G = (V, E); output: a matching M )
M = ∅, G′ = (V ′ , E ′ ) := G
while E ′ = ∅
do
Choose an arbitrary edge {v, w} ∈ E ′ ;
M := M ∪ {v, w};
Update G′ , that is V ′ := V ′ \ {v, w} and remove from E ′ all edges incident to v or w;
od
\end{exercise}

\begin{exercise}
An \concept{edge coloring} of a \concept{graph} is a coloring of the \concepts{edge} such that no two \concepts{edge} connected to the same \concept{vertex} have the same \concept{color}. The \concept{edge coloring problem} is to minimize the number of \concepts{color} used to color a \concept{graph}. The \concept{greedy algorithm} for \concept{edge coloring} colors \concept{edge} after \concept{edge}. When coloring an edge it will first consider \concepts{color} that are already in use before assigning a new \concept{color}. What can you say concerning the \concept{worst case ratio} of this \concept{algorithm}?
\end{exercise}

\begin{exercise}
Can you find instances of the \concept{TSP} which imply that (together with \thmref{wcrdtleq2}) that $\funm{wcr}{\mbox{double tree}}=2$?
\end{exercise}

\begin{exercise}
A \concept{TSP} instance is called \concept{geometric} if each of the \concept[city]{cities} can be represented by a \concept{point} in the plane, i.e. each \concept{city} lies at \concepts{coordinate} $\tupl{x_i,y_i}$ for $i=1,2,\ldots,n$. What do the result in the previous exercise tell you about $\funm{wcr}{\mbox{dt}}$ for the \concept{geometric TSP}?
\end{exercise}