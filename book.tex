\documentclass[titlepage]{book}

\usepackage{fullpage,importsreferences-en,brackets-en,amsmath,amsthm,amssymb,amsfonts,tikz,makeidx,glossaries,hyperref}
\usetikzlibrary{shapes}

\makeindex
\makeglossary

\newcommand{\conceptsee}[2]{\toindex{#1}\indexlayout{#1}}
\newcommand{\concept}[1]{\toindex{#1}\indexlayout{#1}}

\newcommand{\indexlayout}[1]{\emph{#1}}

\makeatletter
\newcommand\toindex{\@ifstar{\@dblarg{\@toindexs}}{\@toindex}}
\def\@toindexs[#1]#2{\index{#1@#2}}
\newcommand\@toindex[2][]{%
  \if\relax\detokenize{#1}\relax
    %
    \begingroup
    \@splitword#2\@nil%
    \uppercase\expandafter{%
      \expandafter\def\expandafter\@initial\expandafter{\@first}}%
    \toks0=\expandafter{\@initial}%
    \toks2=\expandafter{\@rest}%
    \edef\x{\endgroup\noexpand\index{\the\toks0 \the\toks2 }}\x
  \else
    \index{#1}
  \fi
}
\def\@splitword#1#2\@nil{\def\@first{#1}\def\@rest{#2}}
\makeatother

\title{Optimization: Special Topics}
\author{Frits Spieksma\\ \\Edited by:\\Jo Devriendt\\Willem Van Onsem}
\date{February, 2013\\Edited: February 2014}

\theoremstyle{plain}
\newtheorem{theorem}{Theorem}[chapter]
\newtheorem{corollary}[theorem]{Corollary}
\theoremstyle{definition}
\newtheorem{exercise}{Exercise}[chapter]
\newtheorem{definition}{Definition}[chapter]
\theoremstyle{remark}
\newtheorem{example}{Example}
\newtheorem{application}{Application}
\newtheorem{answer}{Answer}
\newtheorem{hint}{Hint}
\newtheorem{note}{Note}

\begin{document}
\begin{titlepage}
\maketitle
\end{titlepage}
\tableofcontents
\chapter*{Preface}
These notes are lecture notes used for the course ``Optimization: special topics''. Its subject is mainly combinatorial optimization with an emphasis on modeling issues and solution strategies. Its audience is students, more specifically: master students in engineering or management or economic programs.

\paragraph{}
The course assumes that the reader has had a first introduction to operations research and has some elementary knowledge of mathematical modeling, linear programming, and graph theory.

\paragraph{}
There are some excellent textbooks on combinatorial optimization. We mention Schrijver's trilogy: ``Combinatorial Optimization. Polyhedra and Efficiency'' \cite{schrijver-book}. Another example is: ``Combinatorial optimization'' by Cook, Cunningham, Pulleyblank, and Schrijver \cite{Cook:98}. Other related textbooks are: Nemhauser and Wolsey \cite{citeulike:2212037}, Wolsey \cite{wolseyip}.

\paragraph{}
Please notice that \chpref{complexity} is written by Prof. Yves Crama.

\chapter{Formulations in combinatorial optimization}
\chplab{formulations}
In this first chapter, we will give an informal notion of combinatorial optimization problems. The defining characteristic of a combinatorial optimization problem is that it has a finite number of feasible solutions. We now give formulations of a number of basic combinatorial optimization problems.

\section{Formulations of basic combinatorial optimization problems}
\seclab{formulations}
Below, we present mathematical formulations of some well-known combinatorial optimization problems. Some of these problems can be formulated in a straightforward way. Others, however, have more complicated formulations. Among the latter ones are problems that can be solved very easily by a greedy algorithm, like the spanning tree problem. Other problems are notoriously hard to solve. This already shows that a formulation need not give insight into the problem's difficulty. Moreover, a problem may have several correct formulations. This leads us to a very important question: which formulations are good and which are bad? Clearly, an answer to this question depends on one's goal; we will adopt here a solver's point of view. Thus, a formulation is better than another formulation when it leads to better solutions, or when it produces solutions faster.

\paragraph{}
Almost all formulations will use binary or integral variables. This shows that \concept{integer programming} is closely related to (or, as a matter of fact, is itself a problem from the domain of) combinatorial optimization.

\subsection{The Matching Problem}
\ssclab{matching}
The \concept{Matching Problem} (also known as the \conceptsee{Edge packing problem}{Matching problem}) is one of the fundamental problems in Combinatorial Optimization. It is described as follows. We are given an arbitrary graph $G=\tupl{V,E}$. A subset of the edges $E'\subseteq E$ is called a \concept{matching} (or an \concept{edge packing}) if each vertex of $V$ is incident to at most one edge of $E'$. In other words, $E'$ is a matching if no two edges of $E'$ have a vertex in common. The problem is to find a matching in $G$ consisting of as many edges as possible (a maximum cardinality matching).

\importtikzfigure{matching-red}{The red edges form a matching.}

\paragraph{}
A matching is called maximum when no matching of larger cardinality exists. A matching is called maximal when it cannot be enlarged.

\paragraph{}
The matching problem can be formulated as an integer program as follows, where we use the symbol $\fun{\delta}{v}$ to denote the set of edges that are incident to vertex $v\in V$. For instance, in \figref{matching-red}, $\fun{\delta}{v}=\accl{\tupl{3,7},\tupl{4,7},\tupl{7,8}}$. We define a 0-1 variable for each edge $e\in E$ as follows:
\begin{equation}
\semboolvar{x_e}{if edge $e$ is selected in the matching;}{otherwise.}
\end{equation}
And here is the integer program:
\begin{eqnarray}
\mbox{maximize}&\sumdomain[e]{E}{x_e}\eqnlab{matching-m}\\
\mbox{subject to}&\forall v\in V:\sumdomain[e]{\fun{\delta}{v}}{x_e}\leq 1\eqnlab{matching-c1}\\
&\forall e\in E:x_e\in\accl{0,1}\eqnlab{matching-c2}
\end{eqnarray}

\paragraph{}
The \concept{weighted matching problem} is a generalization of the cardinality matching problem above by assuming that there is a given weight function w defined on the edges. Then, the objective is to find a maximum weight matching, and the objective is changed accordingly to $\max\isumdomain[e]{E}{w_e\cdot x_e}$ (Obviously, it is a generalization, since the cardinality matching problem arises when $w_e$ for each $e\in E$). In the perfect matching problem the set of feasible solutions is restricted to perfect matchings. These are matchings such that each vertex is incident to precisely one edge in the matching; then, constraints \eqnref{matching-c1} become equalities. Notice that a perfect matching may not exist (consider e.g. a triangle), whereas there is always a feasible solution to \eqnref{matching-m}-\eqnref{matching-c2}.

\paragraph{}
We emphasize that we distinguish between, on the one hand, the problem itself, and, on the other hand, its formulation as an integer program. Indeed, these two are not the same! In fact, in some cases it is appropriate to show the correctness of a formulation. Such an argument is usually based on a correspondence between feasible solutions to the problem, and vectors of decision variables satisfying the constraints.

\paragraph{}
Let us illustrate this matter for the matching problem. Notice that there is a 1-1 correspondence between subsets of the set of edges $E$ and the 0-1 vectors defined by the variables, which are indexed by the edges. To prove that this formulation is correct we must show that there is a 1-1 correspondence between the subsets of the edges that define matchings and the feasible solutions of the above formulation. Moreover, we must show that the matching and its corresponding vector have the same value. This can be done as follows. First, consider an arbitrary matching $M$ in a graph. By definition, this implies that each node $v\in V$ of the graph is incident with at most one edge of $M$ . Let us now construct a solution vector $\vec{x}_M$ in a straightforward manner: we put a ``1'' in $\vec{x}_M$ when the corresponding edge is in $M$, and otherwise we put a ``0'' in the vector $\vec{x}_M$. Clearly, $\vec{x}_M$ is a 0-1 vector, and obviously satisfies \eqnref{matching-c2}. Also, the solution vector $\vec{x}_M$ corresponding to $M$ satisfies the constraints \eqnref{matching-c1} since at most one of the variables in the left-hand side has value 1. Thus, a matching $M$ corresponds to a feasible solution of the integer program. Second, consider a subset of the edges $E'$ that is \textbf{not} a matching. Then there is a vertex, say $v$, that is incident to at least two edges in $E'$. But then, at least two of the variables in the left-hand side of \eqnref{matching-c1} have value 1 for this particular vertex. Thus, the vector corresponding to $E'$ is not feasible in the formulation. Finally, we observe that the value of each set $E'\subseteq E$ is equal to its number of edges, i.e., $\abs{E'}=\isumdomain[e]{E'}{1}=\isumdomain[e]{E}{x_e}$.

\paragraph{}
In general, it may not be trivial to prove the 1-1 correspondence of feasible solutions of a combinatorial problem to solutions of its formulation, i.e., solutions satisfying the constraints. For many problems, however, a correctness proof is omitted because the problem is an (extension of) a well-known problem, and the correctness of a formulation is evident.

\subsection{The Independent Set Problem}
\ssclab{independentset}
Another basic problem within the field of combinatorial optimization is the Independent Set problem (also known as Stable Set, or as Node Packing). It can be described as follows.
\paragraph{}
Consider an arbitrary graph $G=\tupl{V,E}$. A subset of the vertices $V'\subseteq V$ is called an independent set (or a stable set, or a node packing) if each edge of $E$ is incident to at most one vertex of $V'$. In other words, $V'$ is an independent set if no two vertices of an edge are selected both. The problem is to find an independent set in $G$ containing as many vertices as possible (a maximum cardinality independent set). The problem can be formulated as an integer program as follows. We define a 0-1 variable for each edge $v\in V$ as follows:
\begin{equation}
\semboolvar{x_v}{if vertex $v$ is selected in the independent set;}{otherwise.}
\end{equation}
And here is the integer program:
\begin{eqnarray}
\mbox{maximize}&\sumdomain[v]{V}{x_v}\eqnlab{stableset-m}\\
\mbox{subject to}&\forall\tupl{v_1,v_2}\in E:x_{v_1}+x_{v_2}\leq 1\eqnlab{stableset-c1}\\
&\forall v\in V:x_v\in\accl{0,1}\eqnlab{stableset-c2}
\end{eqnarray}

\importtikzfigure{stableset-red}{A stable set.}

\subsection{Spanning forest}
\ssclab{spanningforest}
Consider an undirected graph $G=\tupl{V,E}$. A subset of the edges $E'\subseteq E$ is called a forest if the subgraph of $G$ induced by $E'$ is acyclic, see \figref{forest-red} for an example. In case a forest consists of $\abs{V}-1$ edges it is called a tree. The problem is to find a maximum weight forest in $G$. The problem to find a maximum weight forest can be formulated as an integer program as follows. We define a 0-1 variable for each edge $e\in E$ as follows:
\begin{equation}
\semboolvar{x_e}{if edge $e$ is selected in the forest;}{otherwise.}
\end{equation}
And here is the integer program:
\begin{eqnarray}
\mbox{maximize}&\sumdomain[e]{E}{w_e\cdot x_e}\eqnlab{forest-m}\\
\mbox{subject to}&\forall V'\subseteq V:2\leq\abs{V'}\leq\abs{V}:\sumdomain[e]{\fun{\delta}{v_1}\cap\fun{\delta}{v_2},v_1,v_2\in V}{x_e}\leq\abs{V'}-1\eqnlab{forest-c1}\\
&\forall e\in E:x_e\in\accl{0,1}\eqnlab{forest-c2}
\end{eqnarray}

\importtikzfigure{forest-red}{The edges in red form a forest.}
\paragraph{}The \eqncsref{forest-c1} limit the number of chosen edges with both endvertices in any given subset $V'$ of the nodes to at most $\abs{V'}-1$. Since a cycle contains as many edges as vertices, the \eqncsref{forest-c1} prevent the graph $\tupl{V,E'}$ from containing cycles.
\paragraph{}
Notice that the number of subsets of $V$ of size $2$ or bigger is $2^{\abs{V}}-\abs{V}-1$. Thus, the number of \eqnref{forest-c1} is exponential in the size of the problem. Thus, the size of the formulation is exponential in the size of the input, although the problem is trivially solvable by a greedy algorithm.
\paragraph{}
The spanning tree problem is a variant of the spanning forest problem, where the set of feasible solutions is restricted to those acyclic subgraphs that are connected. It is well-known that for an acyclic subgraph the requirement of connectedness is equivalent to the requirement of having $\abs{V}-1$ edges, i.e., $\abs{E'}=\abs{V}-1$. Thus, by adding the constraint $\isumdomain[e]{E}{x_e}=n-1$ to \eqnnrefr{forest-c1}{forest-c2}, a correct formulation of the minimum weight spanning tree problem arises.

\subsection{The Knapsack Problem}
\ssclab{knapsack}
We are given a set of $n$ items, each with a weight $a_j$ and a value $c_j$ for $\rangei[j]{1}{n}$. Feasible solutions are the subsets of the set of items with cumulative weight at most $b$. The objective is to find a feasible solution of maximum value. The problem formulation contains binary variables $x_j$ which indicate whether element $j$ with $\rangei[j]{1}{n}$ is in the knapsack:

\begin{equation}
\semboolvar{x_j}{if element $j$ is selected in the knapsack;}{otherwise.}
\end{equation}

And here is the integer program:

\begin{eqnarray}
\mbox{maximize}&\sumieqb[j]{1}{n}{c_j\cdot x_j}\eqnlab{knapsack-m}\\
\mbox{subject to}&\sumieqb[j]{1}{n}{a_j\cdot x_j}\leq b\eqnlab{knapsack-c1}\\
&\forall\rangei[j]{1}{n}:x_j\in\accl{0,1}\eqnlab{knapsack-c2}
\end{eqnarray}
In this text, we will come back extensively to the knapsack problem. There is a book devoted to this problem, see Kellerer et al.\cite{KelPfePis04}.

\section{Formulations and difficulty}
\ssclab{difficulty}
Does the formulation of a problem tell us anything about the problem's difficulty? The answer is no, it doesn't. Consider for instance the matching problem (\sscref{matching}) and the stable set problem (\sscref{stableset}). These problems look similar, since the roles of the edges and vertices are interchanged. However, there is a striking difference between them. The matching problem can be solved in polynomial time, but the node packing problem is NP-hard (see \chpref{complexity}). In other words, whereas, for the matching problem, fast and efficient algorithms exist, and have been designed, no such algorithms have been found for the node packing problem. Indeed, this does not rule out the possibility that fast algorithms could exist for node packing, however, no one has ever found such an algorithm. In fact, it is widely suspected that such algorithms do not exist, but a proof of this hypothesis is lacking. All this boils down to the famous, 1 million-dollar worth, P = NP question. In practice, this means that we can find an optimal solution to a matching problem on a graph with, say 10.000 nodes and 50.000 edges within seconds, while there is no algorithm known that would return an optimal solution with one hour for the stable set instance on the same graph. Therefore: a formulation does not give an indication of the solvability of a problem. Also, the number of variables and/or constraints is no clue concerning the difficulty of a problem. For instance, the ``natural'' formulation of the minimum spanning tree problem (see \sscref{spanningforest}) has an exponential number of constraints, while the problem is easily solvable by a greedy algorithm.

\section{Multiple formulations of a combinatorial optimization problem}
\seclab{multipleformulations}

\subsection{Traveling Salesman Problem}
\ssclab{tsp}
Probably the most well-known problem in Combinatorial Optimization is the Traveling Salesman Problem (TSP). The TSP is the prototype combinatorial optimization problem. No other problem has received as much attention as the TSP, and no other problem has captured the imagination as an easy-to-describe, yet hard-to-solve problem. A description of the problem is as follows. Given is a set of $n$ ``cities'' and a distance $c_{i,j}$ between each pair of them. The goal is to find a tour of minimum length, that is to start in some city, visit each other city once, and to return to the city where the tour was started. More formally, given an $n\times n$ matrix $C=c_{i,j}$, find a permutation $\pi$ of $\accl{1,2,\ldots,n}$ such that $c_{\fun{\pi}{n},\fun{\pi}{1}}+\isumieqb[i]{1}{n-1}{c_{\fun{\pi}{i},\fun{\pi}{i+1}}}$ is minimum.
Different formulations of the TSP exist. Here is a conventional one, using binary variables $x_{i,j}$ indicating whether city $j$ is visited directly after city $i$:

\begin{eqnarray}
\mbox{minimize}&\sumieqb[i]{1}{n}{\sumieqb[j]{1}{n}{c_{i,j}\cdot x_{i,j}}}\eqnlab{tsp-m}\\
\mbox{subject to}&\forall\rangei[j]{1}{n}:\sumieqb[i]{1}{n}{x_{i,j}}=1\eqnlab{tsp-c1}\\
&\forall\rangei[i]{1}{n}:\sumieqb[j]{1}{n}{x_{i,j}}=1\eqnlab{tsp-c2}\\
&\forall S\subsetneq V:2\leq\abs{S}:\sumdomain[i]{S}{\sumdomain[j]{S}{x_{i,j}}}\leq\abs{S}-1\eqnlab{tsp-c3}\\
&\forall\rangei[i,j]{1}{n}:x_{i,j}\in\accl{0,1}\eqnlab{tsp-c4}
\end{eqnarray}

\paragraph{}
\eqncsref{tsp-c3} are called the subtour elimination constraints. An equivalent way of writing them is:
\begin{equation}
\forall S\subsetneq V:\abs{S}\geq 2:\sumdomain[i]{S}{\sumndomain[j]{S}{x_{i,j}}}\geq 1
\end{equation}

\paragraph{}
Notice that this formulation has a polynomial number of variables ($n^2$), and an exponential number of constraints (\bigoh{2^n}). The latter fact might be considered a disadvantage of formulation \eqnnrefr{tsp-m}{tsp-c4}.

\paragraph{}
There is, however, an alternative for this formulation which uses additional real variables $u_i$ , one such variable for each city $i$. The interpretation of this variable is the position of city $i$ in the tour, while putting the position of city $1$ first. Next, by replacing \eqncsref{tsp-c3} by the following constraints:

\begin{eqnarray}
\forall \rangei[i,j]{2}{n}:i\neq j:u_i-u_j+n\cdot x_{i,j}\leq n-1\eqnlab{mtz-c1}\\
u_1=1\eqnlab{mtz-c2}
\end{eqnarray}

we arrive at a formulation that is called the Miller-Tucker-Zemlin (MTZ) formulation of the TSP. It is an interesting exercise to verify the correctness of the MTZ-formulation. More concrete: why is it that \eqnnref{mtz-c1} exclude subtours? The answer lies in noticing that: any solution satisfying \eqnnref{tsp-c1}, \eqnnref{tsp-c2}, and \eqnnref{tsp-c4} consists of a collection of subtours (or a feasible solution, that is, a single tour). In case there are subtours, then there is a subtour that does not contain city 1. Let us now, for each pair of consecutive cities $i$ and $j$ in this subtour, sum the corresponding inequalities \eqnnref{mtz-c1}. The $u$-variables will cancel out, and the resulting lefthand side will be larger than the resulting righthand side, which means that this subtour will be forbidden by \eqnnref{mtz-c1}. Thus, any subtour not containing city 1 will be forbidden, and hence, the only possible solution is a single tour.

\paragraph{}
There is more than one book devoted to the TSP. We mention: Applegate et al. \cite{Applegate.2006} and Lawler et al. \cite{Lawler85}.

\paragraph{}
We will end this section with a problem for which we have two natural formulations. Both formulations have the same sets of variables, but they have different sets of constraints. Later we will see different formulations of problems where the sets of variables differ.

\subsection{Uncapacitated Facility Location}
\ssclab{facilitylocation}

We are given a set of $m$ facilities and $n$ clients. Let us call the set of facilities $M\equiv\accl{1,2,\ldots,m}$, and let us call the set of clients $N\equiv\accl{1,2,\ldots,n}$. Each of the facilities can (but need not be) be opened to serve clients. Each client must be served by a facility. The cost for opening facility $i$ is $f_i$, $i\in M$; the cost for serving client $j$ by facility $i$ is $c_{i,j}$, $i\in M$, $j\in N$. This problem can be formulated in two ways with the following sets of variables, defined for each $i\in M$, $j\in N$:

\begin{eqnarray}
\semboolvar{x_{i,j}}{if facility $j$ serves client $j$;}{otherwise.}\\
\semboolvar{y_i}{if facility $i$ is open;}{otherwise.}
\end{eqnarray}

\paragraph{}
The first formulation makes use of the fact that there is an upper bound on the number of clients that are served by a facility, namely the total number of clients $n$.

\begin{eqnarray}
\mbox{minimize}&\sumdomain[i]{M}{\brak{f_i\cdot y_i+\sumdomain[j]{N}{c_{i,j}\cdot x_{i,j}}}}\eqnlab{ufl-ma}\\
\mbox{subject to}&\forall j\in N:\sumdomain[i]{M}{x_{i,j}}=1\eqnlab{ufl-ca1}\\
&\forall i\in M:\sumdomain[j]{N}{x_{i,j}}\leq n\cdot y_i\eqnlab{ufl-ca2}\\
&\forall i\in M,j\in N:x_{i,j},y_i\in\accl{0,1}\eqnlab{ufl-ca3}
\end{eqnarray}

\paragraph{}
In the second formulation, each of the \eqncsref{ufl-ca2} is disaggregated into n new constraints, leading to constraints \eqncsref{ufl-cb2}.

\begin{eqnarray}
\mbox{minimize}&\sumdomain[i]{M}{\brak{f_i\cdot y_i+\sumdomain[j]{N}{c_{i,j}\cdot x_{i,j}}}}\eqnlab{ufl-mb}\\
\mbox{subject to}&\forall j\in N:\sumdomain[i]{M}{x_{i,j}}=1\eqnlab{ufl-cb1}\\
&\forall i\in M,j\in N:x_{i,j}\leq y_i\eqnlab{ufl-cb2}\\
&\forall i\in M,j\in N:x_{i,j},y_i\in\accl{0,1}\eqnlab{ufl-cb3}
\end{eqnarray}

Which of these formulations is preferable is not a matter of comparing the number of constraints or variables. In fact, as will be shown in the sequel, large formulations with many constraints and/or variables are usually better from a solver's point of view. This depends on the techniques that are used to solve the problem. Since these techniques very often rely heavily on linear programming, the quality of the formulation depends almost always on the accuracy of the linear programming relaxation, i.e., the problem which results when the integrality constraints are removed. For the uncapacitated facility location problem formulation (UFL2) is better than (UFL1), since the constraints \eqncsref{ufl-cb2} imply the constraints \eqncsref{ufl-ca2}.

\section{Combinatorial Optimization: a general formulation}
\seclab{generalform}
In this section we (informally) argue that each combinatorial optimization problem can be formulated as an integer program. In a combinatorial optimization problem a finite ground set $E$ is given. To each
element $e\in E$ a weight we is attached. A family $\calS$ of subsets of $E$ is identified as the set of feasible solutions. This family depends on the particular problem. The weight of a set $E'\subseteq E$ is the cumulative weight of its elements, i.e., $\fun{w}{E'}=\isumdomain[e]{E'}{w_e}$. The associated optimization problem is to find the maximum (or minimum) weight feasible solution E' âˆˆ S, i.e.,

\begin{equation}
\displaystyle\max_{E'\in\calS}\accl{\fun{w}{E'}}
\end{equation}

\paragraph{}
The set of feasible solutions $\calS$ is usually given implicitly. It is described by the properties of feasible solutions; it may be very large. For instance, in case of the matching problem, the ground set equals the set of edges, and the set $\calS$ is the collection of edge-sets that are matchings.In case of the knapsack problem, the ground set equals the set of items, and the set $\calS$ equals the collection of item-sets that can be put together in the knapsack.

\paragraph{}
Many examples of problems that fit in the above formulation are found in graph theory (\secref{formulations}). Among them are well-known problems like the shortest path problem, the minimum spanning tree problem, and the traveling salesman problem. The shortest path problem is defined as follows. In a graph $G=\tupl{V,E}$ the feasible solutions are the subsets of the edges that form paths between two specified vertices $s$ and $t$. Among the paths between $s$ and $t$ we want to find the one with a minimum number of edges, or if a length function is given on the edges, we want to find a path of minimum total length. In the minimum spanning tree problem a graph $G=\tupl{V,E}$ is given together with a weight function on the edges. A feasible solution is a set of edges that forms a tree. Among the trees we want to find one with minimum weight. This problem is easily solvable by a greedy algorithm, as is well known. However, if we restrict the set of feasible solutions to trees that form paths, the problem becomes the Hamiltonian path problem, which is highly intractable. Thus, in general, problems do not become simpler when the set of feasible solutions is reduced.

\paragraph{}
To formulate a combinatorial optimization problem in mathematical terms, we introduce decision variables for all elements of the ground set $E$. Each decision variable denotes a choice, namely whether the corresponding element is chosen or not. So, a variable can have two values, which are usually taken from $\accl{0,1}$. A set $E'\subseteq E$ can be described by a binary vector $\vec{x}_{E'}=\brak{x_e}_{e\in E}$ with $n=\abs{E}$ components as follows:

\begin{equation}
\semboolvar{x_e}{if element $e$ is in $E'$;}{otherwise.}
\end{equation}

\paragraph{}
The finite set of vectors $X\subseteq\RRR^n$ corresponding to feasible solutions from $\calS$ can then be described by means of constraints. In many cases, these constraints are linear and involve binary variables. The objective function $\vec{w}$ is usually a linear function of the components of $\vec{x}\in X$. The problem is then

\begin{equation}
\max\condset{\vec{w}\cdot\vec{x}}{A\cdot\vec{x}\leq\vec{b}\wedge \vec{x}\in\accl{0,1}^n}
\end{equation}
where $A$ and $\vec{b}$ depend on the problem at hand. This type of formulation is often called an Integer (or Binary) Linear Program, (ILP).

\section{General Combinatorial Optimization Problems}
\seclab{generalcombinatorial}

In the first section, we introduced binary variables to model decisions of the yes-no type, more specifically, to decide whether an element is in a set or not. These variables were used further to describe the constraints that determine the feasible solutions. In all the examples these constraints could be written as linear functions with a bound imposed on them. Similarly, the objective could be formulated as a linear function of the variables. In this section we will generalize the formulations of combinatorial problems, with respect to all three items, i.e., the variables, the constraints, and the objective.

\paragraph{}
The decisions in combinatorial problems may be more complicated than simple yes/no decisions. One may have to introduce integer variables or even real variables, like in linear programming, to model certain decisions. And, of course, combinations of these types of variables are possible in a single problem formulation. The combinatorial nature (finite or countable number of feasible solutions) may not be so evident in these problems. However, the number of ``interesting'' feasible solutions is usually still finite in such problems. For instance, in linear programming, the interesting feasible solutions are the vertices
of a polyhedron. The number of vertices is usually finite.

\paragraph{}
One may consider any function of the variables with a bound imposed on it as a constraint. Moreover, logical compositions of constraints, like implications and disjunctions (logical ``or'') can be used to model
the restrictions of a problem. In abstracto, any relation on the variables that restricts the set of feasible solutions can be used as a constraint.

\paragraph{}
The objective of a problem can be any function of the variables, thus it is not restricted to linear functions.

\paragraph{}
The above observations lead to the following abstract formulation of optimization problems. We distinguish between the real variables, denoted by the vector $\vec{x}$, and the integral variables, denoted by the
vector $\vec{y}$. A formulation of a combinatorial optimization problem contains the following items:
\begin{itemize}
 \item a vector of $n$ real decision variables:
 \begin{equation}
  \vec{x}=\tupl{x_1,x_2,\ldots,x_n}
 \end{equation}
 \item a vector of $m$ integral decision variables:
 \begin{equation}
  \vec{y}=\tupl{y_1,y_2,\ldots,y_m}
 \end{equation}
 \item a set $C$ of $k$ constraints:
 \begin{equation}
  C=\accl{C_1,\ldots,C_k}
 \end{equation}
 \item an objective function on the variables:
 \begin{equation}
  \fun{f}{\vec{x},\vec{y}}
 \end{equation}
\end{itemize}

\paragraph{}
The set of feasible solutions consists of vectors $\tupl{\vec{x},\vec{y}}$ that satisfy all the constraints. Each variable has a domain $D$, usually the set of real numbers $\RRR$, or the set of integer $\ZZZ$. The solution space of the problem is the Cartesian product of the domains of the variables, i.e., $\RRR^n\times\ZZZ^m$.

\paragraph{}
For many solution techniques, especially the ones that we are going to discuss, it is of eminent importance to restrict the domains of the variables as much as possible. Some constraints imply lower and upper bounds on the value of a variable, directly or indirectly. For instance, binary variables have an explicit lower and upper bound. If this is the case, we usually take this into account in the problem formulation explicitly, i.e., if a real variable $x_i$ has a lower bound $l_i$ and an upper bound $u_i$ , then we describe its domain as $\fbrk{l_i,u_i}$; if $y_j$ is an integral variable, with a lower bound $l_j$ and an upper bound $u_j$ , then we describe its domain as $\accl{l_j,\ldots,u_j}$.

\section*{Exercises}
\begin{exercise}
Consider the stable set problem on an undirected graph $G=\tupl{V,E}$. Show that the formulation \eqnnrefr{stableset-m}{stableset-c2} is a correct formulation of the stable set problem.
\end{exercise}
\begin{exercise}
Consider the matching depicted in \figref{matching-red}. Is it maximal? Is it maximum?
\end{exercise}
\begin{exercise}
Consider the stable set depicted in \figref{stableset-red}. Is it maximal? Is it maximum?
\end{exercise}
\begin{exercise}
Consider an undirected graph $G=\tupl{V,E}$. A edge cover $E'$ is a subset of the edges such that each node is incident to at least one edge in $E'$. Formulate the problem of finding a minimum cardinality edge cover as an integer linear program.
\end{exercise}
\begin{exercise}
Consider an undirected graph $G=\tupl{V,E}$. A node cover $V'$ is a subset of the nodes such that each edge is incident to at least one node in $V'$. Formulate the problem of finding a minimum cardinality node cover as an integer linear program.
\end{exercise}
\begin{exercise}
\exclab{clique-partitioning}
A \concept{clique partitioning} of an undirected, complete graph $G$ is a partitioning of the vertices into subsets $V_1,V_2,\ldots,V_k$ such that the subgraph induced by each $V_i$ is a complete graph itself ($\rangei[i]{1}{k}$). Consider now a complete graph $G$ and an arbitrary weight $w_{i,j}$ for each edge of the graph (notice that $w_{i,j}$ can be negative; in fact, the problem is only interesting when there are both positive and negative edge weights). The objective is to find a clique partitioning of maximal weight, that is, a clique partitioning such that the cumulative weight of the edges that have both vertices in one and the same component is maximum. Formulate this problem as an integer linear programming problem. (Hint: use a variable for each edge).
\end{exercise}
\begin{exercise}
Consider the TSP.
\begin{itemize}
 \item When the distance matrix C is known to be symmetric, can you simplify formulation \eqnnrefr{tsp-m}{tsp-c4} by ``merging'' \eqncsref{tsp-c1} and \eqnnref{tsp-c2}?
 \item Which of the two formulations given in \sscref{tsp} is stronger?
\end{itemize}
\end{exercise}
\begin{exercise}\exclab{rectanglestabbing}
Given is a set of axis-aligned rectangles in the plane. Each of these rectangles needs to be stabbed, either by a horizontal line or by a vertical line. The problem is to find a set horizontal and vertical lines, stabbing each rectangle at least once, with minimum cardinality. We call this the rectangle stabbing problem. Formulate this problem as an integer linear programming problem. (Hint: first, give a formulation for the instance depicted in \figref{rectanglestabbing}).
\end{exercise}
\begin{exercise}
Given an instance of the rectangle stabbing problem as depicted in \figref{rectanglestabbing}, what fractional solution is the optimal linear programming relaxation (of the integer program that you just wrote down) for this instance?
\end{exercise}

\importtikzfigure{rectanglestabbing}{A rectangle stabbing instance.}

\chapter{From linear to integer optimization}
\chplab{lintointopt}

\section{Two equivalent definitions of a polyhedron}
\seclab{defpolyhed}

Consider the feasible region depicted in \figref{polyhedron}. How to describe this object mathematically?

\importtikzfigure{polyhedron}{A feasible region.}

Here is one way: we can view the feasible region as the intersection of as a number of halfspaces, each halfspace defined by a linear inequality. For instance, in the case of the figure above, we can write
\begin{equation}
\accl{\tupl{x_1,x_2}\in\RRR^2: -x_1+5\cdot x_2\leq 20 \wedge 2\cdot x_1+x_2\leq 6\wedge 6\cdot x_1-x_2\leq 10\wedge x_1\geq 0\wedge x_2\geq 0}.
\end{equation}
So we need five inequalities to precisely describe the feasible region.

\paragraph{}
An alternative is to focus on the extreme vertices of the feasible region in \figref{polyhedron}. Indeed, we can alternatively write
\begin{equation}
\accl{\tupl{x_1,x_2}\in\funma{conv}{\tupl{0,0},\tupl{0,4},\tupl{\frac{10}{11},\frac{46}{11}},\tupl{2,2},\tupl{\frac{5}{3},0}}}.
\end{equation}

\paragraph{}
The first approach can be seen as the linear programming approach; here, we simply list all the inequalities that jointly define the feasible region. The second approach can be seen as the integer programming approach; then, we list the extreme vertices of the region, and define the feasible region as anything that is in the convex hull of these given vertices. The two approaches are equivalent: anything that can be written using inequalities, can be written as the convex hull of a number of points, and vice versa. Let us now take a more general point of view. Thus, a polyhedron $P$ can be defined in two equivalent ways. First, as the set of points in $\RRR^n$ that satisfy a finite set of linear constraints, i.e.,
\begin{equation}
P=\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}\leq b}.
\end{equation}

\paragraph{}
Second, $P$ can be defined as the set of points in $\RRR^n$ that are convex combinations of points of a finite set $X=\accl{\vec{x}_1,\vec{x}_2,\ldots,\vec{x}_K}$ plus nonnegative combinations of points of a finite set $Y=\accl{\vec{y}_1,\vec{y}_2,\ldots,\vec{y}_L}$, i.e.,
\begin{equation}
P=\funm{conv}{X}+\funm{cone}{Y}
\end{equation}
where
\begin{equation}
\funm{conv}{X}=\condset{\sumieqb[k]{1}{K}{\alpha_k\cdot\vec{x}_k}}{\forall k:\alpha_k\in\RRR^+\wedge\sumieqb[k]{1}{K}{\alpha_k}=1}
\end{equation}
and
\begin{equation}
\funm{cone}{X}=\condset{\sumieqb[l]{1}{L}{\beta_l\cdot\vec{x}_l}}{\forall l:\alpha_l\in\RRR^+}
\end{equation}

\paragraph{}
The representation theorem of Farkas, Minkowski, and Weyl (see e.g. Nemhauser and Wolsey\cite{citeulike:2212037}) proves that both definitions of a polyhedron are equivalent. Moreover, if we have a description of $P$ in one form, then we know that there is a description in the other form.

\paragraph{}
In the sequel, we will consider only polyhedra which are subsets of the positive orthant in $\RRR^n$ , i.e., $P=\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}}$. This guarantees, if $P$ is not empty, the existence of extreme points. If $X$ and $Y$ are minimal, then $X$ contains the extreme points, and $Y$ contains the extreme rays of $P$. A polytope is a bounded polyhedron, i.e., $Y=\emptyset$ and $\funm{cone}{Y}=\accl{\vec{0}}$. With a few exceptions, we will only consider polytopes in the sequel. In fact, most of the polytopes that we consider lie in the $n$-dimensional unit cube $\BBB^n=\condset{\vec{x}\in\RRR^n}{\vec{0}\leq\vec{x}\leq\vec{1}}$.

\paragraph{}
The way the representation theorem is used in combinatorial optimization is different from the way it is used in linear programming. In linear programming we are given a set of feasible solutions by means of a system of linear constraints $\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}}$. The representation theorem is used to show that the optimization problem $\max\condset{\vec{c}\cdot\vec{x}}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}}$ has an extreme point that is optimum. In combinatorial optimization we are given, implicitly, a description of a finite set of feasible solutions $\calS$. The set $\calS$ is usually described as the set of subsets of a certain ground set $E$, where these subsets satisfy certain properties. The elements from $\calS$ are described by vectors $X=\accl{\vec{x}_1,\vec{x}_2,\ldots,\vec{x}_K}$. The representation theorem is used to conclude that $\funm{conv}{X}$ can be described by linear constraints, i.e., $\funm{conv}{X}=\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}}$ for some matrix $A$ and some vector $\vec{b}$. The main goal of this chapter is to find a way to obtain this set of linear constraints.

\paragraph{}
The set of feasible solutions $X$ of a combinatorial optimization problem is usually described through a formulation with linear restrictions and integrality constraints on the variables, i.e., $X=\condset{x\in\RRR^n}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}\wedge\vec{x}\in\ZZZ^n}$. Notice that the formulation of $X$ as an Integer Linear Program is not unique. The linear programming relaxation of this formulation, denoted by $\funm{LPR}{A,\vec{b}}$, is $\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}}$. Clearly, $\funm{conv}{X}$ is a subset of $\funm{LPR}{A,\vec{b}}$. A first question is: how well does the linear programming relaxation of a formulation describe the convex hull of $X$? This gives a criterion to decide on which formulation is best for a certain problem. In general we choose the formulation that defines the smallest polyhedron containing $\funm{conv}{X}$. A second question is: how can we find constraints that improve the linear programming relaxation? Then, we are looking for constraints that are satisfied by all feasible solutions in $X$, but that cut off part of the polyhedron defined by the relaxation.

\paragraph{}
We will give (partial) answers to both questions. In the following section we identify formulations for problems that have the property that the linear programming relaxation is tight, i.e., it describes $\funm{conv}{X}$ exactly. Then we describe a method, first illustrated using the stable set problem, that improves the linear programming relaxation by adding linear constraints (called valid inequalities) that make the formulation tighter. Finally, we discuss a systematic way of obtaining these inequalities.

\section{Linear description of combinatorial problems}
\seclab{lindesccomb}
Consider the integer linear program
\begin{equation}
\max\condset{\vec{c}\cdot\vec{x}}{A\cdot\vec{x}=\vec{b}\wedge\vec{x}\geq\vec{0}\wedge\vec{x}\in\accl{0,1}^m},
\end{equation}
where $A$ is an $n\times m$ matrix of integers and $\vec{b}$ is an $n$-vector of integers. Suppose we solve the corresponding linear programming formulation. Of course, we would be quite fortuitous if the resulting values for the $\vec{x}$-variables would be integral. However, in some special cases to be discussed next, one can guarantee that the resulting solution is indeed integral.

\paragraph{}
When solving the linear programming formulation, we know from the simplex method that there is a regular $n\times n$ submatrix $B$ of $A$ such that $\overline{x}=B^{-1}\cdot\vec{b}$ is the optimum solution of the linear program. Denoting the columns of $B$ by $B_{\star,j}$ $j\in\accl{1,\ldots,n}$, Cramer's rule gives an explicit description of the $n$ basic variables $x_j$ $j\in\accl{1,\ldots,n}$ corresponding to the columns of $B$:

\begin{equation}
x_j=\displaystyle\frac{\funm{det}{B_{\star,1}|B_{\star,2}|\ldots|B_{\star,j-1}|\vec{b}|B_{\star,j+1}|\ldots|B_{\star,n}}}{\funm{det}{B}}.
\end{equation}

The upper determinant is integral. If the determinant of $B$ would be $\pm 1$, then $x_j$ is certainly integral. We call a matrix $B$ with that property unimodular (UM). Since the basis $B$ may vary with the objective $\vec{c}$ and the right-hand side $\vec{b}$, we would like to have a characterization of matrices $A$ for which each $n\times n$ submatrix $B$ is UM. Indeed, for such matrices, the polyhedron
\begin{equation}
P=\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}=\vec{b}\wedge\vec{x}\geq\vec{0}}
\end{equation}
has integral vertices.

\paragraph{}
Next, consider the integer linear program
\begin{equation}
\max\condset{\vec{c}\cdot\vec{x}}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}\wedge\vec{x}\in\accl{0,1}}.
\end{equation}
To put the associated linear programming problem in the form above we introduce a slack-vector $\vec{y}$ and we reformulate it as
\begin{equation}
\max\condset{\vec{c}\cdot\vec{x}}{A\cdot\vec{x}+\vec{y}\leq\vec{b}\wedge\vec{x},\vec{y}\geq\vec{0}}.
\end{equation}
To obtain a similar result on the integrality of $\vec{x}$ (and $\vec{y}$), we can demand that each $n\times n$ submatrix of the matrix ($A|I$) be unimodular. This, however, is equivalent to stating that all regular square submatrices (not only those with $n$ rows and columns) of the matrix $A$ have a determinant $\pm 1$. Matrices with this property are called totally unimodular (TUM), see the next definition.

\begin{definition}[Totally unimodular matrix]
A matrix $A$ is called \emph{totally unimodular} if each square submatrix of $A$ has determinant equal to $-1$, $0$, or $+1$.
\end{definition}

\paragraph{}
We have the following important theorem for TUM matrices.

\begin{theorem}
If a matrix $A$ is TUM, then the polyhedron $P=\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}}$ has integral vertices.
\end{theorem}

\paragraph{}
Clearly, a TUM matrix consists only of entries $0,\pm 1$. In the following theorem we characterize two types of matrices that are totally unimodular.
\begin{theorem}
\thmlab{tum-matrix}
Let $A$ be a matrix with entries in $\accl{-1, 0, 1}$ such that there are at most two nonzeros in each column. If there exists a partition of the rows of $A$ in two sets $R_1$ and $R_2$ such that
\begin{enumerate}
 \item each column with two nonzero entries of the same sign, has one of its entries in $R_1$ and one in $R_2$,
 \item each column with two nonzero entries of different sign, has either both of its entries in $R_1$ or both of its entries in $R_2$,
\end{enumerate}
then the matrix $A$ is TUM.
\begin{proof}
We use induction on the size of the submatrices. Each submatrix of size $1\times 1$ is trivially TUM. Let $C$ be a submatrix of size $k\times k$. We consider three cases.
\begin{enumerate}
 \item If $C$ has a column with no nonzeros it is singular;
 \item if $C$ has a column with at most one nonzero, its determinant can be expanded along that column, and total unimodularity follows from the induction hypothesis;
 \item finally, if $C$ has only columns with two nonzeroes, we split its rows in the subsets with the property described above. Adding up the rows in each subset results in two identical row vectors, which implies that the matrix is singular.
\end{enumerate}
\end{proof}
\end{theorem}

\paragraph{}
There are two important classes of matrices that satisfy the conditions of the above theorem, and therefore are TUM. The node-arc incidence matrix $A$ of a directed graph (digraph) has rows corresponding with
the nodes and columns corresponding with the arcs. The entry $A_{v,a}$ can obtain three possible values:
\begin{enumerate}
 \item $A_{v,a}=-1$ if vertex $v$ is the tail of arc $a$.
 \item $A_{v,a}=1$ if vertex $v$ is the head of arc $a$.
 \item $A_{v,a}=0$ if vertex $v$ and arc $a$ are not incident.
\end{enumerate}

\paragraph{}
The node-edge incidence matrix $A$ of a graph has rows corresponding with the nodes and columns corresponding with the edges. The entry $A_{v,e}$ can obtain two possible values:
\begin{enumerate}
 \item $A_{v,e}=1$ if vertex $v$ and edge $e$ are incident.
 \item $A_{v,e}=0$ if vertex $v$ and edge $e$ are not incident.
\end{enumerate}

\begin{corollary}
\collab{tum-graph}
The node-arc incidence matrix of a digraph is TUM. The node-edge incidence matrix of a bipartite graph is TUM.
\end{corollary}

\paragraph{}
This implies that many optimization problems on (di)graphs can be solved with linear programming. Among them are the shortest path problem, the max-flow problem, the min-cost flow problem, and the matching problem on bipartite graphs. Finally, we will show by an example that general node-edge incidence matrices need not be TUM. Consider the complete graph on three vertices $K_3$. Its node edge
incidence matrix is:
\begin{equation}
\brak{\begin{array}{ccc}
1&1&0\\
1&0&1\\
0&1&1
\end{array}}
\end{equation}
The determinant of this matrix is $-2$. Now let us compare the ILP formulation of the maximum cardinality matching problem with its linear programming relaxation on this graph. A maximum matching consists of one edge, and thus has value $1$. The LP-relaxation has an optimum value of $1.5$, since each of the three variables can obtain the value $0.5$, without violating any of the linear constraints.

\section{Valid inequalities}
\seclab{validineq}
Consider the stable set problem. Given is an arbitrary graph $G=\tupl{V,E}$. The feasible solutions are the stable sets in $G$. These solutions are represented by binary $n$-vectors, where the components correspond to the vertices. The integer linear programming formulation is the following, see also \eqnnrefr{stableset-m}{stableset-c2}.

\begin{eqnarray}
\mbox{maximize}&\sumdomain[v]{V}{x_v}\eqnlab{stablesetr-m}\\
\mbox{subject to}&\forall\tupl{v_1,v_2}\in E:x_{v_1}+x_{v_2}\leq 1\eqnlab{stablesetr-c1}\\
&\forall v\in V:x_v\in\accl{0,1}\eqnlab{stablesetr-c2}
\end{eqnarray}

The stable set polytope $\funm{conv}{\mbox{SS}}$ is the convex hull of the feasible solutions of the above formulation, i.e., the set of vectors corresponding to stable sets. We will derive two classes of so-called valid inequalities, the clique inequalities and the odd-cycle inequalities. These valid inequalities will allow us to improve the solution found by the linear programming relaxation.

\begin{example}
Consider the following graph depicted in \figref{clique-graph} on five vertices. The nodes 3, 4 and 5 form a clique, i.e., a subset of the vertices that induces a complete graph. At most one of these nodes can be present in a stable set. In other words, each feasible solution must satisfy the inequality $x_3+x_4+x_5\leq 1$. Thus, when solving the linear programming relaxation, one could add this constraint to the formulation, thereby making the constraints $x_3+x_4\leq 1$, $x_3+x_5\leq 1$ and $x_4+x_5\leq 1$ obsolete.

\importtikzfigure{clique-graph}{Graph with cliques.}

\paragraph{}
Notice that the inequality $x_3+x_4+x_5\leq 1$ can be derived from the constraints in the formulation by rounding in the following way.

\begin{equation}
\begin{array}{rcrcrcc}
x_3&+&x_4&&&\leq&1\\
&&x_4&+&x_5&\leq&1\\
x_3&+&&&x_5&\leq&1\\\hline
2\cdot x_3&+&2\cdot x_4&&2\cdot x_5&\leq&3
\end{array}
\end{equation}
This gives $x_3+x_4+x_5\leq 1$. This way we can get $3$-cliques from $2$-cliques. The clique of the nodes $1$, $2$, $3$ and $4$ can not be derived by rounding constraints of the formulation. However, we can derive them from the constraints generated by the four $3$-cliques contained in $\accl{1,2,3,4}$.
\end{example}
\begin{example}
Consider the following graph depicted in \figref{odd-cycle}: It is a cycle consisting of five vertices. The following inequality is valid. At most two nodes of the cycle can be in a packing.
\begin{equation}
x_1+x_2+x_3+x_4+x_5\leq 2
\end{equation}
In general, for a cycle $C$ with an odd number of vertices in a graph $G$, the inequality $\isumdomain[v]{C}{x_v\leq\floor{\frac{1}{2}\abs{C}}}$ valid. Unfortunately, adding such a constraint does not guarantee that the resulting solution is necessarily integral, as the graph depicted in \figref{odd-cycle-claw} shows.

\importtikzfigure{odd-cycle}{Odd cycle.}

\importtikzfigure{odd-cycle-claw}{Odd cycle with 5-claw.}

\paragraph{}
In this graph the solution $x=\tupl{\frac{2}{5},\frac{2}{5},\frac{2}{5},\frac{2}{5},\frac{2}{5},\frac{1}{5}}$ satisfies all the constraints that we have found for the stable set problem. However, the cumulative sum of the variables is larger than two, and the number of nodes in a packing in this graph is at most two. Therefore, we still do not have a description of $\funm{conv}{\mbox{SS}}$ for this graph. We will now strengthen the odd cycle inequality generated by the vertices $1$, $2$, $3$, $4$ and $5$. To do so, we look at the following inequality and we try to find a value for $\alpha$ as high as possible, such that the inequality maintains its validity.
\begin{equation}
x_1+x_2+x_3+x_4+x_5+\alpha\cdot x_6\leq 2
\end{equation}
If $x_6=0$, then the inequality reduces to the odd cycle inequality and is valid for any value of $\alpha$. If $x_6=1$, then node $6$ is in the packing. But this implies that nodes connected to $6$ can not be in the packing. Thus, $x_1=x_2=x_3=x_4=x_5=0$, and the inequality is valid for all $\alpha\leq 2$. Concluding, the inequality remains valid for $\alpha=2$.
\end{example}
\begin{application}[Generalized node packing]
In structured problems with many inequalities one can sometimes derive so-called implications, i.e., if one variable has value 1 that implies that some other variable should have value 0. Such implications can lead to strong inequalities based on node packing inequalities which tighten a formulation. This technique is often used as a preprocessing step in solving huge integer linear programming problems.
\end{application}
\begin{example}
Three binary variables $x_1$, $x_2$ and $x_3$ satisfy the following relations.

\begin{equation}
\begin{array}{rcrcrcr}
&&-3\cdot x_2&-&2\cdot x_3&\leq&-2\\
-4\cdot x_1&-&3\cdot x_2&-&3\cdot x_3&\leq&-6\\
2\cdot x_1&-&2\cdot x_2&+&6\cdot x_3&\leq&5
\end{array}
\end{equation}

\paragraph{}
By using the complementing variables $y_1=1-x_1$, $y_2=1-x_2$ and $y_3=1-x_3$, this system can be reformulated into a system consisting of knapsack constraints, as follows.

\begin{equation}
\begin{array}{rcrcrcr}
&&3\cdot y_2&+&2\cdot y_3&\leq&3\\
4\cdot y_1&+&3\cdot y_2&+&3\cdot y_3&\leq&4\\
2\cdot x_1&+&2\cdot y_2&+&6\cdot x_3&\leq&7
\end{array}
\end{equation}

\paragraph{}
The node packing graph defined by the variables and constraints consists of the following vertices and edges. There are two nodes for each variable, one representing the variable $x_i$ and the other its complement $y_i$ . Two nodes are connected by an edge if the corresponding pair of variables sums up to a value of at most $1$. In this example the edges are $\tupl{x_i,y_i}$ ($i=1,2,3$); $\tupl{y_i,y_j}$ ($1\leq i < j \leq 3$) (second constraint); $\tupl{x1,x3}$ (third constraint); $\tupl{y2,x3}$ (third constraint).

\importtikzfigure{gennodepacking}{Generalized Node Packing graph.}

\paragraph{}
There is a clique consisting of the vertices corresponding to $x_3$, $y_3$ and $y_2$. Thus, $x_3+y_3+y_2\leq 1$. Since $x_3+y_3=1$ this gives $y_2=0$ and $x_2=1$. Notice that the vector $\tupl{x_1,x_2,x_3}=\tupl{1,\frac{1}{2},\frac{1}{2}}$ satisfies the original linear programming relaxation, but is cut off by the generated clique constraint.
\end{example}

\section{Gomory-Chv\`atal rounding}
\seclab{gomorychvatal}
A general method for finding valid inequalities that really cut off a part from the linear programming relaxation is \concept{Gomory-Chv\`atal rounding}.

\paragraph{}
Suppose we have the following description of a set of points
\begin{equation}
X=\condset{\vec{x}\in\RRR^n}{A\cdot\vec{x}\leq\vec{b}\wedge\vec{x}\geq\vec{0}\wedge\vec{x}\mbox{ integral}}
\end{equation}

\paragraph{}
Then, for any vector $\vec{u}\geq\vec{0}$, the following constraint is valid:
\begin{equation}
\floor{\vec{u}\cdot A}\cdot\vec{x}\leq\floor{\vec{u}\cdot\vec{b}}
\end{equation}

\paragraph{}
By the nonnegativity of x we have that âŒŠuAâŒ‹x â‰¤ ub, and from the integrality of x it follows that the left hand side is integral, and therefore we are allowed to round down the right hand side. By adding these constraints for all nonnegative vectors u, we get the polyhedron $P^1=\condset{\vec{x}\in\RRR^n}{\vec{x}\geq\vec{0}\wedge\forall \vec{u}\in\RRR^n:\vec{u}\geq\vec{0}\Rightarrow\floor{\vec{u}\cdot\vec{A}}\cdot\vec{x}\leq\floor{\vec{u}\cdot\vec{b}}}$ which is really smaller than $P$. The problem is that there are infinitely many constraints from which only few are necessary. Moreover, the resulting polyhedron $P^1$ may still contain fractional vertices. Then the process of rounding can be repeated. Chv\`atal showed that this process gives the convex hull of all integral vectors in $P$ after a finite number of times. The number of times that these cuts must be added is called the \concept{Chv\`atal-rank}.

\paragraph{}
\begin{example}
Consider the following integer program:
\begin{equation}
\begin{array}{rrcrcr}
\mbox{maximize}&&&x_2\\
\mbox{subject to}&3\cdot x_1&+&2\cdot x_2&\leq&6\\
&-3\cdot x_1&+&2\cdot x_2&\leq&0\\
&x_1&,&x_2&\geq&0\\
&x_1&,&x_2&&\mbox{integral}
\end{array}
\end{equation}

\paragraph{}
The feasible region of the LP-relaxation of this integer program is depicted in \figref{feasibleregion-gc}.


\importtikzfigure{feasibleregion-gc}{Feasible region of LP-relaxation.}

Consider now the nonnegative vector $\vec{u}=\tupl{\frac{5}{12},\frac{1}{12}}$. Using $\vec{u}$, we can construct the following linear combination of the given constraints:
\begin{equation}
\begin{array}{rcrcrcrcr}
\tfrac{5}{12}&\times&[3\cdot x_1&+&2\cdot x_2&\leq&6]&&\\
\tfrac{1}{12}&\times&[-3\cdot x_1&+&2\cdot x_2&\leq&0]&&\\\hline\\
&&x_1&+&x_2&\leq&\floor{\frac{30}{12}}&=&2
\end{array}
\end{equation}

\paragraph{}
Another possibility is to set $\vec{u}=\tupl{\frac{1}{12},\frac{5}{12}}$. The resulting constraint can be found as follows:
\begin{equation}
\begin{array}{rcrcrcrcr}
\tfrac{1}{12}&\times&[3\cdot x_1&+&2\cdot x_2&\leq&6]&&\\
\tfrac{5}{12}&\times&[-3\cdot x_1&+&2\cdot x_2&\leq&0]&&\\\hline
&&-x_1&+&x_2&\leq&\floor{\tfrac{6}{12}}&=&0
\end{array}
\end{equation}

\paragraph{}
When both additional restrictions are added to the original constraints, a polytope depicted in \figref{feasibleregion-gc-mod} with integral vertices arises. Thus, when these constraints are added to the linear program, the problem can be solved with the simplex method.

\importtikzfigure{feasibleregion-gc-mod}{New polyhedron with additional constraints.}
\end{example}

\paragraph{}
A main question is of course: how to get hold of a ``right'' $\vec{u}$? That is, a $\vec{u}$ such that the resulting inequality cuts away fractional extreme points without eliminating integral extreme vertices? A constructive method has been designed by Gomory.

\begin{example}
We continue our example described above to illustrate the idea. When we solve the LP-relaxation of the formulation given in the example with the simplex-method (see e.g. Chv\`atal\cite{Chvatal/83/Linear}), we start with the following dictionair:

\begin{equation}
\begin{array}{rcrcrcr}
x_3&=&6&-&3\cdot x_1&-&2\cdot x_2\\
x_4&=&&&3\cdot x_1&-&2\cdot x_2\\\hline
z&=&&&&&x_2
\end{array}
\end{equation}

\paragraph{}
After performing two iterations, we find the following, final, dictionair:

\begin{equation}
\begin{array}{rcrcrcr}
x_1&=&6&-&3\cdot x_1&-&2\cdot x_2\\
x_2&=&&&3\cdot x_1&-&2\cdot x_2\\\hline
z&=&&&&&x_2
\end{array}
\end{equation}

\paragraph{}
Consider now the second equation of this last dictionair. We can rewrite it as follows:

\begin{equation}
x_2+\tfrac{1}{4}\cdot x_3+\tfrac{1}{4}\cdot x_4=\tfrac{3}{2}\eqnlab{cg-cut-eq2-ini}
\end{equation}

\paragraph{}
Since $x_3,x_4\geq 0$, it follows from the latter equality that:

\begin{equation}
x_2+\floor{\tfrac{1}{4}}\cdot x_3+\tfrac{1}{4}\cdot x_4\leq\floor{\tfrac{3}{2}}
\end{equation}

\paragraph{}
Moreover, since we know that the left-hand side of this expression is integral, we can safely round down the right-hand side, and obtain:

\begin{equation}
x_2+\floor{\tfrac{1}{4}}\cdot x_3+\tfrac{1}{4}\leq\cdot x_4=1
\end{equation}

This is the same as writing

\begin{equation}
x_2\leq 1\eqnlab{cg-cut-eq2-fin}
\end{equation}

\paragraph{}
We now continue our argument by subtracting inequality \eqnnref{cg-cut-eq2-fin} from equality \eqnnref{cg-cut-eq2-ini}. This gives us:

\begin{equation}
\tfrac{1}{4}\cdot x_3+\tfrac{1}{4}\cdot x_4\geq\tfrac{1}{2}
\end{equation}

This is called a \concept{Gomory's cut}. Substituting for $x_3$ and $x_4$ their defining equations (see the first simplex dictionair), we obtain, an equivalent inequality:

\begin{equation}
x_2\leq 1.
\end{equation}
\end{example}

\begin{note}
Notice that the current fractional solution violates this inequality. Repeatedly adding such a Gomory's cut gives in the end an integral solution.
\end{note}

\paragraph{}
We now show that the procedure outlined above not only works for this particular example, but in fact works in general. We denote by $B$ the set of basic variables, and use $x_{B_i}$ to denote the basic variable corresponding to row $i$ of the dictionair. Consider row $i$ from the last dictionair:
\begin{equation}
x_{B_i}+\sumndomain[j]{B}{d_{i,j}\cdot x_j}=d_i.\eqnlab{gc-theory1}
\end{equation}

Since $x_j\geq 0$ for all $j$, it follows that 
\begin{equation}
x_{B_i}+\sumndomain[j]{B}{\floor{d_{i,j}}\cdot x_j}=d_i.
\end{equation}

Next, due to integrality of the left-hand side, we can round down the right-hand side, and obtain:
\begin{equation}
x_{B_i}+\sumndomain[j]{B}{\floor{d_{i,j}}\cdot x_j}=\floor{d_i}.\eqnlab{gc-theory2}
\end{equation}

When we define $f_{i,j}=d_{i,j}-\floor{d_{i,j}}$, and $f_i=d_iâˆ’\floor{d_i}$, and when we subtract \eqnnref{gc-theory2} from \eqnnref{gc-theory1}, we get Gomory's cut:
\begin{equation}
\sumndomain[j]{B}{f_{i,j}\cdot x_j}=f_i.
\end{equation}

\begin{note}
Notice that when $d_i$ is not integral, then $f_i>0$, and hence Gomory's cut is violated by the current solution (which, of course, has $x_j=0$ for all $j\notin B$).
\end{note}

\paragraph{}
Unfortunately, there are some disadvantages to Gomory's method:
\begin{enumerate}
 \item The number of additional constraints is usually large. Moreover, Gomory's method does not always yield the best constraints possible.
 \item The additional constraints contain a lot of non-zero elements, in general. Therefore problems may arise with respect to the numerical stability of the simplex method.
\end{enumerate}
In order to cope with these disadvantages we will develop methods for generating better constraints. Such methods are usually problem specific, but they alleviate, to some extent, the problems mentioned.

\section*{Exercises}
\begin{exercise}\exclab{interval-matrix}
Prove \colref{tum-graph}, i.e., show that the node-arc incidence matrix of a digraph is TUM, and that the node-edge incidence matrix of a bipartite graph is TUM.
\begin{hint}
Use \thmref{tum-matrix}.
\end{hint}
\begin{answer}We solve this exercise in two parts:
\begin{description}
 \item [Node-arc incidence matrix] Since $A_{v,a}$ can only be $0$, $1$ or $-1$, matrix $A$ consists out of $\accl{-1,0,1}$. The columns of $A$ represent the arcs every arc has only one tail and one head and therefore there is one $1$ and one $-1$ in each column. We can assign all rows to one partition $R_1$ since it cannot occur that two elements in a column have the same sign, there is no constraint that a row should belong to a different partition.
 \item [Node-edge incidence matrix] By definition of a node-edge incidence matrix, the matrix only contains ones and zeros. Since each edges are incident to exactly two nodes, each column has exactly two ones. A bipartite graph can be split in two set of nodes such that there are only edges between the vertices of two different sets. By assigning the rows corresponding to the vertices of the first set to the first partition and the rows corresponding to the vertices of the second set, every two rows that have both one in a column are in a different column.
\end{description}
\end{answer}
\end{exercise}
\begin{exercise}
A 0-1 matrix has the consecutive ones property if each row has its entries with value 1 in neighboring columns. Such a matrix is also called an \concept{interval matrix}. Show that such matrices are TUM.
\begin{hint}
Use induction, plus the facts that:
\begin{enumerate}
 \item interchanging two rows does not change whether a matrix is TUM, and
 \item replacing row $A_i$ by the difference of rows $A_i$ and $A_j$ also does not change whether a matrix is TUM.
\end{enumerate}
\end{hint}
\begin{answer}
\footnote{Note: this answer does not actually use induction.}
Firstly, we remark that each square submatrix of an interval matrix again is an interval matrix. So to prove that each interval matrix is TUM, it is sufficient to prove that each square interval matrix is unimodular. Secondly, given a square interval matrix $M$, if $det(M)=0$, then $M$ is unimodular.\\
What is left to prove, is that each $n$-by-$n$ interval matrix $M$ for which $det(M)\neq 0$ is unimodular, which means it has a determinant of $+1$ or $-1$. We will do this by showing that we can transform $M$ into an identity matrix with the row operations defined above.\\
The first step in this proof is to define for each row $i \in 1..n$ the variables $s_i$ and $e_i$, denoting respectively the column where the interval of $1$'s starts and ends. For instance, the following interval matrix has three rows, where $s_1=1$, $s_2=1$, $s_3=2$, $e_1=3$, $e_2=2$, $e_3=3$:
\begin{equation}
\label{unimodular_interval}
\brak{\begin{array}{ccc}
1&1&1\\
1&1&0\\
0&1&1
\end{array}}
\end{equation}
Now, whenever two rows $i$ and $j$ have $s_i=s_j$ or $e_i=e_j$, we subtract the row with the fewest $1$'s from the row with the most $1$'s. This transformation preserves both the consecutive ones property and the unimodular property, so we end up with a new interval matrix $M'$ with the same unimodular property\footnote{This transformation can change the sign of the determinant though.}, but with less $1$'s. For example, matrix \ref{unimodular_interval} can be transformed into
\begin{equation}
\brak{\begin{array}{ccc}
0&0&1\\
1&1&0\\
0&1&1
\end{array}}
\end{equation}
by noting that $s_1=s_2$, and subsequently subtracting the row $2$ from the row $1$.\\
If we now continue to apply this row operation until no two rows have the same start value or end value, we end up with a matrix containing exactly one $1$ in each row, never in the same column.\footnote{Note that no empty rows or columns can be derived, since we could assume the determinant was non-zero.} One way to understand this, is by noting that the $n$ $s_i$'s of the final matrix must all be different, and since they can only take the values $1..n$ (being the colomn numbers), each column is associated to exactly one $s_i$. The same argument can be made for the $e_i$'s. Now, since no $e_i$ can be smaller than its corresponding $s_i$, $e_i=s_i$ for all $i \in 1..n$. Continuing the example yields \ref{unimodular_interval_2} after subtracting row $1$ from row $3$ and then row $3$ from row $2$:
\begin{equation}
\label{unimodular_interval_2}
\brak{\begin{array}{ccc}
0&0&1\\
1&0&0\\
0&1&0
\end{array}}
\end{equation}
Such a matrix can after some row-swap operations be transformed into the identity, e.g.:
\begin{equation}
\brak{\begin{array}{ccc}
1&0&0\\
0&1&0\\
0&0&1
\end{array}}
\end{equation}
And since the identity is unimodular, and since we only used unimodularity preserving row operations, $M$ must be unimodular, which concludes the proof.
\end{answer}
\end{exercise}
\begin{exercise}
Consider \excref{rectanglestabbing} of \chpref{formulations}, and let us modify that problem by only considering vertical lines as
potential stabbing lines. The resulting problem can be formulated as follows: given a set of intervals,
find a minimum number of vertical lines stabbing each interval at least once.
\begin{enumerate}
 \item Give an IP-formulation of the resulting problem.
 \item Is the corresponding constraint matrix an interval matrix (see \excref{interval-matrix})?
 \item How would you solve this problem?
 \item Can you use the same approach for the rectangle stabbing problem?
\end{enumerate}
\end{exercise}
\begin{answer}
The IP-formulation is the following:
\begin{eqnarray}
\mbox{minimize}&\sumieqb[i]{1}{n}{y_i}\eqnlab{rsv-m}\\
\mbox{subject to}&\forall I\in\calI:\sumdomain[i]{I}{x_{i}}\geq 1\eqnlab{rsv-c1}\\
&\forall\rangei[i]{1}{n}:x_i\in\accl{0,1}\eqnlab{rsv-c2}
\end{eqnarray}
The corresponding matrix is TUM since it is an interval matrix. You can solve this problem using linear programming since the matrix is TUM and thus the variables are guaranteed to be integral. It is not possible to solve the rectangle stabbing problem since such matrix is not guaranteed to be TUM.
\end{answer}
\begin{exercise}
Consider the problem formulated below, where in addition, the variables $x_1$ and $x_2$ need to be integral.

\begin{equation}
\begin{array}{rrcrcr}
\mbox{maximize}&2\cdot x_1&+&x_2\\
\mbox{subject to}&4\cdot x_1&+&x_2&\leq&8\\
&-3\cdot x_1&+&3\cdot x_2&\leq&6\\
&x_1&,&x_2&\geq&0\\
&x_1&,&x_2&&\mbox{integral}
\end{array}
\end{equation}
Solving the linear program by the simplex method gives the following final dictionary.
\begin{equation}
\begin{array}{rcrcrcr}
x_1&=&\tfrac{18}{11}&-&\tfrac{3}{11}\cdot x_3&+&\tfrac{1}{11}\cdot x_4\\
x_2&=&\tfrac{16}{11}&+&\tfrac{1}{11}\cdot x_3&-&\tfrac{4}{11}\cdot x_4\\\hline
z&=&\tfrac{52}{11}&-&\tfrac{5}{11}\cdot x_3&-&\tfrac{2}{11}\cdot x_4
\end{array}
\end{equation}
\paragraph{}
Find two Gomory cuts for the problem where the variables $x_1$ and $x_2$ need to be integral. Next, rewrite each of these cuts in terms of solely $x_1$ and $x_2$.
\end{exercise}
\begin{exercise}
Consider the following problem in integral variables $x_1$ and $x_2$. How many cutting planes do you have to add to solve the problem for $k=2$? For $k=4$? For general $k$? Can you use integer rounding to generate a valid inequality?
\begin{hint}
Draw a picture.
\end{hint}
\begin{equation}
\begin{array}{rrcrcr}
\mbox{maximize}&&&x_2\\
\mbox{subject to}&x_1&-&2\cdot k\cdot x_2&\geq&0\\
&2\cdot k\cdot x_1&+&x_2&\leq&2\cdot k\\
&x_1&,&x_2&\geq&0\\
&x_1&,&x_2&&\mbox{integral}
\end{array}
\end{equation}
\end{exercise}
\begin{exercise}
Let $G=\tupl{V,E}$ be an undirected graph. A matching in $G$ is represented by a vector $\vec{x}\in\BoolSet^{\abs{E}}$ in the following way. For each edge $e\in E$ we define

\begin{equation}
\semboolvar{x_e}{if edge $e$ is selected in the matching;}{otherwise.}
\end{equation}

The set of matchings is now given by

\begin{equation}
M=\condset{\vec{x}\in\BoolSet^{|E|}}{\forall v\in V:\sumdomain[e]{\fun{\delta}{v}}{x_e}\leq 1\wedge\forall e\in E:x_e\in\accl{0,1}}.
\end{equation}

\begin{enumerate}
 \item Derive with integer rounding that
\begin{equation}
\sumdomain[e=\tupl{v_1,v_2}]{E:v_1,v_2\in S}{x_e}\leq\displaystyle\frac{\abs{S}-1}{2}
\eqnlab{matching-introunding}
\end{equation}
is a valid inequality for each $S\subseteq V$ with $3\leq\abs{S}\leq\abs{V}$ and $\abs{S}$ odd. (These inequalities are called \concept{odd-set constraints}).
 \item Find, for the graph depicted in \figref{triangle}, a fractional solution violating the inequality \eqnref{matching-introunding} with $S=\accl{1,2,3}$.
\end{enumerate}
\importtikzfigure{triangle}{A triangle.}
\end{exercise}
\begin{exercise}
Consider the integer programming formulation of the clique partitioning problem (see \excref{clique-partitioning} of \chpref{formulations}). \figref{cliquepartition-integer} shows an instance of that problem. Notice that solid lines correspond to edges with weight $+1$, whereas dotted lines correspond to edges with weight $-1$. What is the value of the linear programming relaxation of the integer programming formulation corresponding to this instance? Can you find a violated inequality using integer rounding?
\importtikzfigure{cliquepartition-integer}{An instance of clique partitioning.}
\end{exercise}

\chapter{A glimpse at computational complexity (Yves Crama)}
\chplab{complexity}
In order to fully appreciate the field of combinatorial optimization, it is necessary to understand, at least at an intuitive level, some of the basic concepts of computational complexity. This part of theoretical computer science deals with fundamental, but extremely deep questions like: ``what tasks can be carried out by a computer?'', or ``how much time does a given computational task require?''. In this chapter, we attempt to introduce some elements of computational complexity, in a very informal and hand-waving way.

\section{Computational performance criteria}
What do we expect from an algorithm for a combinatorial optimization problem? Well, an obvious answer would be that this algorithm should always return an optimal solution of the problem. Is it the only game in town? Certainly not. We might also want it to be fast or efficient. Combining these two expectations is a crucial thing. Of course, the time required to solve a problem increases with the size of this problem,  where the size can be measured by the amount of data needed to describe a particular instance of theproblem.

\begin{example}
Let us take a look at an example. Suppose that we want to solve a 0-1 linear programming problem involving $n$ variables $x_j\in\accl{0,1}$, $j=1,\ldots,n$. We can certainly find an optimal solution by listing all possible vectors $\tupl{x_1,x_2,\ldots,x_n}$, checking for each of them whether it is feasible or not, computing the value of the objective function for each such feasible solution, and, finally, retaining the best solution found in the process. If we decide to go that way, then we must consider $2^n$ vectors. For $n=50$, that means $2^{50}\approx 10^{15}=1'000'000'000'000'000$ vectors! If our algorithm is able to enumerate one million ($1'000'000$) solutions per second, the whole procedure takes $10^9$ seconds, or about $30$ years. And for $n=60$, the enumeration of the $2^{60}$ solutions would take about $30'000$ years !!

\paragraph{}
Notice that adding $10$ variables to the problem increases the computing time by a multiplicative factor of $2^{10}\approx1'000$. So, with $n=80$ variables (a rather modest problem size), the same algorithm would run for $30$ billion years, which is about twice the age of the universe. Not really efficient, by any practical standards...
\end{example}

\paragraph{}
Let us look at this issue from another vantage point. Consider the well-known Moore's law: Gordon Moore, co-founder of the chips giant Intel, prophetized in 1965 that the number of transistors per square inch on integrated circuits would double every 18 months per year starting from 1962, the year the integrated circuit was invented (see the original paper for more details). In other words, your PC processor works twice faster every year and a half, meaning that its speed is multiplied by $100$ in $10$ years\footnote{This rate has slowed down since Moore made his claim. It is now generally admitted that the number of transistors doubles every two years.}. So, if you were able to enumerate $2^n$ solutions in one hour in 1993, you can enumerate $100\cdot2^n<2{n+7}$ solutions in 2003. This great increase in computing speed thus allows you to ``gain'' only $7$ variables in 10 years!! Conclusion: exhaustive enumeration is not feasible in practice for large-scale (or even medium-scale) combinatorial optimization problems. Furthermore, we should not count on technical progress alone to improve the situation in any significant way. Only algorithmic, or mathematical, advances can help in this respect.

\paragraph{}
So, how much progress can we expect on the theoretical front? Before we provide a tentative answer to this question, let us try to formulate more precisely some of the notions that have just been sketched.

\section{Problems and problem instances}
Formally speaking, a (computational) \concept{problem} is a generic question whose formulation includes a number of undetermined parameters. Here are some simple examples.

\begin{description}
 \item[Matrix addition problem] The parameters are $n$, $A$ and $B$ where $n\in\NNN$, and $A$ and $B$ are two $n\times n$ matrices. Question: what is the value of $A+B$?
 \item[Shortest path problem] The parameters are a graph $G=\tupl{V,E}$, two vertices $s,t\in V$, and the length $\fun{l}{e}\geq 0$ of every edge $e\in E$. Question: find a shortest path from $s$ to $t$.
 \item[Traveling salesman problem] The parameters are a graph $G=\tupl{V,E}$, and the length $\fun{l}{e}\geq 0$ of every edge $e\in E$. Question: find a shortest traveling salesman tour in $G$.
\end{description}

\paragraph{}
An \concept{instance} of a problem $P$ arises when the values of all undetermined parameters of $P$ are specified (or, more intuitively, by specifying the input file that contains the numerical data). So, a problem can also be viewed as a collection of instances. Notice that an instance admits an answer, but a problem does not (try to give the answer of the matrix addition problem above!). We will use the symbol $I$ for an instance.

\paragraph{}
An \concept{algorithm} for a problem $P$ is a step-by-step procedure that describes how to compute a solution for every instance $I$ of $P$. To compare the efficiency of different algorithms for a same problem $P$ , we can determine the time required by each algorithm to solve an instance of $P$. Notice that this obviously depends on the particular instance which is to be solved, but also on the speed of the computer, on the skills of the programmer, etc. Therefore, we need again to define this notion in more formal way.

\paragraph{}
The \concept{size of an instance} $I$, denoted by $\fun{s}{I}$, is the number of bits needed to represent $I$. It is determined both by the number of parameters and by their magnitude. (Intuitively, this can be viewed as the size of the input file of a computer program which solves $I$.)

\paragraph{}
The \concept{running time} of an algorithm $A$ on an instance $I$, denoted $\fun{t_A}{I}$, is the number of elementary operations (additions, multiplications, comparisons,...) performed by $A$ when it runs on the instance $I$. Determining the running time of an algorithm for each particular instance $I$ is not an easy task. However, it is often easier to estimate the running time as a function of the size of the instance.

\paragraph{}
Consider again the examples defined above.
\begin{description}
 \item[Matrix addition problem] Instance size: $\approx n^2$.
 \begin{enumerate}
  \item Naive addition: $\approx n^2$ (additions). We denote this by $\bigoh{n^2}$, meaning that the running time grows at most like $n^2$.
 \end{enumerate}
 \item[Shortest path problem] Instance size: $\bigoh{n^2}$ where $n=\abs{V}$.
 \begin{enumerate}
  \item Enumerate all possible paths between $s$ and $t$. There could be exponentially many paths, leading to $\bigoh{2^n}$.
  \item \concept{Dijkstra's algorithm}: $\bigoh{n^2}$ operations.
 \end{enumerate}
 \item[Traveling salesman problem] Instance size: $\bigoh{n^2}$ where $n=\abs{V}$.
 \begin{enumerate}
  \item Enumerate all possible tours: $\bigoh{n!}$.
 \end{enumerate}
\end{description}

\paragraph{}
Notice that, in all these examples, we chose to ignore the size of a number, that is, we did not take into account the number of bits needed to store some number. In view of these examples, we are led to the following concept: the complexity of an algorithm $A$ for a problem $P$ is the function 
\begin{equation}
\fun{f_A}{n}=\max\condset{\fun{t_A}{I}}{\mbox{$I$ is an instance of $P$ with size $\fun{s}{I}=n$}}.
\end{equation}
This is sometimes called the ``worst-case complexity'' of $A$: indeed, the definition focuses on the worst-case running time of $A$ on an instance of size $n$, rather than on its average running.

\section{Easy and hard problems}


Figure 3.1: (a) Linear: F (n) = an + b;

(b) Exponential: F (n) = a 2n

Figure 3.1 represents different types of complexity behaviors for algorithms. The algorithm $A$ is polynomial if $\fun{F_A}{n}$ is a polynomial (or is bounded by a polynomial) in $n$ and exponential if $\fun{F_A}{n}$ grows faster than any polynomial process in $n$. Intuitively, we can probably accept the idea that a polynomial algorithm is more efficient than an exponential one.

\paragraph{}
For instance, the obvious algorithms for the addition and or the multiplication of matrices are polynomial.
So is the Gaussian elimination algorithm for the solution of systems of linear equations. On the other
hand, the simplex method (or at least, some variants of it) for linear programming problems is known to
be exponential2 while interior point methods are polynomial. This clearly illustrates the emphasis on the
â€œworst-caseâ€ running time which was already underlined above: indeed, in an average sense, the simplex
algorithm is an efficient method.
The complete enumeration approach for shortest path, matching, stable set or travelling salesman problems is exponential, since all these problems have an exponential number of feasible solutions. But
polynomial algorithms exist for the shortest path problem and the matching problem.
For stable set, the travelling salesman problem, or for 0-1 integer programming problems, by contrast,
only exponential algorithms are known. In fact, it is widely suspected that there does not exist any
polynomial algorithm for these problems. This is a typical feature of so-called NP-hard problems which
we define (very informally again) as follows.
2 Klee

and Minty provide instances I of the LP problem such that tsimplex (I) â‰¥ 2s(I)

41

Definition 3.3.1 A problem P is N P -hard if it is as least as difficult as the 0-1 linear programming
problem, in the sense that any algorithm for P can be used to solve the 0-1 LP problem with a polynomial
increase in running time.

The next claim has resisted all proof attempts (and there have been many) since the early 70's, but the
vast majority of computer scientists and operations researchers believe that it holds true.

P = N P conjecture. If a problem is N P -hard, then it cannot be solved by a polynomial algorithm.

The P = N P conjecture, if true, expresses a deep and fundamental fact of complexity theory. Its
implications are of enormous importance for the development of algorithms in operations research and
related areas. Indeed, a large number of combinatorial optimization problems turn out to be N P -hard,
and hence difficult to solve.

Proposition 3.3.1 The following problems are N P -hard:
â€¢ travelling salesman;
â€¢ stable set;
â€¢ graph coloring;
â€¢ knapsack;
â€¢ assembly line balancing;
â€¢ three-dimensional assignment;
â€¢ facility location;
â€¢ jobshop scheduling;
â€¢ several hundred other CO problems.

It is quite remarkable that most of the problems in the above list can in fact be formulated as special
cases of the 0-1 LP problem. This is obvious, in particular, for the knapsack problem, but it is also true
42

(though less obvious) for graph equipartitioning, or for the travelling salesman problem, or for graph
coloring, etc. Thus, the actual meaning of Proposition 3.3.1 is that all these NP-hard problems are
somehow equivalent, in the sense that an efficient algorithm for any of them would immediately provide
an efficient algorithm for all of them.
From a practical point of view, however, some N P -hard problems turn out to be more difficult than
others. For instance, the knapsack problem is quite easy to solve as compared with the general 0-1 LP
problems. Nevertheless, N P -hard problems seem to be intrinsically tougher than linear systems, LP
problems or shortest path problems.
As a consequence, for the solution of such difficult (or â€œapparentlyâ€ difficult) problems, heuristic algorithms are often used in practice.
In addition, of course, not all combinatorial optimization problems are NP-hard. Minimal spanning trees,
min-cost flow, linear optimization are prime examples where polynomial-time algorithms suffice to find
an optimal solution.

Definition 3.3.2 A heuristic for an optimization problem P is an algorithm which is based on intuitively
appealing principles, but which does not guarantee to provide an optimal solution of P .

So, when running on a particular CO problem, a heuristic could for instance
â€“ return an optimal solution of the problem, or
â€“ return a suboptimal solution, or
â€“ return an infeasible solution, or
â€“ fail to return any solution at all,
â€“ etc.
This very broad definition of a heuristic may seem rather amazing at first sight. It raises again the
question of the criteria which can be applied to analyze the performance of a particular heuristic. We
mention here two criteria which will be of particular concern in this course.
43

3.3.1

Computational complexity

Generally speaking, we want heuristics to be fast , at least when compared with the highly exponential
running times mentioned above. In fact, the main reason for giving up optimality is that we want the
heuristic to compute quickly a reasonably good solution. Thus, the basic trade-off that we want to achieve
reads
SOLUTION QUALITY vs. RUNNING TIME

3.3.2

Quality of approximation

The solution returned by the heuristic should provide a good approximation of the optimal solution. To
understand how to measure this, let xH be the solution computed by heuristic H for a particular instance
and let xopt be an optimal solution for this instance. Also, val(xH ) denotes the value of the solution
found by the heuristic, and val(xopt ) denotes the optimum solution value.Then,
E(xH ) =

val(xH ) âˆ’ val(xopt )
â‰¥0
val(xopt )

(3.2)

provides a relative error measure: the closer it is to 0, the better the solution xH . Notice that we assume
that we are dealing with a minimization problem.
In general, however, val(xopt ) is unknown. So, suppose now that we know how to compute a lower bound
on val(xopt ), i.e. a number valâˆ’ such that valâˆ’ â‰¤ val(xopt ) (this is often much easier to compute than
val(xopt )). Define
E âˆ’ (xH ) =

val(xH ) âˆ’ valâˆ’
.
valâˆ’

(3.3)

Then we have
E(xH ) =

val(xH )
val(xH )
âˆ’ 1 = E âˆ’ (xH )
âˆ’
1
â‰¤
val(xopt )
valâˆ’

(3.4)

which means that E âˆ’ (xH ) overestimates the relative error E(xH ). So, if E âˆ’ (xH ) is small, we can
certainly be happy with the quality of the solution provided by H. (Notice also that if the lower bound
valâˆ’ is reasonably close to val(xopt ), then E âˆ’ (xH ) actually provides a good estimate of the error.)
44

For example, consider the travelling salesman instance described by the (symmetric) distance matrix L,
where â„“ij represents the distance from i to j, i, j = 1, 2, . . . , 6:
ï£«
0 4 7 2 6 3
ï£¬
ï£¬
ï£¬ 4 0 3 5 5 7
ï£¬
ï£¬
ï£¬ 7 3 0 2 6 5
L = ï£¬
ï£¬
ï£¬ 2 5 2 0 9 8
ï£¬
ï£¬
ï£¬ 6 5 6 9 0 5
ï£­
3 7 5 8 5 0

ï£¶

ï£·
ï£·
ï£·
ï£·
ï£·
ï£·
ï£·.
ï£·
ï£·
ï£·
ï£·
ï£·
ï£¸

Assume now that a heuristic returns the tour xH = (1, 2, 3, 4, 5, 6) (displayed in Figure 3.2).
6r
âœ
âœ
5 âœ
âœ
âœ
5 râœ
â†
â†
9â†
â†
â†
â†r
4

3

2

1r
â†
â†
â† 4
â†
â†
â†r2
âœ
âœ
âœ3
âœ
âœ
râœ
3

Figure 3.2: A feasible tour

The total length of this tour is val(xH ) = 4 + 3 + 2 + 9 + 5 + 3 = 26. On the other hand, an obvious
lower bound on the optimal tour length is given by the sum of the 6 shortest distances in L. Thus valâˆ’
= 2 + 2 + 3 + 3 + 4 + 5 = 19, and, consequently, E âˆ’ (xH ) =

26âˆ’19
19

â‰ˆ 0.37. We can therefore conclude

that xH is at most 37% longer than the optimal tour.

In order to compute lower bounds for combinatorial optimization problems, a simple but powerful principle can often be used: when a constraint of a minimization problem P is relaxed (i.e., when the constraint
is either removed or replaced by a weaker one), then the optimal value of the resulting â€œrelaxedâ€ problem
provides a lower bound on the optimal value of P . This principle will be illustrated on the examples
below.
45

Exercises
Exercise 1. Consider again the travelling salesman problem. For every vertex v âˆˆ V , select the shortest
edge ev incident to v. Show that

vâˆˆV

â„“(ev ) is a lower bound on the length of the optimal tour.

Compute this lower bound for the numerical example in Section 3.3.2. Can you improve this lower bound
by taking into account the two shortest edges incident to every vertex v? What bound do you obtain for
the numerical example?
Exercise 2. Consider the following problem: you want to save n electronic files with respective sizes
s1 , s2 , . . . , sn â‰¥ 0 on the smallest possible number of storing devices (say, floppy disks) with capacity C.
This problem is known under the name of bin packing problem, and it is NP-hard. Can you compute a
lower bound on its optimal value?
Exercise 3. Show that the optimal value of the linear programming problem
min cx

subject to Ax â‰¤ b, 0 â‰¤ xj â‰¤ 1 (j = 1, 2, . . . , n)

provides a lower bound on the optimal value of the 0-1 LP problem
min cx subject to Ax â‰¤ b, xj âˆˆ {0, 1} (j = 1, 2, . . . , n).

Exercise 4. Show that the lower bounds obtained in Exercises 1-3 can all be viewed as optimal solutions
of a relaxation of the original problem.
Exercise 5. Consider the Hamiltonian Cycle problem (HC). Given a graph G = (V, E), does G contain
a Hamiltonian cycle, i.e., a cycle visiting each node exactly once? Show that the Traveling Salesman
Problem is at least as hard as HC.
Exercise 6. Consider Partition. Given are n integers s1 , s2 , . . . , sn , does there exist a set S âŠ† {1, 2, . . . , n}
such that

iâˆˆS

si =

iâˆˆS
/

si ? Show that Knapsack is at least as hard as Partition.

Exercise 7. Show that min-cost flow is at least as hard as shortest path.

46

Chapter 4

Separation and lifting: towards a
cutting-plane algorithm
In this chapter we show how valid inequalities can be used to develop cutting plane algorithms. A key
issue in any cutting-plane algorithm is separation. We illustrate how the separation problem for specific classes of valid inequalities can be solved, by considering the cover inequalities for the knapsack
problem (section 4.1), and the subtour elimination inequalities for the traveling salesman problem (section 4.2). Lifting is about strengthening valid inequalities; we apply this concept to the cover inequalities
in section 4.3.

4.1

Separation for the knapsack problem

Although one could argue that the knapsack problem is a very specific problem featuring only a single
constraint, one should realize that any integer programming formulation can be seen as an optimization
problem with many knapsack constraints. Thus, valid inequalities that we can derive from a knapsack
constraint are important since such an inequality can be relevant for any integer program.
We restate the knapsack problem (see (1.10)-(1.12) in Chapter 1).
47

n

(Knapsack)

cj xj

(4.1)

aj xj â‰¤ b

(4.2)

max
j=1
n

s.t.
j=1

xj âˆˆ {0, 1}

for all j = 1, 2, . . . , n.

(4.3)

We assume, without loss of generality, that the parameters a1 , a2 , . . . , an , and b satisfy the following
conditions:

â€¢ selecting any single item is a feasible solution, or: aj â‰¤ b for each j, and
â€¢ selecting all n items is not a feasible solution, or:

n
j=1

aj > b.

Notice that these conditions can be checked easily. In the sequel we will also assume (unless explicitly
stated otherwise) that the items in the instance of the knapsack problem are sorted according to decreasing
weights aj , that is, a1 â‰¥ a2 â‰¥ . . . â‰¥ an . In the following section, we will derive a set of valid inequalities
for the knapsack problem and we will use them to sketch a solution approach for the knapsack problem.

4.1.1

Separation of cover inequalities

Example Consider the following linear programming relaxation of an instance of the knapsack problem.
max

206x1

+

180x2

+

176x3

+ 170x4

+ 146x5

+

110x6

83x1

+

75x2

+

70x3

+

+

+

45x6

0â‰¤

xj

68x4

59x5

â‰¤

170

â‰¤ 1 j = 1, 2, 3, 4, 5, 6.

32
A solution of the linear programming relaxation of this instance is xâˆ— = (0, 0, 1, 1, 59
, 0). We can conclude

from this LP-solution that items 3, 4, and 5 cannot simultaneously be part of a knapsack-solution. Hence,
x3 = x4 = x5 = 1 is impossible. Therefore, the following constraint is a valid inequality:
x3 + x4 + x5 â‰¤ 2.
In fact, this constraint is a violated valid inequality, that is, the given solution xâˆ— violates this inequality.
48

In general, for a subset C âŠ† {1, . . . , n} of the items with the property that

jâˆˆC

aj > b, we have the

following valid inequality:
xj â‰¤ |C| âˆ’ 1.
jâˆˆC

Such an inequality is called a cover-inequality. The set C is called a cover. More precisely, any set of
items whose total weight exceeds b is a cover with respect to this constraint. Thus, as an aside, earlier in
this section, we in fact assumed that {1, 2, . . . , n} is a cover. The inequality above is clearly valid: any
feasible solution to the knapsack problem cannot select all items from C when C is a cover. A minimal
cover is a cover with the property that the removal of any element makes the total weight of the remaining
elements drop to b or less. In other words: C is a minimal cover if

jâˆˆC

aj > b

and

for all i âˆˆ C :

jâˆˆC{i}

aj â‰¤ b.

The problem we now face is to find, given some point xâˆ— âˆˆ IRn , a cover inequality for the knapsack
problem that is not satisfied by the given point. More formally, the separation problem for the cover
inequalities is:
Given xâˆ— âˆˆ IRn , find a cover C such that

jâˆˆC

xâˆ—j > |C| âˆ’ 1, or establish that no such cover exists.

Such an inequality is called a violated cover inequality. In general, the separation problem is hard for hard
problems. However, if we restrict the search of a violated inequality to a subset of the valid inequalities,
the separation problem restricted to this subset of inequalities, may be easier to solve. We will restrict
ourselves here to the separation of the cover inequalities for the knapsack problem.
The separation problem for the cover inequalities is now restated as follows. Let the point xâˆ— âˆˆ IRn be
given. Is there a cover-inequality that is violated by xâˆ— ? In mathematical terms this problem can be
described as follows.
Given xâˆ— : Is there a C âŠ† {1, 2, . . . , n} with
xâˆ—j

>

|C| âˆ’ 1 and

(4.4)

aj

>

b?

(4.5)

jâˆˆC

jâˆˆC

To solve this problem we introduce binary variables zj (1 â‰¤ j â‰¤ n). Define, for j = 1, 2, . . . , n:
49

zj

ï£±
ï£² 1
=
ï£³ 0

if j is chosen in the cover C;
otherwise.

These variables will determine which elements are present in the cover. The solution z to be found should
satisfy the following conditions.

ï£«

n
j=1

xâˆ—j zj > ï£­

n
j=1

ï£¶

zj ï£¸ âˆ’ 1

(4.6)

Clearly, this inequality follows from reformulating (4.4) by taking the newly defined z-variables into
account (notice that, by definition, |C| =

n
j=1 zj ).

Let us rewrite inequality (4.6) by bringing all terms

with z-variables to the left hand side:
n

(1 âˆ’ xâˆ—j )zj < 1.
j=1

Consider now inequality (4.5). When we plug in the z-variables into this inequality, the following inequality results:

n

aj zj â‰¥ b + 1.
j=1

Summarizing all conditions, we can formulate the separation problem for the cover inequalities as the
following minimization problem.

n

min Î· =
j=1

(1 âˆ’ xâˆ—j )zj

(4.7)

n

aj z j â‰¥ b + 1

s.t.

(4.8)

j=1

zj âˆˆ {0, 1}

for all j = 1, 2, . . . , n.

(4.9)

Suppose that we are able to solve (4.7)-(4.9). Then, if Î· < 1, a cover inequality violated by xâˆ— has been
found. If, on the other hand, Î· â‰¥ 1, then we haven't found a cover inequality violated by xâˆ— (and for good
reason: none exists!). Although the separation problem for cover inequalities, i.e., solving (4.7)-(4.9), is
50

NP-hard in general, the problem can become fairly easy for a given instance. This is due to the fact
that there are usually only few fractional values in the solution xâˆ— . Indeed, items whose corresponding
xâˆ— -variables equal 1 can always be added to the cover; this follows from observing that objective function
(4.7) will not increase when selecting such an item in the cover. Also, items whose corresponding xâˆ— variables equal 0 can be safely excluded from the cover, since selecting such an item will result in Î· â‰¥ 1.
In other words: if xâˆ—j = 1 then zj = 1, and if xâˆ—j = 0 then zj = 0. We illustrate this with the next
example.
Example
79x1 + 53x2 + 53x3 + 47x4 + 45x5 â‰¤ 178
A fractional solution for this example: xâˆ— = (1, 1, 46
53 , 0, 0). To find a violated cover we have to solve the
problem (verify this!):

min
s.t.

Î·=

7
53 z3

+ z4 + z5

(4.10)

79z1 + 53z2 + 53z3 + 47z4 + 45z5 â‰¥ 179
zj âˆˆ {0, 1}

(4.11)
for all j âˆˆ {1, . . . , 5}

(4.12)

As argued above, if xâˆ—j = 1, then zj = 1 as well (since the the coefficient of zj in (4.10) equals zero). And,
since we are only interested in finding violated cover inequalities, xâˆ—j = 0 implies zj = 0 (since zj = 1
gives Î· â‰¥ 1). Now, observe that the solution (z1 , z2 , z3 , z4 , z5 ) = (1, 1, 1, 0, 0) is feasible in (4.11)-(4.12),
and has objective function value less than 1. Thus, we have identified a violated cover inequality:
x1 + x2 + x3 â‰¤ 2.

In the following iterations of a cutting-plane algorithm, the number of fractional variables may increase
since the number of constraints increases. Therefore, identifying violated inequalities may become more
complicated in forthcoming steps.
Consider the following example.
51

max

77x1 + 6x2 + 3x3 + 6x4 + 33x5 + 13x6 + 110x7 + 21x8 + 47x9

s.t. 774x1 + 76x2 + 22x3 + 42x4 + 21x5 + 760x6 + 818x7 + 62x8 + 785x9 â‰¤ 1500
67x1 + 27x2 + 794x3 + 53x4 + 234x5 + 32x6 + 797x7 + 97x8 + 435x9 â‰¤ 1500
0 â‰¤ xi â‰¤ 1 for all i.

In the following table we see how the linear programming solution and its value develop after adding
violated cover inequalities. In the first table we give the solutions that are generated in the iterations.
In the second table the violated cover inequalities are given. Notice that we can derive cover inequalities
from both constraints.

Iteration

x1

x2

1

.71

2

x3

x4

x5

.35

1

1
.63

3
4

1

.35

1

Iteration

x6

x7

x8

x9

zLP

1

1

1

1

1

1

1

.61

204.8

1

1

.37

1

.63

177.1

1

1

1

1

225.7

176.0

Cover wrt constraint 1

Cover wrt constraint 2

1

x1 + x7 â‰¤ 1

x3 + x7 â‰¤ 1

2

x7 + x9 â‰¤ 1

3

x1 + x7 + x9 â‰¤ 1

Notice that the inequality x1 + x7 + x9 â‰¤ 1 is not a cover inequality. Indeed, although {1, 7, 9} is a
cover with respect to the first inequality, the right-hand side does not equal |C| âˆ’ 1. This inequality is a
so-called extended cover inequality. The extended cover inequalities are the subject of section 4.3.
From the first table one can see that the number of fractional variables is small compared to the total
number of variables. Thus, the separation problem for the cover inequalities is fairly easy here. In
general, the number of fractional variables is bounded by the number of constraints of the problem at
hand. Although this number may increase, the number of fractional variables tends to remain limited.
This observation is true for many problems.
52

4.2

Separation for the traveling salesman problem

Consider the following formulation of the symmetric traveling salesman problem, which uses a binary
variable xe indicating whether edge e is selected or not.

e ce xe

minimize
subject to

(4.13)

eâˆˆÎ´(v)

xe = 2

eâˆˆÎ´(S)

xe â‰¥ 2

xe âˆˆ {0, 1}

for all v âˆˆ V
for all S âŠ‚ V, |S| â‰¥ 2
for all e.

(4.14)
(4.15)
(4.16)

Obviously, constraints (4.14) ensure that each node must be incident to two edges; these constraints are
referred to as degree constraints. Constraints (4.15) state that, for each nodeset S âŠ‚ V , there at least two
edges with one endpoint in S and one endpoint not in S. These constraints are the subtour elimination
constraints.
When we replace the integrality constraints (4.16) by 0 â‰¤ xe â‰¤ 1, we have created a linear program that
we refer to as the subtour LP. Clearly, solving this subtour LP gives a lower bound to the optimal value
of the TSP instance. Notice however, that this subtour LP contains exponentially many constraints. We
will show how to solve the separation problem for the subtour elimination constraints efficiently, i.e., in
polynomial time. This implies that we can optimize over the subtour LP in polynomial time (despite the
exponential number of constraints).
So, let us assume we are given a vector xâˆ—e , found, for instance, by optimizing (4.13) over the constraints
(4.14) and 0 â‰¤ xe â‰¤ 1. The question now is: does there exist a violated subtour elimination constraint?
In other words, is there a set S âŠ‚ V such that the left-hand side of (4.15) is less than 2? To answer this
question we build a network G consisting of nodes, edges, and a capacity for each edge as follows. There
is a node in G for each city in the TSP-instance, and there is an edge in the network for each e with
xâˆ—e > 0. The capacity of this edge equals xâˆ—e .
Proposition 4.2.1 The value of a minimum cut in G is less than 2 if and only if there exists a violated
subtour elimination constraint.
53

We leave it to the reader to verify this proposition. Concluding, by solving a minimum cut problem we
solve the separation problem for the subtour elimination constraints.

4.3

Lifting: extended cover inequalities

Consider the example in Section 4.1. From the first constraint we could have obtained the valid inequality
x1 + x6 + x7 + x9 â‰¤ 1
. Indeed, since the coefficients of x1 , x6 , x7 and x9 are each larger than 750, no two of these variables
can both equal 1. Thus, this inequality is valid, and in fact, it is stronger that the corresponding cover
inequalities. Addition of this particular inequality to the linear programming relaxation would have
given the integral solution immediately. Unfortunately, this inequality is not part of the class of cover
inequalities. But we can derive it from a cover inequality with a technique called lifting.
Example Let S be the set of feasible solutions of the problem in the previous section. Consider the inequality x1 +x7 â‰¤ 1. This inequality is valid in the set of solutions restricted to the items {1, 2, 3, 4, 5, 7, 8},
i.e., it is valid for the set S âˆ© {x âˆˆ IB 9 |x6 = x9 = 0}. We will now derive an inequality
x1 + Î±x6 + x7 â‰¤ 1
where Î± is chosen such that this inequality is valid for S âˆ© {x âˆˆ IB 9 |x9 = 0}. In order to do so, we have
to evaluate two situations.
x6 = 0:

in this case the inequality remains valid trivially.

x6 = 1:

in this case each of the items 1 and 7 can not be taken into the knapsack because constraint 1
would be violated. Therefore, taking Î± = 1 maintains validity of the constraint.

This process can be repeated for item 9. It will lead to the inequality
x1 + x6 + x7 + x9 â‰¤ 1.
Notice that the resulting inequality is not a cover inequality (there are four variables on the lefthand side,
whereas the righthand side does not equal 3). This inequality belongs to the class of so-called extended
cover inequalities.
54

Recall that we have assumed that the items are indexed according to decreasing weight. Consider a
minimal cover C = {j1 , . . . , jk }. Then the corresponding extended cover E(C) is defined as
E(C) = {1, . . . , j1 âˆ’ 1} âˆª C.
Thus, each item that is heavier than the heaviest item in the cover C is added in order to construct the
set of items E(C). We claim:
Theorem 4.1

jâˆˆE(C)

xj â‰¤ |C| âˆ’ 1 is a valid inequality for the knapsack problem.

The derivation of an extended cover inequality from a cover inequality can be seen as a special case
of a process called lifting. Given some valid inequality (say, a cover inequality) lifting refers to raising
coefficients of variables in this inequality in order to obtain a stronger, yet valid, new inequality (the
extended cover inequality). Indeed, the coefficients of variables x1 , x2 , . . . , xj1 âˆ’1 have value 0 in the cover
inequality, and have been raised to value 1 in the extended cover inequality. This principle, however, can
be applied in a more general way. In fact, lifting is a technique that can be used in many problems to
strengthen known classes of valid inequalities. The following theorems can be used repeatedly for this
purpose. In the theorems stated below, we assume that x is a n-dimensional {0, 1} vector, and that S
denotes the set of feasible x-vectors.
Theorem 4.2 Suppose that
Then Î±x1 +

n
j=2

n
j=2

Ï€j xj â‰¤ Ï€0 is valid for each x âˆˆ S with x1 = 0.

Ï€j xj â‰¤ Ï€0 is valid for each x âˆˆ S as long as Î± â‰¤ Ï€0 âˆ’ maxxâˆˆS|x1 =1

Theorem 4.3 Suppose that
Then Î²x1 +

n
j=2

n
j=2

n
j=2

Ï€j xj .

Ï€j xj â‰¤ Ï€0 is valid for each x âˆˆ S with x1 = 1.

Ï€j xj â‰¤ Ï€0 +Î² is a valid inequality for each x âˆˆ S as long as Î² â‰¥ maxxâˆˆS|x1 =0

n
j=2

Ï€j xj âˆ’

Ï€0 .
Notice that applying Theorem 4.2 does not change the righthand side, whereas applying Theorem 4.3
may change the righthand side. In the remainder of this section we give an example in which the two
theorems above are applied repeatedly.
Example Consider the knapsack constraint
3x1 + x2 + x3 + x4 + x5 â‰¤ 4.
55

(4.17)

As before, let S be the set of (binary) feasible solutions of this constraint. Suppose that we fix the values
of the first three variables as follows:
x1 = 1, x2 = x3 = 0.
Plugging in these values in (4.17) reduces the inequality to x4 + x5 â‰¤ 1. Thus x4 + x5 â‰¤ 1 is valid for
each x âˆˆ S with x1 = 1, x2 = x3 = 0.
We now lift variable x3 by applying Theorem 4.2. This gives (using Î±3 as coefficient for x3 ): find a
maximal Î±3 such that Î±3 x3 + x4 + x5 â‰¤ 1 is valid for each in x âˆˆ S with x1 = 1, x2 = 0, x3 = 1. This is
equivalent to determining a maximal Î±3 such that
Î±3 â‰¤ 1 âˆ’

max

xâˆˆS|x1 =1,x2 =0,x3 =1

x4 + x5 .

It follows that Î±3 = 1. In other words, we can conclude that x3 + x4 + x5 â‰¤ 1 is valid for all x âˆˆ S with
x1 = 1, x2 = 0.
We now proceed by lifting variable x1 using Theorem 4.3. This gives (using Î²1 as coefficient for x1 ): find
a minimal Î²1 such that Î²1 x1 + x3 + x4 + x5 â‰¤ 1 + Î²1 is valid for each x âˆˆ S with x1 = x2 = 0. This is
equivalent to determining a minimal Î²1 such that
Î²1 â‰¥

(x3 + x4 + x5 ) âˆ’ 1.

max

xâˆˆS|x1 =x2 =0

It follows that Î²1 = 2. Thus, we conclude that 2x1 + x3 + x4 + x5 â‰¤ 3 is valid for all x âˆˆ S with x2 = 0.
Finally, we lift variable x2 using Theorem 4.2. This gives (using Î±2 as coefficient for x2 ): find a maximal
Î±2 such that 2x1 + Î±2 x2 + x3 + x4 + x5 â‰¤ 3 is valid for each x âˆˆ S with x2 = 1. This is equivalent to
determining a maximal Î±2 such that
Î±2 â‰¤ 3 âˆ’

max

xâˆˆS|x2 =1

2x1 + x3 + x4 + x5 .

It follows that Î±2 = 0. We arrive at the conclusion that the resulting inequality
2x1 + x3 + x4 + x5 â‰¤ 3

(4.18)

is a valid inequality for each x âˆˆ S. Notice that we have derived a new inequality (4.18) that is stronger
than the original one (4.17). As an example, consider the solution x = ( 13 , 0, 1, 1, 1), and observe that
this particular solution is cut off by (4.18), while it is not violated by (4.17).
56

Here we have lifted the variables x1 , x2 and x3 in the sequence x3 , x1 , x2 . It is interesting to notice that
different sequences may yield different inequalities. For instance, the sequence x3 , x1 , x2 produces another
inequality. Thus, the order of lifting influences the final inequality we get, see Exercise 4.

4.4

Applications

Knapsack constraints are embedded in many structured problems. Two obvious examples are the multiknapsack problem and the generalized assignment problem. We will give their respective formulations
below.
The multi-knapsack problem

n

cj xj

(M KP ) max

(4.19)

j=1
n

aij xj â‰¤ bi

s.t.

for all i = 1, 2, . . . , m

(4.20)

for all j = 1, 2, . . . , n

(4.21)

j=1

xj âˆˆ {0, 1}

The generalized assignment problem

m

n

cij xij

(GAP ) max

(4.22)

i=1 j=1
n

s.t.

aij xij â‰¤ bi

for all i = 1, 2, . . . , m

(4.23)

for all j = 1, 2, . . . , m

(4.24)

for all i = 1, 2, . . . , m, for all j = 1, 2, . . . , n.

(4.25)

j=1
m

xij â‰¤ 1
i=1

xij âˆˆ {0, 1}

57

Exercises
Exercise 1
Find all inequalities, induced by minimal covers, of the following knapsack inequality:
79x1 + 53x2 + 53x3 + 45x4 + 45x5 â‰¤ 178.
Can you find an extended cover inequality?
Exercise 2
Consider the following knapsack problem.
max

3x1 + 2x2 + x3

s.t.

4x1 + 3x2 + 2x3 â‰¤ 6
x1 , x2 , x3 âˆˆ {0, 1}

Solve this problem with a cutting-plane algorithm.
Exercise 3
It is clear that one can use the simplex-method to find the linear programming relaxation of the knapsack
problem as formulated by (1.10)-(1.12). However, we claim that there is a much easier way:
Sort the items such that
c1
c2
cn
â‰¥
â‰¥ ... â‰¥
,
a1
a2
an
and next fill the knapsack with items 1, 2, . . . , k âˆ’ 1, until item k can only be fractionally added to the
knapsack. In other words, we claim that the following solution is an optimal linear programming solution
to the knapsack problem.
ï£±
ï£´
ï£´
1
ï£´
ï£²
kâˆ’1
xj =
(b âˆ’ j=1 aj )/ak
ï£´
ï£´
ï£´
ï£³ 0

for all j = 1, 2, . . . , k âˆ’ 1
if j = k
for all j = k + 1, . . . , n.

Can you prove this?

Apply this to the example in Section 4.1.
Exercise 4
58

Consider the example in Section 4.3. What inequality results if the variables are lifted in the sequence
x2 , x1 , x3 ? And what inequality results when using x1 , x2 , x3 as lifting sequence?

59

60

Chapter 5

Column generation and
branch-and-price
In this chapter we describe a technique that is used for solving linear programs with a huge number of
variables, namely column generation (see Section 5.1). The use of this technique within an enumerative
framework is next discussed in Section 5.2. We illustrate these issues on the cutting stock problem (bin
packing) and the crew scheduling problem.

5.1

Column generation

In this section we show how column generation procedures can work. We emphasize that column generation is a technique for solving (large) linear programming problems. The main idea is (i) to work in
iterations, and deal, at all times during the course of the method, with only a limited number of variables,
and (ii) to verify optimality of the outcome of each iteration using complementary slackness. In Subsection 5.1.1 we show how this method can be applied to the cutting stock problem, and in Subsection 5.1.2,
we show how it works for a crew scheduling problem.
61

5.1.1

The cutting stock problem

We start by illustrating this on the cutting stock problem. This problem can be described as follows.
Given are n item types; there is a demand of di items for type i, and each item of type i has size wi ,
i = 1, 2, . . . , n. Let the total number of items be denoted by D =

i

di . Given are a (large enough)

number of rolls of size L. The problem is to fulfill demand exactly, using a minimum number of rolls. A
straightforward formulation is as follows, where we use, with i = 1, . . . , D,j = 1, 2, . . . binary variables
ï£±
ï£² 1 if item i is cut from roll j,
xij =
ï£³ 0 otherwise,

and

ï£±
ï£² 1
yj =
ï£³ 0

The formulation is now:

(CS-1) min
s.t.

if roll j is used,
otherwise.

j=1
D
i=1

yj

wi xij â‰¤ Lyj

j=1

xij = 1

(5.1)
for j = 1, 2, . . .

(5.2)

for i = 1, 2, . . . , D

(5.3)

xj âˆˆ {0, 1}, yj âˆˆ {0, 1} for all i, j.

(5.4)

There are a number of reasons why this formulation is not suited for solving large instances of the cutting
stock problem. First of all, the linear programming bound is very weak, since the solution xij =

1
D

is

feasible to the linear programming relaxation (verify that this leads to a linear programming solution
with value (

wi /L)). Secondly, symmetry of solutions (the rolls are interchangeable) will also affect the

performance of a branch-and-bound algorithm based on this formulation. Therefore, another formulation
based on another concept is welcome. Instead of focusing on individual items, let us focus on a possible
way to cut a roll. More precisely, we refer to a possible way of cutting a roll as a pattern. Obviously,
given the input described above, we could, in principle enumerate all possible patterns. Then, we could
write down the following formulation that uses an integral variable zj for the number of times a roll is
cut according to pattern j = 1, 2, . . .:
62

(CS-2) min
s.t.

j=1 zj
j=1

aij zj = di

zj integral

(5.5)
for i = 1, . . . , n

(5.6)

for all j.

(5.7)

Notice that aij denotes the number of times that an item of type i is used in pattern j; this is a known
number. Now although this formulation does not suffer from the disadvantages mentioned above, there
is a disadvantage to the current formulation: the number of variables. Indeed, this number can be
astronomically high.
Let us therefore first focus on solving the linear programming relaxation of formulation (CS-2). How to
overcome the obstacle posed by the number of variables? The crucial idea of column generation is based
on the observation that in an optimal solution of the linear programming relaxation of (CS-2), only very
few of these variables will have a value different from 0. Indeed, the theory of the simplex-algorithm
tells us that if there is an optimal solution, this solution will consist of n basic variables that may have
a non-zero value, while all other variables will be non-basic and have value 0.
How to make use of this observation? Of course, we do not know a priori which variables are basic in an
optimal solution and which variables are not. However, given a feasible basic solution, we can determine
(using complementary slackness and duality) whether it is optimal, and if not, which variable should
be included in the basis to improve the current solution. This idea suggests an iterative procedure for
solving the LP-relaxation of (CS-2) as follows:

Step 0: Start with a subset of the variables (that contains a feasible solution). All other variables have
implicitly the value 0. This is called the restricted master problem.
Step 1: Solve the LP-relaxation, and arrive at a feasible primal solution.
Step 2: Question: does there exist a variable (a pattern) with negative reduced costs? That is, does there
exist a variable that should enter the basis? This question is called the pricing problem. If no, the
current LP-solution is optimal, and we STOP, else
Step 3: Identify that variable and add it to the current set of variables. Go to Step 1.
63

At first sight, there may be no reason why this would be more efficient than solving the linear program
with all variables. Indeed, the crux of this approach lies in solving the pricing problem: if explicitly
determining the reduced cost of each individual variable by enumeration was the only way to solve the
pricing problem, we would not have gained much. However, in a lot of cases, solving the pricing problem
can be done very efficiently, for instance by solving a shortest path problem, or by solving a knapsack
problem. Then, column generation is a very efficient way of solving the master problem. Let us proceed
by illustrating this idea on the cutting stock problem.
Consider a column in the matrix A of the second cutting stock formulation, and let us denote this
column by a. It describes a pattern, that is, the entries of that column equal the multiplicity of each
item type in that pattern. Of course, for a column a = (a1 , a2 , . . . , an ) of A to be a feasible pattern it
must be true that

i

wi ai â‰¤ L. But the converse is true as well, that is, any n nonnegative integers

(a1 , a2 , . . . , an ) that satisfy

i

wi ai â‰¤ L is a feasible pattern. Let us denote pattern j by nonnegative

integers (a1j , a2j , . . . , anj ).
Now suppose we are given a primal solution z = (z1 , z2 , . . .), and we are also given the values of the dual
variables (u1 , u2 , . . . , un ) associated to the constraints (5.6). How to determine whether z is an optimal
solution to the LP-relaxation of (CS-2)? Let us consider the constraints of the dual of the LP-relaxation
of (CS-2). We know that these constraints are of the form:

i

ui aij â‰¤ 1 for each possible pattern j

(verify this!). Thus, if the current u-values satisfy all these constraints (i.e., for each pattern j), we have
an optimal LP-solution. Or, alternatively formulated, we are looking for a pattern (a1 , a2 , . . . , an ) such
that

i

wi ai â‰¤ L and

i

ui ai > 1. If we can find such a pattern, we know that the current LP-solution

is not optimal, and hence we add this pattern to the current set of columns and start a new iteration.
Otherwise, if we cannot find such a pattern, the current LP-solution is optimal. Summarizing, the pricing
problem boils down to solving the following problem:

max
s.t.

u i ai

(5.8)

wi ai â‰¤ L

(5.9)

i
i

ai integer

for all i.

(5.10)

This problem is (a variant of) the well-known knapsack problem (which, in spite of its NP-hardness, can
be solved in reasonable computing times for very large instances, see Chapter 4). Concluding, the pricing
64

problem can be solved relatively fast, and hence the LP-relaxation of (CS-2) can be solved fast as well.

5.1.2

The hierarchical crew scheduling problem

In this subsection we illustrate the column generation technique on the hierarchical crew scheduling
problem. This problem can be described as follows. Given are m crews who have to perform n tasks.
For each crew t a cost-rate rt is known, t = 1, . . . , m. Each task is characterized by a starting time si
and a processing time pi . Each task i has to start at si and must be carried out nonpreemptively by
some crew until si + pi . Also, a distance dij for every pair of tasks i and j is given. Finally, the crews are
hierarchically ordered in the following way: for each job a 'maximal' crew is given such that each crew
with an index higher than the index of the maximal crew is not capable of performing that job; all other
crews are capable of performing that job. The cost of a crew is the product of its cost rate rt and the
distance traveled by that crew. The problem is to find an assignment of tasks to crews against minimal
costs.
Example Here is an instance with 2 crews and 3 jobs:
m = 2, n = 3, r1 = 3, r2 = 1, s1 = 20, s2 = 40, s3 = 60, p1 = p2 = p3 = 0,
job 1 can only be carried out by crew 1, jobs 2 and 3 can be carried out by each of the two crews and
with distances dij as in Figure 5.1.
Â 
10Â 
Â 
Â  16
â¦
0
â…
â…
9
â…
â…

2â¦
â…
â… 12
â… âœŽâ˜ž
â… â¦
1
âœâœŒ
Â 
16 Â 12
Â 
Â 
â¦
3

Figure 5.1: The distances
One (of the 2) optimal solution(s) for this instance can be described as follows. Starting at time 0, crew
1 travels to job 1, waits 4 time units, performs the job, travels to job 3, waits 28 time units, performs it
and returns to the depot. Distance traveled is 37, so its costs are 111. Crew 2 simply travels to job 2,
performs it and returns for a total cost of 20. Thus, the value of an optimal solution to this instance is
131.
65

We model the hierarchical crew scheduling problem as a problem on a weighted, directed graph G = (V, A)
as follows. Construct a vertex for each task i = 1, . . . , n and let V = {1, . . . , n} âˆª {s, f }. The vertices s
and f can be regarded as the source and sink of the graph G. There is an arc from vertex i to j in A if
si + pi + dij â‰¤ sj for all i, j âˆˆ V \ {s, f }. Further, there is an arc {s, i} and {i, f } in A for all i âˆˆ V \ {s, f }.
Finally, there is a cost vector ctij associated to each arc {i, j} âˆˆ A. We compute this vector as follows:
ï£±
ï£² r Â·d
if crew t is able to do jobs i and j,
t
ij
ctij =
(5.11)
ï£³ M
otherwise, for all t, for all {i, j} âˆˆ A,

where M is a large number.

Consider now the following formulation using the following parameters:
â€¢ R = the set of paths in G from s to f ,
for i = 1, . . . , n, r âˆˆ R :
â€¢ Î´ir
for t = 1, . . . , m, r âˆˆ R :

ï£±
ï£² 1 if vertex i is in path r, and
=
ï£³ 0 otherwise

â€¢ ctr = cost incurred when crew t takes path r, (observe that, for a given r, t, we can easily compute
this quantity using (5.11); notice that if a path r contains a vertex that cannot be served by crew t, we
set the corresponding ctr to a large number),
and using, for t = 1, . . . , m, r âˆˆ R, the decision variables
ï£±
ï£² 1 if crew t takes path r,
ytr =
ï£³ 0 otherwise.
m

ctr ytr

(CGHCSPm) minimize
t=1 râˆˆR
m

Î´ir ytr = 1 for i = 1, . . . , n;

such that

(5.12)

t=1 râˆˆR

ytr â‰¤ 1

for t = 1, . . . , m;

(5.13)

for t = 1, . . . , m, r âˆˆ R.

(5.14)

râˆˆR

ytr âˆˆ {0, 1}

Constraints (5.12) state that each vertex must occur once in a selected path, inequalities (5.13) express
that a crew can do at most one path and constraints (5.14) are the integrality constraints. The LPrelaxation of this model is found by replacing constraints (5.14) by ytr â‰¥ 0 for all t, r.
66

Given a feasible basis for some LP the question determining whether this basis is an optimal one is: do
there exist variables with negative reduced costs? Using dual variables ui attached to constraints (5.12)
and dual variables et to constraints (5.13) we can deduce the following expression for the reduced costs
of variable ytr :

n

Î´ir ui âˆ’ et .

ctr âˆ’
i=1

Thus, given some LP-solution and its associated dual variables the pricing problem boils down to the
following question:

n

Î´ir ui âˆ’ et < 0?

Price: âˆƒ t, r âˆˆ R such that ctr âˆ’
i=1

This question can be answered as follows:
Lemma: Problem Price can be solved by solving m shortest path problems on a directed acyclic graph.
Proof: We claim that for a fixed t, Price boils down to a shortest path problem which implies the lemma.
This can be seen as follows: consider the graph corresponding to the instance and consider only those
nodes that can be visited by crew t. Observe that no cycles occur in this network. Modify the existing
arc costs ctij by setting hij := ctij âˆ’ uj for all {i, j} âˆˆ A. Observe that the cost of a path P in this network
with respect to costs hij from s to f equals:

{i,j}âˆˆP

hij =

t
{i,j}âˆˆP (cij

âˆ’ uj ) = ctr âˆ’

i Î´ir ui .

If this

expression is smaller than et , there is a profitable column (path) for crew t, otherwise not.
âœ·

This shows that the pricing problem, and hence the associated LP-relaxation, can be solved efficiently.

5.2

Branch-and-price

Of course, it is nice that one can solve a linear program with (exponentially) many variables efficiently
using column generation. However, this leaves us with a potentially fractional solution. We are interested
in integral solutions. Can we embed column generation within an enumerative framework so that we are
guaranteed to find an integral optimum? In this section we describe such an approach.
Let us consider the example of the hierarchical crew scheduling problem. A simple idea would be to
argue as follows: given a fractional solution, pick a variable with a fractional value. We know that
in an optimal solution this variable will have either value 0 or value 1. Create two subproblems, one
67

subproblem in which that variable equals 1, and another subproblem where this variable is constrained to
be 0. Unfortunately, this idea is too simple. Setting a variable to 1 in the crew scheduling context poses
no problem: indeed the problem becomes smaller since we postulate that, in this branch this crew t takes
path r. However, setting a variable to 0 causes a difficulty: how can we guarantee that when we solve
the pricing problem this specific variable does NOT come out as the variable to be added? One might
think: OK let us find the shortest path, and if it corresponds to this variable, find the second shortest
path. But that idea is bound to cause difficulties when we have a branching tree that can have many
levels.
We need another partitioning of the solution space. Instead of branching by setting a variable to 1 versus
setting it to 0, we need a branching rule that does not destroy the efficient solvability of the pricing
problem. For the hierarchical crew scheduling problem, an example of such a rule is as follows: Here
we propose a branching rule that leaves the structure of the problem intact, allowing for the efficient
solvability of the pricing problem throughout the search tree.
Suppose that y is a fractional feasible LP-solution, and let us call a path r from s to f a fractional path
(with respect to y) if there exists a t with 0 < ytr < 1. We claim that y has the following property: there
exist two vertices i and j (that differ from source and sink) that lie consecutively on a fractional path
such that the sum of all ytr such that r contains arc {i, j} is greater than 0 and smaller than 1. Let us
formally phrase this claim in the following lemma:
Lemma: If y is fractional, there exist two nodes i, j âˆˆ V \ {s, f }, {i, j} âˆˆ A with
is contained in r ytr < 1.
Proof: Observe that if y is fractional there are at least two different fractional paths. Now, consider the
0<

t

r:{i,j}

first node in each fractional path. If this set of nodes has cardinality more than 1, the claim is easily seen
to be true. So assume that each fractional path has the same first node. However, then we can repeat
this argument replacing the sink s by this first node. Since there must be at least two fractional paths,
a pair i, j as described in the lemma must exist.
âœ·

Thus, by this Lemma, when y is fractional there exist nodes i and j (that differ from source and sink)
that are connected by an arc whose sum of fractional values lies between 0 and 1. Now, in an optimal
solution either these nodes are visited consecutively, or they are not. More specifically, given a fractional
68

solution we identify two nodes i and j having the property described above. Then we branch as follows.
In one branch we modify G into G1 by deleting all arcs {i, p} for p = j and all arcs {p, j} for p = i. Thus,
in any feasible solution there is a path that contains arc {i, j}. In the other branch we modify G into G2
by simply deleting arc {i, j}. In this case it is obvious that no feasible solution has a path with arc {i, j}
in it. Notice that the current solution is excluded by this rule. Let us illustrate this branching rule on
the example.
Example (continued): Consider the instance described in the example. The graph corresponding to
this instance is depicted in Figure 5.2.
â¦
âœ¯2
âœŸâœŸ
âœ’
Â 
â…
âœŸâœŸ Â 
â…
âœŸ
Â 
â…
âœŸâœŸ âœŽâ˜ž
âœŸ
Â 
â˜ â¦
â…
âœ²
sâ¦ âœ² 1â¦
f
âœâœŒ
â
ââ
â…
âœ’
Â 
Â 
â
â…
ââ â…
Â 
ââ
â˜â„
â…
Â 
â¥
3â¦
Figure 5.2: The graph G
An optimal solution to the LP-relaxation of (5.12)-(5.14) for this instance is described by y2,sâˆ’2âˆ’3âˆ’f =
y1,sâˆ’1âˆ’2âˆ’f = y1,sâˆ’1âˆ’3âˆ’f = 12 , and all other variables 0. Now, let 1,2 be a pair of nodes that we branch
on. The resulting graphs G1 and G2 are depicted in Figure 5.3:
â¦
2â¦
âœ¯2
âœŸ
âœŸ
âœ’ â…
Â 
â…
Â 
âœŸâœŸ
â…
â…
âœŸ
Â 
âœŸ
â…
â…
âœŸ
âœŽâ˜ž
âœŽâ˜ž
Â 
â˜â¦
â…
â˜â¦
â…
âœŸ
âœ²
sâ¦ âœ² 1â¦
sâ¦ âœ² 1â¦
f
f
âœâœŒ
âœâœŒ
â
â
â…
âœ’
Â 
âœ’
Â 
ââ
ââ
Â 
Â 
ââ
ââ â…
Â 
Â 
ââ
âââ…
â„
â˜â¦
â…
Â 
Â 
â¥ 3â„
â
â
â¥
â¦
3
Figure 5.3: The graphs G1 (left) and G2 (right)
Notice that in G1 the arcs {s, 2}, {1, 3} and {1, f } have been deleted. When solving the LP-relaxation
corresponding to G1 we find an integral solution with value 132. G2 is constructed by deleting arc {1, 2}.
In this branch we also find an integral solution with value 131, which is therefore optimal.
Concluding, we have found a branching rule for the hierarchical crew scheduling problem that preserves
69

the structure of the original problem. In this way, the efficient solvability of the pricing problem remains
intact throughout the nodes in the branching tree. In general, this is the challenge when devising
branching rules for integer programming problems whose LP-relaxation is solved by column generation.

Exercises
Exercise 1
Consider the following problem occurring in combinatorial auctions. Given are m items, and n bidders.
Each bidder j, 1 â‰¤ j â‰¤ n, specifies a (nonnegative) bid bj (S) for subsets of the items S âŠ† {1, 2, . . . , m}.
(Notice that the value of a bid that a bidder specifies for a pair of items need not be the same as the sum
of the valuations for the two individual items; this is, in fact, the defining property of a combinatorial
auction). Clearly, each item can be allocated to at most one bidder, and each bidder receives at most
one set of items.
(i) Give an integer programming formulation for this problem that maximizes the total auction revenue.
(ii) How many variables are there?
(iii) What is the dual of the linear programming relaxation of your formulation?
Exercise 2
Consider the following problem occurring in production management. Given are N jobs which have to be
processed by a single machine. Each job needs some (prespecified) tools to be processed; in total there
are M tools available. The machine can hold at most C tools simultaneously (and of course, each job
does not need more than C tools). We call a subset of the jobs a feasible group if these jobs together
require at most C tools. The job grouping problem consists in finding a minimum number of feasible
groups such that each job is contained in at least one group.
(i) Formulate this problem as an integer programming problem.
(ii) Describe a column generation approach for this problem.
Exercise 3
Consider the following problem occurring in routing applications. Given are n + 1 locations, among
70

which a depot, and distances d between each pair of locations. The depot harbors K vehicles that serve
the locations. No vehicle can serve more than C locations. The problem is to select K paths (one for
each vehicle), each starting at the depot, such that each location is in exactly one path. The goal is to
minimize the total length of the K paths.
(i) Formulate
ï£± this problem as a â€˜traditional' integer program using variables
ï£² 1 if vehicle k travels from location i to location j
xijk =
ï£³ 0 otherwise

(ii) Formulate this problem as an integer programming problem using a formulation that involves
exponentially many variables.
(iii) Discuss how a column generation approach for this formulation would work.

71

72

Chapter 6

Approximation algorithms
6.1

Introduction

Instances of combinatorial optimization problems cannot always be solved to optimality within a reasonable amount of computing time. Indeed, some combinatorial problems are so-called NP-hard (e.g.
knapsack, stable set, node cover) which implies that the best-known algorithms that guarantee an optimal solution have an enumerative character (like the branch-and-price approach).
This chapter deals with approximation algorithms. These are algorithms that return a feasible solution
fast (i.e. within polynomial time), but sacrifice the guarantee of optimality. Thus, whereas branch-andprice algorithms always output an optimum solution at the expense of potentially enormous computing
times, approximation algorithms form a dual approach to solving combinatorial optimization problems.
An approximation algorithm guarantees a fast solution, but not necessarily an optimal one. Of course,
one still wants an approximation algorithm to produce solutions that have a value that does not differ
too much from the optimum value. In order to be able to judge approximation algorithms, the concept
of worst case analysis is discussed in Section 6.2. Further, we present approximation algorithms for two
specific problems, namely node cover (Section 6.3) and the TSP (Section 6.4).
73

6.2

Worst case analysis

The worst case ratio (WCR) of an algorithm A for a minimization problem P is defined as follows. Given
an instance I of problem P , let the value of the solution generated by algorithm A be A(I), and let the
optimum value be denoted by OPT(I); we will sometimes simply write OPT, and ignore the â€œ(I)â€-part.
The ratio
R(I) =

A(I)
OP T (I)

is a measure of the quality of the solution found. (Notice that other measure are certainly possible as
well!). Now, the smallest upper bound on R(I), measured over all instances I of P is called the worst
case ratio (WCR) of algorithm A, i.e.,
A(I)
.
OP T (I)

W CR(A) = supI

Notice that this ratio is at least 1. For a maximization problem P we define a similar quality measure as
follows.
W CR(A) = infI

A(I)
.
OP T (I)

This ratio is at most 1 (and not smaller than 0). How can one find the WCR of a certain algorithm?
Almost always this amounts to applying a problem specific analysis. In such an analysis two things must
be argued:
â€¢ one has to argue that for all instances I of P it is true that
â€¢ there exists an instance I of P for which the ratio

A(I)
OP T (I)

A(I)
OP T (I)

â‰¤ R, and that

is equal (or arbitrarily close) to R.

Then one can conclude that W CR(A) = R. Notice that the WCR depends on the algorithm, thus different
algorithms for the same problem can yield different WCRs (as we shall see in this chapter). Of course, one
could ask the question: how well can we approximate a certain problem when using only polynomial time
algorithms. More formal, let P OLY T IM E(P ) = {A| A is a polynomial time algorithm for P }, then one
is interested in something that can be formulated as:
infAâˆˆP OLY T IME(P ) W CR(A).
This is certainly a valid question, and in recent years a number of results in this direction have been
obtained; however, we will not go into this issue.
74

6.3

Node Cover

Recall that given a graph G = (V, E), a node cover is a subset of the vertices W âŠ† V with the property
that each edge in E is incident to at least one vertex in W . The objective in this problem is to find
a node cover with a minimum number of nodes. This problem is NP-hard. Let us now describe two
approximation algorithms for node cover.

Algorithm 1 (Input: a graph G = (V, E); output: a node cover W )
W = âˆ…, E â€² := E
while E â€² = âˆ…
do
Choose a node v âˆˆ V with largest degree;
W := W âˆª {v};
Update E â€² , that is remove from E â€² all edges incident to v;
od
Algorithm 2 (Input: a graph G = (V, E); output: a node cover W )
W = âˆ…, E â€² := E
while E â€² = âˆ…
do
Choose an arbitrary edge in E â€² ;
W := W âˆª {v, w};
Update E â€² , that is remove from E â€² all edges incident to v or w;
od
Algorithm 1 is a greedy type of algorithm. At first glance it seems to be better than Algorithm 2, as it uses
at least part of the structure of the graph. And indeed, in instances arising from practical applications,
it turns out that Algorithm 1 outperforms Algorithm 2 with respect to the number of nodes in the cover
found. However, as we are about to discover, the WCR of Algorithm 2 is much better than the WCR of
Algorithm 1.
Consider the following instance depicted in Figure 6.1.
75

C

â‘ 

B

â‘ 
â‘ 
â‘ 
â‘ 
â‘ 
âœŸ
âœ‘
âœ‘
Â 
âœ
â…
âœ
Â 
Â 
â†
âœâ†
âœŸ
âœ‘
âœ‘
Â âœ
â†â…
âœ â†
âœ‘Â 
âœ‘ Â âœ âœŸ
â† Â  âœ âœ‘ Â  âœâœŸâœŸ
âœ‘Â 
â†â… âœ
âœâœ‘âœ‘ Â 
â† âœâ… Â â† âœâœ‘âœ‘ Â âœŸâœŸ
âœŸ
âœ Â 
â†âœ âœŸ
Â  âœ‘
Â  âœ‘
â†âœ â…
âœ‘âœâœŸâ†âœŸ
Â âœ‘âœ‘âœ Â 
âœ â† Â âœ‘â…
âœŸ
âœ Â â†âœ‘âœŸ âœâ…Â â†âœ‘ âœ Â 
âœ‘âœŸ Â âœ‘
â…â† âœÂ 
âœÂ 
âœ‘
âœŸâœŸ â† âœâœ‘
âœÂ 
â†â‘ 
âœ‘
â…
âœ
âœ‘
âœŸ
Â 
Â 
â†â‘ 
âœ
â‘ 

A

â‘ 

â‘ 

â‘ 

â‘ 

Figure 6.1: An instance for node cover.

What is the optimum? It is not hard to figure out that one needs at least 5 nodes for a node cover in
the instance above, and moreover, that taking all nodes from layer B indeed constitutes a feasible node
cover. Thus, this is an optimum solution. Let us now apply algorithm 1 to this instance and let us break
ties by choosing nodes in the lowest possible layer first (that is nodes of layer A enjoy priority over nodes
in layer B which enjoy priority over nodes in layer C). What happens? Algorithm 1 selects first the nodes
from layer A and then the nodes from layer B concluding with a node cover consisting of 8 nodes. Even
worse, we can generalize this instance as follows: let the number of nodes in layer B be n, then there
are also n nodes in layer C and there are at most n âˆ’ 1 nodes in the bottom layer. Again, each node in
layer A is connected to each node in layer B and a node in layer C is connected only to its â€œcompanion
nodeâ€ directly beneath it. Thus the optimum node cover consists of all nodes in layer B with optimal
value n, whereas Algorithm 1 will find a solution consisting of all nodes of layer A and B, with a value
equal to almost twice the optimum value. What can we deduce from this example concerning the WCR
of Algorithm 1? Well, we can only say that it is at least 2. One cannot conclude that the WCR equals 2
since there may exist instances on which Algorithm 1 fares even worse.
And these examples exist. Consider Figure 6.2.
In this instance we see that the optimum node cover still consists of all middle nodes (i.e. value 6),
whereas the node cover constructed by Algorithm 1 will consist of all nodes in the two bottom layers (i.e.
a solution with value 13). From this instance alone we can conclude that the WCR of Algorithm 1 must
76

C

â‘ 

B

â‘ 
â‘ 
â‘ 
â‘ 
â‘ 
â‘ 
â›
â
â›â› âœâ
â›â› âœâ›
â——
â——
âœ‘
â——
â†
â…
â…
âœ
â†
â†
Â 
Â 
â
â——
â——
âœ‘
â—— â› âœ â…â…â
â›â›
âÂ  â†â… â——Â  â…âœ‘ âœ â†
âœ â† â——
â—— â›â› ââ
âââ† â…
â›â†â›Â  â——
â†
â›
â…â›âœ â
Â â—— âœ‘â… âœ
â——
âœ
â›
â
â
â——
âœ‘
â——
â› â†â â›â——
â†
âœâ…
â† ââ…
Â 
âœ
â›
â——
â——
âœ‘
â—— âœâ… â›Â 
â
â
â â——
âœ â… â†
â†â›â›â…
âœ‘
â——
Â  â›â——
Â  â›â†â›â›â
âœ â…
âœ
â â—— â… â†
â
âœ‘ â†â—— â›â…
Â â——â… â† Â â›
âœ â——
âœ
â——
â—— â›âœâ
âœ‘â›â
â
â›â
â›
â›â
â… â†
â›
âœâ…
â†â
â——â…Â â†âœ‘
âœ Â 
âœ
â›â——
â›â——
â
â
â——
âœ‘
â——
â›â——
â
âœâ
â† â›
Â 
âœÂ 
âœ
â›â…
â›â…
â——
â——
âœ‘â…
â——â†
ââ†
â
â
â
â†â‘ 
â›
â——
â›â‘  â›â…
â——
â†âœâ‘  â›â…
â†â‘ 
âœ‘
â——
â…
Â 
Â 
âœâ‘ 
âœ
â‘ 
â‘ 

A

â‘ 

â‘ 

â‘ 

â‘ 

â‘ 

Figure 6.2: Another instance for node cover.
be worse than 2.1666. However, by generalizing this instance an even more dramatic statement can be
made:
Theorem 6.1 For each r â‰¥ 0, there exist instances I of node cover such that A(I) â‰¥ r Â· OP T (I)
In other words, the WCR of Algorithm 1 is unbounded; it is impossible to find a constant R such that
A(I)
OP T (I)

â‰¤ R. Let us motivate this theorem by generalizing the instance in Figure 6.2. The structure of

this instance is as follows. In case of 6 middle nodes we do the following: partition the nodes from B into
3 pairs and join the nodes in each pair with a node from layer A. Then we partition the nodes in layer
B into two triples, and again join all nodes in a triple with a new node from layer A. Repeat this for
quadruples and quintuples, and so on, possibly leaving out some nodes from layer B, and always adding
a new node in layer A. Then, when applying Algorithm 1, there is always a node from the bottom layer
with highest degree, consequently Algorithm 1 will find a node cover consisting of L(n) + n nodes, where
L(n) is the number of nodes in layer A. How large is L(n)? Observe that L(n) =

nâˆ’1
j=2 âŒŠn/jâŒ‹.

We leave

the exact proof of Theorem 6.1 as an exercise.
What about Algorithm 2? It is easy to establish a lower bound of 2 on the WCR. Indeed, when simply
taking a graph consisting of 2n vertices and n edges forming a perfect matching, one observes that n is
the value of a minimum node cover, whereas Algorithm 2 selects all 2n nodes. However, it turns out that
this is the worst that can happen for Algorithm 2:
77

Theorem 6.2 W CR(Algorithm2) = 2.
The argument is as follows. Of course, any node cover must cover all edges chosen by Algorithm 2.
However, these edges do not have a node in common, and therefore each edge must be covered by a
different node in any node cover. Thus no node cover can be smaller than half the size of the node cover
found by Algorithm 2. Together with the example sketched above Theorem 6.2 now follows.

6.4

The Traveling Salesman Problem (TSP)

In a sense the TSP is a harder problem to solve than node cover. This follows from the well known fact
that, unless P=NP, no polynomial time algorithm for the TSP exists that has a bounded WCR (which
contrasts with Algorithm 2 in the previous section).
What we can do is to restrict our instances. Recall that the input to the TSP is a distance matrix D. In
the sequel we restrict ourselves to instances for which the distances satisfy the triangle inequality, that is,
we have that dik â‰¤ dij + djk for all i, j, k. Observe that many practical problems satisfy this restriction.
Indeed, TSP instances coming from actual â€œtravel settingsâ€ are quite likely to obey the triangle inequality.
The double tree algorithm (DT).
Algorithm DT consists of four phases. In the first three phases, we construct an Euler-cycle that we
convert into a Hamilton circuit in Phase 4.
Phase 1. Construct a minimum spanning tree with respect to the distance function d.
Phase 2. Double all edges in the tree. Notice that the resulting graph is Eulerian.
Phase 3. Determine an Euler cycle in the Eulerian graph determined in Phase 2. Since the Eulerian
graph is connected (it contains the minimum spanning tree as a subgraph), the cycle contains each vertex
at least once.

Phase 4. Convert the Euler cycle into a Hamilton cycle by applying shortcuts, i.e., replace a pair of
consecutive edges {i, j} and {j, k} in the Euler cycle by {i, k}. We are only allowed to do this if j appears
somewhere else in the Euler cycle.
Example Consider the following 7-city TSP instance.
78

1
1

2

3

4

5

6

7

1

2

2

3

4

5

1

1

3

3

4

2

3

2

3

1

2

3

1

4

2
3
4
5

1

6
7
3 âœ‰

3 âœ‰
2 âœ‰

4
âœ‰

5
âœ‰

6
âœ‰

7
âœ‰

2 âœ‰

4
âœ‰

5
âœ‰

6
âœ‰

7
âœ‰

1 âœ‰

1 âœ‰

Figure 6.3: Phases 1 and 2.
The Euler-cycle generated in phase 3 is 1232456765421.
The operation described in Phase 4 can be performed on any cycle. Its effect is that a new cycle is
constructed with one edge less; in this cycle, there is one vertex that is visited one time less in comparison
with the previous cycle. Due to the assumption that the length function satisfies the triangle inequality,
it follows that applying a shortcut does not increase the length of the cycle. Let us formally record this
observation in a lemma.
Lemma 6.3 Let G = (V, E) be a complete graph, and let d : E â†’ R+ be a distance function on the
edges, which satisfies the triangle inequality. Let C be a cycle in this graph with total length d(C). If C â€²
is a cycle constructed from C by applying shortcuts, then we have that the total length of C â€² is no more
than d(C).
Let us now be more specific concerning Phase 4. We apply a shortcut on each second appearance of a
vertex j. Therefore, each vertex remains in the cycle at least once. After the shortcut has been applied
to all second appearances of the vertices, the cycle contains each vertex exactly once, that is, we have
constructed a Hamilton cycle.
79

3 âœ‰
2 âœ‰

4
âœ‰

5
âœ‰

6
âœ‰

3 âœ‰
â…
â…
â… 4
â…âœ‰
2 âœ‰

7
âœ‰

1 âœ‰

3 âœ‰
â…
â…
â… 4
â…âœ‰
2 âœ‰

5
âœ‰

6
âœ‰

7
âœ‰

5
âœ‰

6
âœ‰

7
âœ‰

1 âœ‰

5
âœ‰

Figure 6.4: Phase 4: replacing 324 by 34
3 âœ‰
â…
â…
â… 4
6
7
âœ‰
âœ‰
â…âœ‰
2 âœ‰

1 âœ‰

1 âœ‰
Figure 6.5: Phase 4: further replacements

We now show that Algorithm DT will never produce a solution with length more than twice the length
of an optimal solution. In other words:
Theorem 6.4 W CR(DT ) â‰¤ 2.
Given an instance I, let OPT(I) denote the length of an optimal tour, and let zDT (I) denote the length
of the tour constructed by algorithm DT. Finally, let zT (I) denote the length of a minimum spanning
tree. We first prove that zT (I) â‰¤ OPT(I) for all instances I; we then complete the proof by showing
that zDT (I) â‰¤ 2 Â· zT (I).
1. Consider any optimal tour. If we delete an arbitrary edge from it, then we obtain a . . . spanning tree.
By definition, the length of a spanning tree does not exceed the length of a minimal spanning tree,
and hence, we know that its length amounts to at least zT . Concluding, we have that zT â‰¤ OPT.
2. The total length of the edges in the Eulerian graph that is constructed by doubling the minimum
spanning tree is equal to 2 Â· zT . From Lemma 6.3, it follows that the length zDT of the Hamiltonian
circuit that is obtained by applying shortcuts, amounts to no more than the length of the Eulerian
cycle, which is equal to 2 Â· zT .
80

Combining both results, we get zDT â‰¤ 2 Â· zT â‰¤ 2 Â· OPT.
The tree-matching algorithm (TM).
From the analysis above, it follows that, if we want to improve our worst-case ratio, then we can try to
decrease the length of the Eulerian cycle. In the sequel we will do so. This means that we use the same
structure of algorithm DT. In fact, Phases 1, 3, and 4 in Algorithm TM are identical to the corresponding
phases in Algorithm DT. Thus, we only change the phase in which the Eulerian Cycle is constructed.
Recall that a graph is Eulerian if and only if it is connected, and each vertex has even degree. It seems
obvious to start with a minimum spanning tree to make sure that the graph is connected. The only
problem left is to take care of the vertices with odd degree, which we denote by V0 ; notice that the
number of vertices with odd degree is even. We see that we can get even degree in each of these vertices
by adding a perfect matching on these vertices V0 (see Chapter 1 for the definition of a perfect matching).
This is exactly what happens in phase 2 of algorithm TM, where we will compute a minimum weight
perfect matching M on the vertices in V0 .
Consider the example again. The initial minimum spanning tree contains 4 vertices of odd degree, namely
1, 2, 3, and 7. The minimum weight perfect matching of these vertices consists of the edges {1, 2} and
{3, 7}. Thus, we get the following extension of the minimum spanning tree.
3 âœ‰
2 âœ‰

4
âœ‰

5
âœ‰

6
âœ‰

âœ‰â³
3 â³
â³â³â³
â³â³
â³â³â³
â³â³â³
4
5
6 â³â³ 7
â³âœ‰
âœ‰
âœ‰
âœ‰
âœ‰
2

7
âœ‰

1 âœ‰

1 âœ‰
Figure 6.6: Phases 2 of algorithm TM.

An Euler-cycle in this graph is 123765421, where 2 is the only vertex that appears more than once, and
therefore we remove one of its occurrences.
This small change with respect to algorithm DT results in a better worst-case behaviour. For any instance
of the TSP (satisfying the triangle-inequality), algorithm TM constructs a tour with length no more than
3
2

times the length of an optimal tour. To prove this, it suffices to show that the length zM of the

matching M is no more than

1
2

times OPT. Namely, then zT M â‰¤ zT + zM â‰¤ OPT + 12 Â· OPT =
81

3
2

Â· OPT.

â³â³â³
3 âœ‰
â³â³
â³â³â³
â³â³
â³â³â³
4
5
6 â³â³ 7
âœ‰
âœ‰
âœ‰
âœ‰
â³âœ‰
2

âœ‰
3 â³
â³â³â³
â³â³
â³â³â³
â³â³â³
4
5
6â³â³â³ 7
âœ‰
âœ‰
âœ‰
â³âœ‰
2 âœ‰
Â 
Â 
Â 
âœ‰
1 Â 

1 âœ‰

Figure 6.7: Replacing 421 by 41.
The proof makes use of a shrinking argument. Consider any optimal tour with value OPT. Apply
shortcuts such that only the vertices in V0 remain in the cycle; this yields a cycle C on the vertices in
V0 with length no more than OPT. C can be partitioned into two perfect matchings M1 and M2 on V0
by â€˜walking' along the circuit and putting the first edge in M1 , the second edge in M2 , the third edge in
M1 , etc. Notice that the cycle contains an even number of edges, because |V0 | is even.
Since M1 and M2 are perfect matchings on V0 , we have that d(M ) â‰¤ d(M1 ) and d(M ) â‰¤ d(M2 ). Hence,
we have that 2 Ã— d(M ) â‰¤ d(M1 ) + d(M2 ) = d(C) â‰¤ OPT, which was to be proved.
Notice that for both algorithms, our analysis of the worst-case ratio depends heavily on the assumption
that the triangle inequality holds. It can be shown that, in case the triangle inequality fails to hold, the
worst-case ratio is unbounded (as could be inferred from the beginning of this section).

Exercises
Exercise 1
Prove Theorem 6.1.
Exercise 2
Consider the following greedy algorithm for the knapsack problem. Sort the objects by decreasing ratio
of profit and size, and reindex the items such that the order of objects is 1, 2, . . . , n. Next, greedily pick
objects in this order while ensuring that the capacity of the knapsack is not exceeded.
â€¢ Show that this method can behave arbitrarily bad,
â€¢ Modify this method by identifying the smallest k such that the total size of the first k objects
82

exceeds the capacity. Next, find the best of the following two solutions: {1, 2, . . . , k âˆ’ 1} and {k}.
Show that this algorithm is a 2-approximation.

Exercise 3
Consider the node packing problem. What can you tell about the WCR of each of the following two
algorithms?
Algorithm 1 (Input: a graph G = (V, E); output: a node packing W )
W = âˆ…, Gâ€² = (V â€² , E â€² ) := G
while V â€² = âˆ…
do
Choose a node v âˆˆ V â€² with smallest degree;
W := W âˆª {v};
Update Gâ€² , that is V â€² := V â€² \ {v} and remove from E â€² all edges incident to v;
od
Algorithm 2 (Input: a graph G = (V, E); output: a node packing W )
W = âˆ…, Gâ€² = (V â€² , E â€² ) := G
while E â€² = âˆ…
do
Choose an arbitrary edge {v,w} in E â€² ;
W := W âˆª {v};
Update Gâ€² , that is V â€² := V â€² \ {v, w} and remove from E â€² all edges incident to v or w;
od
Exercise 4
Consider the matching problem. What can you tell about the WCR of the following greedy algorithm
for matching?
Algorithm (Input: a graph G = (V, E); output: a matching M )
M = âˆ…, Gâ€² = (V â€² , E â€² ) := G
while E â€² = âˆ…
do
Choose an arbitrary edge {v, w} âˆˆ E â€² ;
83

M := M âˆª {v, w};
Update Gâ€² , that is V â€² := V â€² \ {v, w} and remove from E â€² all edges incident to v or w;
od
Exercise 5
An edge coloring of a graph is a coloring of the edges such that no two edges connected to the same
vertex have the same color. The edge coloring problem is to minimize the number of colors used to color
a graph. The greedy algorithm for edge coloring colors edge after edge. When coloring an edge it will
first consider colors that are already in use before assigning a new color. What can you say concerning
the WCR of this algorithm?
Exercise 6
Can you find instances of the TSP which imply that (together with Theorem 6.4) that WCR(DT)= 2?
Exercise 7
A TSP instance is called geometric if each of the cities can be represented by a point in the plane, i.e.
each city lies at coordinates (xi , yi ), i = 1, . . . , n. What do the result in the previous exercise tell you
about WCR(DT) for the geometric TSP?

84

Chapter 7

Lagrangian Relaxation
In this chapter we study a concept called Lagrangian relaxation. The formulation of many practical
combinatorial optimization problems contains several sets of constraints. Lagrangian relaxation exploits
this property by disregarding one or more sets of constraints. It turns out that this relaxation allows
one to obtain lower bounds (upper bounds) for difficult minimization (maximization) problems. In
Section 7.1 we introduce some terminology, Section 7.2 presents some basic results, in Section 7.3 we
describe an application, and Section 7.4 concludes this chapter by presenting two ways of strengthening
the Lagrangian dual.

7.1

Terminology

Consider an integer program

n
zIP = max {cx| x âˆˆ S}, where S = {x âˆˆ Z+
| Ax â‰¤ b},

85

which can be rewritten as problem (IP):
zIP =

max

cx

s.t.

A1 x â‰¤ b1 (complicating constraints)
A2 x â‰¤ b2 (nice constraints)
n
x âˆˆ Z+
.

(Notice that the superscripts do NOT refer to powers). We are going to assume that A2 x â‰¤ b2 are
m âˆ’ m1 â€œnice constraintsâ€, say those of an assignment or a network problem. By simply dropping the
m1 complicating constraints A1 x â‰¤ b1 , we obtain a relaxation of problem (IP) that is obviously easier to
solve than problem (IP) itself. There are many problems for which the constraints can be partitioned in
this way. An example will be given in Section 7.4.
The idea of dropping constraints can be embedded in a more general framework called Lagrangian relaxation. It is convenient to consider a generalization of problem (IP) called IP(Q), which we formulate as
follows:

zIP = max
s.t.

cx
A1 x â‰¤ b1
x âˆˆ Q.

n
| A2 x â‰¤
However, when we are discussing results that are specific to IP, it is assumed that Q = {x âˆˆ Z+

b2 } = âˆ…. Of course, the problem obtained from IP(Q) by dropping the complicating constraints A1 x â‰¤ b1
m1
is much easier to solve than IP(Q). Now, for any Î» âˆˆ R+
, consider the problem LR(Î»):

zLR (Î») = max {z(Î», x)| x âˆˆ Q}, where z(Î», x) = cx + Î»(b1 âˆ’ A1 x).
The problem LR(Î») is called the Lagrangian relaxation of IP(Q) with respect to A1 x â‰¤ b1 . This terminology is used because the vector Î» plays a role in LR(Î») similar to the role of Lagrange multipliers in
constrained optimization problems. By our choice, LR(Î») does not contain the complicating constraints.
86

Instead we have included these constraints in the objective function with the â€œpenaltyâ€ term Î»(b1 âˆ’ A1 x).
Since Î» â‰¥ 0, violations of A1 x â‰¤ b1 make the penalty term negative, and thus, intuitively speaking, for
suitably large values of Î», one would expect that A1 x â‰¤ b1 will be satisfied.
Let us formally state the relation between zIP and zLR (Î»):

Theorem 7.1 zLR (Î») â‰¥ zIP for all Î» â‰¥ 0.

Proof: If x is feasible in IP(Q), then x âˆˆ Q and hence x is feasible for LR(Î»). Also, z(Î», x) = cx + Î»(b1 âˆ’
A1 x) â‰¥ cx for all x feasible in IP(Q) since A1 x â‰¤ b1 and Î» â‰¥ 0.
âœ·

Obviously, one is interested in the least upper bound from the infinite family of relaxations {LR(Î»)}Î»â‰¥0 ,
denoted here by zLR (Î»âˆ— ), where Î»âˆ— is an optimal solution to the problem called LD:

zLD = min

Î»â‰¥0 zLR (Î»).

Problem LD is called the Lagrangian dual of IP(Q) with respect to the constraints A1 x â‰¤ b1 .

7.2

Some results

In this section we illustrate the terminology introduced in the previous section with the following example
and use this example to derive some results.
Example: Consider the following problem.
87

max 7x1 + 2x2

(7.1)

s.t. âˆ’ x1 + 2x2

â‰¤

4

(7.2)

6x1 + x2

â‰¤

24

(7.3)

âˆ’2x1 âˆ’ 2x2

â‰¤

âˆ’7

(7.4)

âˆ’x1

â‰¤

âˆ’2

(7.5)

x2

â‰¤

4

(7.6)

x

âˆˆ

2
Z+
.

(7.7)

2
Let Q = {x âˆˆ Z+
| x satisfies (7.3), (7.4), (7.5) and (7.6)}. The Lagrangian relaxation (see Section 7.1)

with respect to âˆ’x1 + 2x2 â‰¤ 4 is:

zLR (Î»)

xâˆˆQ [7x1

+ 2x2 + Î»(4 + x1 âˆ’ 2x2 )]

=

max

=

max (7 + Î»)x1 + (2 âˆ’ 2Î»)x2 + 4Î»
s.t. 6x1 + x2 â‰¤ 24
âˆ’2x1 âˆ’ 2x2 â‰¤ âˆ’7
âˆ’x1 â‰¤ âˆ’2
x2 â‰¤ 4
2
x âˆˆ Z+
.

Notice that Q is a finite set of points, which can be written as follows (see Figure 7.1):

{x1 , x2 , x3 , x4 , x5 , x6 , x7 , x8 } = {(2, 2), (2, 3), (2, 4), (3, 1), (3, 2), (3, 3), (3, 4), (4, 0)}.

The example suggests at least two different viewpoints. The first one is to see z(Î», x) = (c âˆ’ Î»A1 )x + Î»b1
as a linear function of x for fixed Î». It then follows that zLR (Î») can be determined by solving the linear
program
88

zLR (Î») = max {z(Î», x)| x âˆˆ conv(Q)}.

In this example,

2
conv(Q) = {x âˆˆ R+
| âˆ’ x1 â‰¤ âˆ’2, x2 â‰¤ 4, âˆ’x1 âˆ’ x2 â‰¤ âˆ’4, 4x1 + x2 â‰¤ 16}.

In Figure 7.1, solid lines indicate the original constraints, the dots correspond to the feasible integral
vertices, and the dashed lines correspond to constraints describing conv(Q).

x2
4

s

3

s

2
1
1

s âŠ
âŠ
âˆ âŠ
s

âŠ
âˆâŠ

s
s âŠ
â…
âˆâŠ
â…
âŠ
â…
â… â…
âŠ
â…s
âˆâŠ
â…
â… âŠ
â…â…
â… âˆâŠs
2
3
4

x1

Figure 7.1: The region
Thus, computing zLR (Î») for Î» = 0 and Î» = 1 gives:

zLR (0) =

max {7x1 + 2x2 )| x âˆˆ conv(Q)} = z(0, x7 ) = 29,

zLR (1) =

max {8x1 + 4)| x âˆˆ conv(Q)} = z(1, x8 ) = 36.

As one increases Î» from 0, zLR (Î») first decreases until Î» =
89

1
9

and then it increases. In general we obtain

zLR (Î»)

=

z(Î», x7 ) = 29 âˆ’ Î» for 0 â‰¤ Î» â‰¤

zLR (Î»)

=

z(Î», x8 ) = 28 + 8Î» for Î» â‰¥

1
,
9

1
.
9

Hence, we can deduce that zLD = zLR ( 91 ) = z( 19 , x7 ) = z( 91 , x8 ) = 28 98 and Î»âˆ— =

1
9.

Notice that, for

Î» = 91 , x7 as well as x8 are optimal with respect to the constraints determining conv(Q), and hence the
objective function - which equals 7 91 x1 +

16
9 x2

for Î» =

1
9

- must be parallel to 4x1 + x2 â‰¤ 16. All these

calculations can be seen in Figure 7.1.
The second viewpoint is to consider zLR (Î») to be determined by maximization over a set of discrete
points, that is,
zLR (Î») = maxxi âˆˆQ z(Î», xi ).
Observe here that for a fixed xi , z(Î», xi ) = cxi + Î»(b1 âˆ’ A1 xi ) is a linear function of Î». See Figure 7.2,
where we have drawn the linear functions z(Î», xi ) for xi âˆˆ Q.
z(Î», xi )

(4)
âœ±
âœ±
(8)
36
âœ±
âœ±
Â 
Â 
âœ±
Â 
(5)
Â 
âœ±
âœŸâœŸ
Â 
âœ±
âœŸ
Â 
âœŸ
Â 
âœ±
Â 
âœŸâœŸ
Â 
âœ±
Â 
âœ± âœŸâœŸ
Â 
Â 
30
âœ±
âœ­âœ­âœ­(6)
âœŸâœŸ
Â 
Â 
âœŸ âœ­âœ­âœ­âœ­âœ­âœ­
Â 
â¤
âœ±
â¤â¤
â¤â¤â¤
âœŸ
âœ­âœ­
â¤âœ­
âœŸ
âœ­
Â 
â¤âœ±
â¤âœ­
âœ­
â¤â¤â¤
âœŸ
âœ­âœ­âœŸ
âœ±
âœ­
â¤â¤â¤â¤
âœ­
âœ­
âœŸ
â¤â¤â¤â¤
âœŸâœ±âœ±
â¤(7)
âœŸâœŸâœ±
âœŸ
âœ±
24 âœ±
âœâœ(1)
âœ±
âœâœ
âœ
âœâœ
Â€Â€
âœâœ
Â€Â€
âœ
Â€Â€
âœâœ
(2)
Â€âœ
âœ
Â€Â€
âœ
âœ
Â€Â€
âœ
Â€Â€
âœâœ
Â€Â€
18 âœ
Î»
1
2 Â€Â€
Â€Â€ (3)
Â€
Figure 7.2: The lines: (1) 18 + 2Î»; (2) 20; (3) 22 - 2Î»; (4) 23 + 5Î»; (5) 25 + 3Î»; (6) 27 + Î»; (7) 29 - Î»;
(8) 28 + 8Î»;
90

In Figure 7.2 one can read the values of zLR (Î») for any value of Î». We see that zLR (Î») is piecewise linear
and convex (the heavy lines in Figure 7.2) and that zLD = 28 98 . Formally, one solves the linear program

zLR (Î») = min {w| w â‰¥ z(Î», xi ) for i = 1, . . . , 8},

which shows that zLR (Î») is the maximum of a finite number of linear functions and is therefore piecewise
linear and convex.
We now study how the solution of the Lagrangian dual relates to the solution of the original problem
IP(Q). Returning to Figure 7.1, notice that when Î» = 1/9 we obtain

28

8
9

1
1
= z( , x7 ) = z( , x8 )
9
9
1 8 7 1 8
= z( , x + x )
9 9
9
1
1 8
= z( , (3, 4) + (4, 0))
9 9
9
1 28 32
1
28 32
= z( , ( , ) = z( , xâˆ— ) with xâˆ— = ( , )
9 9 9
9
9 9
1
âˆ—
âˆ—
âˆ—
= cx + (4 + x1 âˆ’ 2x2 )
9
âˆ—
= cx .

In other words, by taking a convex combination of points in Q (in this example x7 and x8 ), we obtain a
point xâˆ— in conv(Q) satisfying the complicating constraint, for which cxâˆ— = zLD . This shows that for the
example we get zLD = max {cx| A1 x â‰¤ b1 , x âˆˆ conv(Q)}. And in fact this holds in general as witnessed
by the following theorem which we state without proof.

Theorem 7.2
zLD = max {cx| A1 x â‰¤ b1 , x âˆˆ conv(Q)}.

An interesting question is of course: how good is the bound zLD ? In general, the difference between
zLD and zIP (called the duality gap) depends on the sizes of conv(S) (which determines zIP ), conv(Q) âˆ©
91

{x| A1 x â‰¤ b1 } (which determines zLD ) and the objective coefficients c. A duality gap of 0 can be
characterized as follows.

Theorem 7.3 zLD = zIP for all c if and only if
n
n
conv{Q âˆ© {x âˆˆ R+
| A1 x â‰¤ b1 }} = conv(Q) âˆ© {x âˆˆ R+
| A1 x â‰¤ b1 }.

Another interesting difference is the difference between zLD and the value of the LP-relaxation, denoted
n
by zLP . Notice that this only makes sense when Q = {x âˆˆ Z+
| A2 x â‰¤ b2 }. We can characterize the case

where zLP = zLD .

n
Theorem 7.4 zLD = zLP for all c if all the extreme points of {x âˆˆ R+
| A2 x â‰¤ b2 } are integral.

It is easily verified that the conditions mentioned in the two previous theorems are not fulfilled by our
2
example. Indeed, we have 28 = zIP < zLD = 28 98 < zLP = 30 11
. (Check this !).

In fact, a more natural choice of complicating constraints in our example would lead to different results
2
2
for zLD . If we set Q = {x âˆˆ Z+
| âˆ’ x1 â‰¤ âˆ’2, x2 â‰¤ 4}, we find that {x âˆˆ R+
| âˆ’ x1 â‰¤ âˆ’2, x2 â‰¤ 4} only has

integral extreme points so that by our latest theorem, this Lagrangian relaxation would terminate with
2
.
zLD = zLP = 30 11

Summarizing, we have

n
n
conv(S) âŠ† conv(Q) âˆ© {x âˆˆ R+
| A1 x â‰¤ b1 } âŠ† {x âˆˆ R+
| Ax â‰¤ b}.

This implies that zIP â‰¤ zLD â‰¤ zLP . But because some faces of the respective polyhedra can coincide,
we may obtain zIP = zLD or zLD = zLP for a particular c even if the conditions of the two previous
theorems do not hold. Below, we give at table indicating the possibilities using four different objective
functions c1 , c2 , c3 and c4 .
92

Objective functions

objective values

c1

zIP = zLD = zLP

2

zIP < zLD = zLP

c3

zIP < zLD < zLP

4

zIP = zLD < zLP

c

c

7.3

An application

Suppose there is a set of n jobs to be assigned to a set of n workers, with N = {1, . . . , n}. Suppose
further that
â€¢ cij is the value of assigning worker i to job j,
â€¢ tij is the cost of training worker i to do job j, and
â€¢ there is a training budget of b units.
We wish to maximize the total value of the assignment subject to the budget constraint, that is

max

cij

xij

(7.8)

xij

=

1 for i âˆˆ N

(7.9)

xij

=

1 for j âˆˆ N

(7.10)

tij xij

â‰¤

b

(7.11)

x

âˆˆ

{0, 1}.

(7.12)

iâˆˆN jâˆˆN

jâˆˆN

iâˆˆN

jâˆˆN iâˆˆN

If we wish to use Lagrangian relaxation there are different options to consider. Notice that in each of
the following four options the relaxed problem LR(Î») is considerably easier to solve than the original
problem.
1
1. Lagrangian relaxation with respect to (7.11). Then LR1 (Î»), Î» âˆˆ R+
is an assignment problem with

objective function
93

(cij âˆ’ Î»tij )xij .

Î»b +
iâˆˆN jâˆˆN

2. Lagrangian relaxation with respect to (7.9) and (7.10). Then LR2 (u, v), u âˆˆ Rn , v âˆˆ Rn is a
knapsack problem with objective function

ui +
iâˆˆN

(cij âˆ’ ui âˆ’ vj )xij .

vj +
jâˆˆN

iâˆˆN jâˆˆN

3. Lagrangian relaxation with respect to (7.9) or (7.10), say (7.9). Then LR3 (u), u âˆˆ Rn is a knapsack
problem with so-called generalized upper bound constraints and with objective function

(cij âˆ’ ui )xij .

ui +
iâˆˆN

iâˆˆN jâˆˆN

4. Lagrangian relaxation with respect to (7.9) or (7.10) and (7.11), say (7.9) and (7.11). Only gener1
with objective function
alized upper bound constraints remain. Thus, LR4 (u, Î»), u âˆˆ Rn , Î» âˆˆ R+

Î»b +

(cij âˆ’ ui âˆ’ Î»tij )xij ,

ui +
iâˆˆN

iâˆˆN jâˆˆN

which is trivial to solve. (For each j, an i is chosen to maximize cij âˆ’ui âˆ’Î»tij , and the corresponding
xij is set to 1).

In choosing a relaxation there are two major questions to consider: how strong is the lower bound zLD
and how difficult to solve is the Lagrangian dual (LD)? Let us here only consider the bounds.
When Q is a set of assignment constraints or a set of generalized upper bound constraints, we have that
4
1
= zLP . Since
= zLD
zLD

94

2

Q3 = {x âˆˆ {0, 1}n |

xij = 1 for j âˆˆ N,
iâˆˆN

tij xij â‰¤ b}
iâˆˆN jâˆˆN

2

âŠ‚ Q2 = {x âˆˆ {0, 1}n |

tij xij â‰¤ b}
iâˆˆN jâˆˆN

2

n
and conv(Q2 ) âŠ‚ {x âˆˆ R+
|

tij xij â‰¤ b, xij â‰¤ 1 for i, j âˆˆ N },
iâˆˆN jâˆˆN

we have
3
2
1
4
zIP â‰¤ zLD
â‰¤ zLD
â‰¤ zLD
= zLD
= zLP ,

and each of the inequalities is strict for some objective function.

7.4

Strengthening the Lagrangian dual

We now consider two ways of strengthening the Lagrangian dual of problem IP. The first approach yields
a dual whose optimal value equals
n
n
max{cx| x âˆˆ conv(x âˆˆ Z+
| A1 x â‰¤ b1 ) âˆ© conv(x âˆˆ Z+
| A2 x â‰¤ b2 )}.

This dual is obtained by applying Lagrangian duality to a reformulation of IP, which is called RIP:
zIP = max cx1
A1 x1

â‰¤ b1

A2 x2

â‰¤ b2

x1 âˆ’ x2

= 0

x1

âˆˆ

n
Z+

x2

âˆˆ

n
Z+
.

95

Taking now x1 âˆ’ x2 = 0 as complicating constraints, we obtain the Lagrangian dual of RIP:
zCSD = minu {max{(c

âˆ’

u)x1 + ux2 }}

A1 x1

â‰¤

b1

A2 x2

â‰¤

b2

x1

âˆˆ

n
Z+

x2

âˆˆ

n
Z+

= minc1 +c2 =c {

max

c1 x1 + max c2 x2 }

A1 x1

â‰¤

b1

A2 x2

â‰¤

b2

x1

âˆˆ

n
Z+

x2

âˆˆ

n
Z+
,

where u = c2 .
A polyhedral interpretation of the dual is stated in the next theorem.

n
n
| A2 x â‰¤ b2 
| A1 x â‰¤ b1  âˆ© convx âˆˆ Z+
Theorem 7.5 zCSD = maxcx| x âˆˆ convx âˆˆ Z+

and zCSD â‰¤ zLD .

The technique described is referred to here with CS since this technique has been called cost splitting.
The technique is useful when

n
n
| A1 x â‰¤ b1 , so for some objective functions c we obtain
| A1 x â‰¤ b1  âŠ‚ x âˆˆ R+
â€¢ convx âˆˆ Z+

zCSD < zLD .
â€¢ The sets of constraints Ai x â‰¤ bi are simple to deal with separately; that is, the difficulty is caused
by their interaction.

In our example, we could take A1 x â‰¤ b1 to be constraint set (7.9) and (7.11) and take A2 x â‰¤ b2 to be
3
with the inequality strict for some objective
constraint sets (7.10) and (7.11). This yields zCSD â‰¤ zLD

functions c.
96

Another approach that domiantes the Lagrangian dual is the â€œsurrogateâ€ dual. Starting from IP(Q),
m1
with weights Î» âˆˆ R+
for the complicating constraints, consider the following problem called SD(Î»).

zSD (Î») = max{cx| Î»A1 x â‰¤ Î»b1 , x âˆˆ Q}.

The problem SD(Î») is called the surrogate relaxation of IP(Q) with respect to A1 x â‰¤ b1 . SD(Î») contains
n
a single complicating constraint. For instance when Q = Z+
the surrogate relaxation is a knapsack

problem. The surrogate dual of IP(Q) is the problem denoted by SD.

zSD = min

Î»â‰¥0 zSD (Î»).

Although the surrogate dual can be used computationally, it does not have such nice theoretical properties
as the Lagrangian dual.

Exercises
Exercise 1
Consider the following problem.
max 2x1 + 5x2
4x1 + x2

â‰¤

28

x1 + 4x2

â‰¤

27

x1 âˆ’ 5x2

â‰¤

1

x

âˆˆ

2
Z+
.

(i) Show that if any two constraints are dualized, the value of the Lagrangian dual equals the value of
the LP-relaxation.
(ii) Find an objective function for which (i) is false.
97

(iii) Show that if any single constraint is dualized, the value of the Lagrangian dual is an improvement
compared to the value of the LP-relaxation.
(iv) Apply cost-splitting to get a better Lagrangian dual.

Exercise 2
Construct two Lagrangian duals for the generalized assignment problem and discuss their merits.

max
s.t.

j cij xij

i
j

xij â‰¤ 1 for i âˆˆ M

i li xij

â‰¤ bj for j âˆˆ N
2

x âˆˆ {0, 1}n .

\bibliographystyle{alpha}
\bibliography{biblio}
\printindex
\glsaddall
\glossarystyle{listgroup}
\printglossaries

\end{document}
